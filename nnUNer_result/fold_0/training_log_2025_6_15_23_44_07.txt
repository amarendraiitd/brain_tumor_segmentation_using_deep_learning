
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-06-15 23:44:09.434474: do_dummy_2d_data_aug: False 
2025-06-15 23:44:09.446351: Using splits from existing split file: /scratch/scai/mtech/aib232081/nnUNet_preprocessed/Task501_GLIOMA/splits_final.json 
2025-06-15 23:44:09.448175: The split file contains 1 splits. 
2025-06-15 23:44:09.448612: Desired fold for training: 0 
2025-06-15 23:44:09.448988: This split has 1080 training and 135 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 160, 112], 'median_image_size_in_voxels': [142.0, 175.0, 136.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Task501_GLIOMA', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [142, 175, 136], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 9210.0, 'mean': 1083.545654296875, 'median': 776.2343139648438, 'min': -38.0, 'percentile_00_5': 60.319400787353516, 'percentile_99_5': 3614.736328125, 'std': 863.6681518554688}, '1': {'max': 37011.69921875, 'mean': 1248.953857421875, 'median': 950.2376708984375, 'min': 0.0, 'percentile_00_5': 64.50062900543213, 'percentile_99_5': 5005.8203125, 'std': 1037.698486328125}, '2': {'max': 12372.0, 'mean': 1316.230224609375, 'median': 1016.6731262207031, 'min': 0.0, 'percentile_00_5': 215.22721061706542, 'percentile_99_5': 5257.6171875, 'std': 933.8424682617188}, '3': {'max': 4578.0, 'mean': 707.5701904296875, 'median': 619.3465881347656, 'min': -1.0, 'percentile_00_5': 11.428452491760254, 'percentile_99_5': 2516.0, 'std': 507.3000183105469}}} 
 
2025-06-15 23:44:17.576099: unpacking dataset... 
2025-06-15 23:44:32.756856: unpacking done... 
2025-06-15 23:44:32.810965: Unable to plot network architecture: 
2025-06-15 23:44:32.811660: No module named 'hiddenlayer' 
2025-06-15 23:44:32.961102:  
2025-06-15 23:44:32.961906: Epoch 0 
2025-06-15 23:44:32.963103: Current learning rate: 0.01 
2025-06-15 23:46:09.831867: train_loss -0.0033 
2025-06-15 23:46:09.849404: val_loss -0.1453 
2025-06-15 23:46:09.850304: Pseudo dice [0.0, 0.6517, 0.0197, 0.3326] 
2025-06-15 23:46:09.850965: Epoch time: 96.86 s 
2025-06-15 23:46:09.851604: Yayy! New best EMA pseudo Dice: 0.251 
2025-06-15 23:46:13.317420:  
2025-06-15 23:46:13.317969: Epoch 1 
2025-06-15 23:46:13.318360: Current learning rate: 0.00999 
2025-06-15 23:46:57.860343: train_loss -0.2008 
2025-06-15 23:46:57.861101: val_loss -0.2587 
2025-06-15 23:46:57.863569: Pseudo dice [0.0, 0.7449, 0.6795, 0.5753] 
2025-06-15 23:46:57.864198: Epoch time: 44.54 s 
2025-06-15 23:46:57.864693: Yayy! New best EMA pseudo Dice: 0.2759 
2025-06-15 23:46:59.884655:  
2025-06-15 23:46:59.885213: Epoch 2 
2025-06-15 23:46:59.885628: Current learning rate: 0.00998 
2025-06-15 23:47:54.182605: train_loss -0.2639 
2025-06-15 23:47:54.183997: val_loss -0.3025 
2025-06-15 23:47:54.184758: Pseudo dice [0.0, 0.7771, 0.7136, 0.6797] 
2025-06-15 23:47:54.185676: Epoch time: 54.3 s 
2025-06-15 23:47:54.186403: Yayy! New best EMA pseudo Dice: 0.3026 
2025-06-15 23:47:56.690008:  
2025-06-15 23:47:56.690773: Epoch 3 
2025-06-15 23:47:56.691457: Current learning rate: 0.00997 
2025-06-15 23:48:52.866915: train_loss -0.2832 
2025-06-15 23:48:52.868251: val_loss -0.3544 
2025-06-15 23:48:52.868721: Pseudo dice [0.0, 0.8224, 0.7647, 0.7398] 
2025-06-15 23:48:52.869086: Epoch time: 56.18 s 
2025-06-15 23:48:52.869421: Yayy! New best EMA pseudo Dice: 0.3305 
2025-06-15 23:48:54.500399:  
2025-06-15 23:48:54.501000: Epoch 4 
2025-06-15 23:48:54.501453: Current learning rate: 0.00996 
2025-06-15 23:49:39.030994: train_loss -0.3276 
2025-06-15 23:49:39.031870: val_loss -0.3564 
2025-06-15 23:49:39.032307: Pseudo dice [0.0038, 0.8093, 0.7803, 0.7116] 
2025-06-15 23:49:39.033070: Epoch time: 44.53 s 
2025-06-15 23:49:39.033590: Yayy! New best EMA pseudo Dice: 0.3551 
2025-06-15 23:49:41.674020:  
2025-06-15 23:49:41.674967: Epoch 5 
2025-06-15 23:49:41.675466: Current learning rate: 0.00995 
2025-06-15 23:50:35.705904: train_loss -0.3606 
2025-06-15 23:50:35.706666: val_loss -0.3942 
2025-06-15 23:50:35.707078: Pseudo dice [0.2304, 0.8441, 0.7897, 0.7714] 
2025-06-15 23:50:35.707469: Epoch time: 54.03 s 
2025-06-15 23:50:35.708035: Yayy! New best EMA pseudo Dice: 0.3854 
2025-06-15 23:50:37.217223:  
2025-06-15 23:50:37.217765: Epoch 6 
2025-06-15 23:50:37.218279: Current learning rate: 0.00995 
2025-06-15 23:51:22.873170: train_loss -0.3643 
2025-06-15 23:51:22.874584: val_loss -0.3963 
2025-06-15 23:51:22.875220: Pseudo dice [0.3348, 0.8371, 0.8199, 0.7928] 
2025-06-15 23:51:22.876010: Epoch time: 45.66 s 
2025-06-15 23:51:22.876524: Yayy! New best EMA pseudo Dice: 0.4165 
2025-06-15 23:51:25.292167:  
2025-06-15 23:51:25.292873: Epoch 7 
2025-06-15 23:51:25.293595: Current learning rate: 0.00994 
2025-06-15 23:52:21.950476: train_loss -0.3951 
2025-06-15 23:52:21.951371: val_loss -0.4112 
2025-06-15 23:52:21.951876: Pseudo dice [0.4163, 0.8653, 0.8193, 0.8052] 
2025-06-15 23:52:21.952314: Epoch time: 56.66 s 
2025-06-15 23:52:21.952748: Yayy! New best EMA pseudo Dice: 0.4475 
2025-06-15 23:52:24.058074:  
2025-06-15 23:52:24.058686: Epoch 8 
2025-06-15 23:52:24.059114: Current learning rate: 0.00993 
2025-06-15 23:53:10.110226: train_loss -0.4143 
2025-06-15 23:53:10.154339: val_loss -0.414 
2025-06-15 23:53:10.155493: Pseudo dice [0.4021, 0.833, 0.8086, 0.8362] 
2025-06-15 23:53:10.162373: Epoch time: 46.05 s 
2025-06-15 23:53:10.163167: Yayy! New best EMA pseudo Dice: 0.4748 
2025-06-15 23:53:12.601380:  
2025-06-15 23:53:12.601968: Epoch 9 
2025-06-15 23:53:12.602406: Current learning rate: 0.00992 
2025-06-15 23:53:59.029287: train_loss -0.4131 
2025-06-15 23:53:59.030455: val_loss -0.4435 
2025-06-15 23:53:59.031463: Pseudo dice [0.4825, 0.8485, 0.8155, 0.7692] 
2025-06-15 23:53:59.032554: Epoch time: 46.43 s 
2025-06-15 23:53:59.033180: Yayy! New best EMA pseudo Dice: 0.5002 
2025-06-15 23:54:01.200729:  
2025-06-15 23:54:01.201454: Epoch 10 
2025-06-15 23:54:01.202132: Current learning rate: 0.00991 
2025-06-15 23:54:53.694348: train_loss -0.4181 
2025-06-15 23:54:53.695188: val_loss -0.4555 
2025-06-15 23:54:53.695608: Pseudo dice [0.4392, 0.8604, 0.835, 0.7555] 
2025-06-15 23:54:53.696017: Epoch time: 52.49 s 
2025-06-15 23:54:53.696388: Yayy! New best EMA pseudo Dice: 0.5224 
2025-06-15 23:54:55.664694:  
2025-06-15 23:54:55.665564: Epoch 11 
2025-06-15 23:54:55.666475: Current learning rate: 0.0099 
2025-06-15 23:55:37.527994: train_loss -0.4302 
2025-06-15 23:55:37.529083: val_loss -0.4234 
2025-06-15 23:55:37.529842: Pseudo dice [0.5274, 0.8036, 0.7629, 0.7876] 
2025-06-15 23:55:37.530519: Epoch time: 41.86 s 
2025-06-15 23:55:37.531043: Yayy! New best EMA pseudo Dice: 0.5422 
2025-06-15 23:55:39.879807:  
2025-06-15 23:55:39.880561: Epoch 12 
2025-06-15 23:55:39.881149: Current learning rate: 0.00989 
2025-06-15 23:56:32.923761: train_loss -0.4149 
2025-06-15 23:56:32.924706: val_loss -0.4449 
2025-06-15 23:56:32.925155: Pseudo dice [0.5563, 0.8318, 0.8206, 0.817] 
2025-06-15 23:56:32.925593: Epoch time: 53.05 s 
2025-06-15 23:56:32.925946: Yayy! New best EMA pseudo Dice: 0.5636 
2025-06-15 23:56:34.880093:  
2025-06-15 23:56:34.880749: Epoch 13 
2025-06-15 23:56:34.881168: Current learning rate: 0.00988 
2025-06-15 23:57:18.822009: train_loss -0.4362 
2025-06-15 23:57:18.823206: val_loss -0.4835 
2025-06-15 23:57:18.823734: Pseudo dice [0.5438, 0.8452, 0.8615, 0.8309] 
2025-06-15 23:57:18.824445: Epoch time: 43.94 s 
2025-06-15 23:57:18.824877: Yayy! New best EMA pseudo Dice: 0.5843 
2025-06-15 23:57:22.397369:  
2025-06-15 23:57:22.398238: Epoch 14 
2025-06-15 23:57:22.399002: Current learning rate: 0.00987 
2025-06-15 23:58:18.547469: train_loss -0.4368 
2025-06-15 23:58:18.548444: val_loss -0.4742 
2025-06-15 23:58:18.549086: Pseudo dice [0.5917, 0.8687, 0.8706, 0.8552] 
2025-06-15 23:58:18.549592: Epoch time: 56.15 s 
2025-06-15 23:58:18.550447: Yayy! New best EMA pseudo Dice: 0.6055 
2025-06-15 23:58:20.767529:  
2025-06-15 23:58:20.768203: Epoch 15 
2025-06-15 23:58:20.768721: Current learning rate: 0.00986 
2025-06-15 23:59:08.238481: train_loss -0.4493 
2025-06-15 23:59:08.239233: val_loss -0.4748 
2025-06-15 23:59:08.239805: Pseudo dice [0.561, 0.8771, 0.8712, 0.8107] 
2025-06-15 23:59:08.240205: Epoch time: 47.47 s 
2025-06-15 23:59:08.240551: Yayy! New best EMA pseudo Dice: 0.623 
2025-06-15 23:59:09.978671:  
2025-06-15 23:59:09.979184: Epoch 16 
2025-06-15 23:59:09.979550: Current learning rate: 0.00986 
2025-06-15 23:59:48.907901: train_loss -0.4445 
2025-06-15 23:59:48.908673: val_loss -0.4856 
2025-06-15 23:59:48.909103: Pseudo dice [0.5851, 0.8796, 0.8295, 0.8217] 
2025-06-15 23:59:48.910016: Epoch time: 38.93 s 
2025-06-15 23:59:48.910614: Yayy! New best EMA pseudo Dice: 0.6386 
2025-06-15 23:59:50.505471:  
2025-06-15 23:59:50.506057: Epoch 17 
2025-06-15 23:59:50.506624: Current learning rate: 0.00985 
2025-06-16 00:00:33.209291: train_loss -0.4503 
2025-06-16 00:00:33.210739: val_loss -0.4755 
2025-06-16 00:00:33.211371: Pseudo dice [0.5102, 0.8667, 0.7898, 0.8079] 
2025-06-16 00:00:33.212080: Epoch time: 42.7 s 
2025-06-16 00:00:33.212732: Yayy! New best EMA pseudo Dice: 0.6491 
2025-06-16 00:00:35.623349:  
2025-06-16 00:00:35.624189: Epoch 18 
2025-06-16 00:00:35.624726: Current learning rate: 0.00984 
2025-06-16 00:01:29.756958: train_loss -0.4671 
2025-06-16 00:01:29.758463: val_loss -0.4747 
2025-06-16 00:01:29.759243: Pseudo dice [0.5764, 0.8787, 0.8638, 0.8181] 
2025-06-16 00:01:29.759809: Epoch time: 54.13 s 
2025-06-16 00:01:29.760316: Yayy! New best EMA pseudo Dice: 0.6626 
2025-06-16 00:01:31.864968:  
2025-06-16 00:01:31.865508: Epoch 19 
2025-06-16 00:01:31.865879: Current learning rate: 0.00983 
2025-06-16 00:02:14.349072: train_loss -0.4405 
2025-06-16 00:02:14.350278: val_loss -0.458 
2025-06-16 00:02:14.350874: Pseudo dice [0.5447, 0.8774, 0.843, 0.8474] 
2025-06-16 00:02:14.351677: Epoch time: 42.49 s 
2025-06-16 00:02:14.352294: Yayy! New best EMA pseudo Dice: 0.6742 
2025-06-16 00:02:16.436415:  
2025-06-16 00:02:16.437081: Epoch 20 
2025-06-16 00:02:16.437522: Current learning rate: 0.00982 
2025-06-16 00:03:11.248145: train_loss -0.4474 
2025-06-16 00:03:11.249372: val_loss -0.4856 
2025-06-16 00:03:11.250089: Pseudo dice [0.5523, 0.8567, 0.8596, 0.8373] 
2025-06-16 00:03:11.250768: Epoch time: 54.81 s 
2025-06-16 00:03:11.251395: Yayy! New best EMA pseudo Dice: 0.6844 
2025-06-16 00:03:14.367456:  
2025-06-16 00:03:14.368062: Epoch 21 
2025-06-16 00:03:14.368526: Current learning rate: 0.00981 
2025-06-16 00:04:00.273346: train_loss -0.4507 
2025-06-16 00:04:00.274469: val_loss -0.5098 
2025-06-16 00:04:00.275274: Pseudo dice [0.6692, 0.8892, 0.8704, 0.8197] 
2025-06-16 00:04:00.275775: Epoch time: 45.91 s 
2025-06-16 00:04:00.276262: Yayy! New best EMA pseudo Dice: 0.6972 
2025-06-16 00:04:02.229138:  
2025-06-16 00:04:02.229825: Epoch 22 
2025-06-16 00:04:02.230269: Current learning rate: 0.0098 
2025-06-16 00:04:42.640655: train_loss -0.4771 
2025-06-16 00:04:42.643158: val_loss -0.4619 
2025-06-16 00:04:42.643783: Pseudo dice [0.5714, 0.8637, 0.8274, 0.8137] 
2025-06-16 00:04:42.644299: Epoch time: 40.41 s 
2025-06-16 00:04:42.644756: Yayy! New best EMA pseudo Dice: 0.7044 
2025-06-16 00:04:44.878020:  
2025-06-16 00:04:44.878678: Epoch 23 
2025-06-16 00:04:44.879189: Current learning rate: 0.00979 
2025-06-16 00:05:36.575079: train_loss -0.4654 
2025-06-16 00:05:36.576231: val_loss -0.4853 
2025-06-16 00:05:36.577050: Pseudo dice [0.5612, 0.8824, 0.84, 0.8045] 
2025-06-16 00:05:36.577746: Epoch time: 51.7 s 
2025-06-16 00:05:36.578376: Yayy! New best EMA pseudo Dice: 0.7111 
2025-06-16 00:05:39.837448:  
2025-06-16 00:05:39.838053: Epoch 24 
2025-06-16 00:05:39.838485: Current learning rate: 0.00978 
2025-06-16 00:06:27.101105: train_loss -0.4662 
2025-06-16 00:06:27.101821: val_loss -0.5292 
2025-06-16 00:06:27.102329: Pseudo dice [0.6999, 0.8919, 0.8655, 0.8443] 
2025-06-16 00:06:27.102759: Epoch time: 47.27 s 
2025-06-16 00:06:27.103106: Yayy! New best EMA pseudo Dice: 0.7225 
2025-06-16 00:06:29.730907:  
2025-06-16 00:06:29.731656: Epoch 25 
2025-06-16 00:06:29.732157: Current learning rate: 0.00977 
2025-06-16 00:07:15.967717: train_loss -0.4813 
2025-06-16 00:07:15.969452: val_loss -0.4899 
2025-06-16 00:07:15.970404: Pseudo dice [0.5176, 0.8807, 0.872, 0.8692] 
2025-06-16 00:07:15.971384: Epoch time: 46.24 s 
2025-06-16 00:07:15.972035: Yayy! New best EMA pseudo Dice: 0.7288 
2025-06-16 00:07:18.386740:  
2025-06-16 00:07:18.387437: Epoch 26 
2025-06-16 00:07:18.388203: Current learning rate: 0.00977 
2025-06-16 00:08:14.445571: train_loss -0.4728 
2025-06-16 00:08:14.446455: val_loss -0.5014 
2025-06-16 00:08:14.446964: Pseudo dice [0.6219, 0.8946, 0.8278, 0.8256] 
2025-06-16 00:08:14.447412: Epoch time: 56.06 s 
2025-06-16 00:08:14.447990: Yayy! New best EMA pseudo Dice: 0.7351 
2025-06-16 00:08:16.006118:  
2025-06-16 00:08:16.006670: Epoch 27 
2025-06-16 00:08:16.007044: Current learning rate: 0.00976 
2025-06-16 00:09:00.200283: train_loss -0.4823 
2025-06-16 00:09:00.201519: val_loss -0.4943 
2025-06-16 00:09:00.202333: Pseudo dice [0.5047, 0.8827, 0.8589, 0.8482] 
2025-06-16 00:09:00.203282: Epoch time: 44.2 s 
2025-06-16 00:09:00.204026: Yayy! New best EMA pseudo Dice: 0.739 
2025-06-16 00:09:03.054889:  
2025-06-16 00:09:03.055605: Epoch 28 
2025-06-16 00:09:03.056167: Current learning rate: 0.00975 
2025-06-16 00:10:00.513568: train_loss -0.4698 
2025-06-16 00:10:00.514915: val_loss -0.4846 
2025-06-16 00:10:00.515337: Pseudo dice [0.5605, 0.8824, 0.8537, 0.8468] 
2025-06-16 00:10:00.515697: Epoch time: 57.46 s 
2025-06-16 00:10:00.516017: Yayy! New best EMA pseudo Dice: 0.7437 
2025-06-16 00:10:02.077388:  
2025-06-16 00:10:02.077951: Epoch 29 
2025-06-16 00:10:02.078373: Current learning rate: 0.00974 
2025-06-16 00:10:45.725492: train_loss -0.4746 
2025-06-16 00:10:45.726368: val_loss -0.5198 
2025-06-16 00:10:45.727105: Pseudo dice [0.5221, 0.8811, 0.8538, 0.8788] 
2025-06-16 00:10:45.727617: Epoch time: 43.65 s 
2025-06-16 00:10:45.728313: Yayy! New best EMA pseudo Dice: 0.7477 
2025-06-16 00:10:48.379221:  
2025-06-16 00:10:48.380143: Epoch 30 
2025-06-16 00:10:48.380738: Current learning rate: 0.00973 
2025-06-16 00:11:35.309735: train_loss -0.4926 
2025-06-16 00:11:35.311087: val_loss -0.5362 
2025-06-16 00:11:35.312059: Pseudo dice [0.6604, 0.9047, 0.8892, 0.8903] 
2025-06-16 00:11:35.312700: Epoch time: 46.93 s 
2025-06-16 00:11:35.313420: Yayy! New best EMA pseudo Dice: 0.7566 
2025-06-16 00:11:37.527558:  
2025-06-16 00:11:37.528253: Epoch 31 
2025-06-16 00:11:37.528781: Current learning rate: 0.00972 
2025-06-16 00:12:30.006847: train_loss -0.4981 
2025-06-16 00:12:30.007747: val_loss -0.519 
2025-06-16 00:12:30.008353: Pseudo dice [0.5733, 0.8972, 0.8587, 0.8628] 
2025-06-16 00:12:30.008802: Epoch time: 52.48 s 
2025-06-16 00:12:30.009180: Yayy! New best EMA pseudo Dice: 0.7607 
2025-06-16 00:12:31.765868:  
2025-06-16 00:12:31.766559: Epoch 32 
2025-06-16 00:12:31.767465: Current learning rate: 0.00971 
2025-06-16 00:13:12.038977: train_loss -0.4836 
2025-06-16 00:13:12.039805: val_loss -0.5072 
2025-06-16 00:13:12.040370: Pseudo dice [0.6246, 0.8447, 0.8821, 0.8065] 
2025-06-16 00:13:12.041077: Epoch time: 40.27 s 
2025-06-16 00:13:12.041661: Yayy! New best EMA pseudo Dice: 0.7636 
2025-06-16 00:13:14.313438:  
2025-06-16 00:13:14.314174: Epoch 33 
2025-06-16 00:13:14.314611: Current learning rate: 0.0097 
2025-06-16 00:14:05.936272: train_loss -0.4776 
2025-06-16 00:14:05.937053: val_loss -0.4925 
2025-06-16 00:14:05.937488: Pseudo dice [0.5821, 0.8897, 0.8599, 0.8359] 
2025-06-16 00:14:05.938048: Epoch time: 51.62 s 
2025-06-16 00:14:05.938445: Yayy! New best EMA pseudo Dice: 0.7664 
2025-06-16 00:14:07.746254:  
2025-06-16 00:14:07.746799: Epoch 34 
2025-06-16 00:14:07.747159: Current learning rate: 0.00969 
2025-06-16 00:14:54.869601: train_loss -0.4756 
2025-06-16 00:14:54.870825: val_loss -0.4663 
2025-06-16 00:14:54.871418: Pseudo dice [0.4998, 0.8635, 0.8707, 0.8045] 
2025-06-16 00:14:54.872179: Epoch time: 47.12 s 
2025-06-16 00:14:57.519859:  
2025-06-16 00:14:57.520662: Epoch 35 
2025-06-16 00:14:57.521676: Current learning rate: 0.00968 
2025-06-16 00:15:41.594520: train_loss -0.494 
2025-06-16 00:15:41.595678: val_loss -0.5083 
2025-06-16 00:15:41.596402: Pseudo dice [0.4116, 0.8817, 0.7962, 0.8541] 
2025-06-16 00:15:41.597197: Epoch time: 44.08 s 
2025-06-16 00:15:43.426137:  
2025-06-16 00:15:43.427178: Epoch 36 
2025-06-16 00:15:43.428060: Current learning rate: 0.00968 
2025-06-16 00:16:39.001824: train_loss -0.4976 
2025-06-16 00:16:39.002578: val_loss -0.5503 
2025-06-16 00:16:39.002964: Pseudo dice [0.7081, 0.9046, 0.8806, 0.8612] 
2025-06-16 00:16:39.003362: Epoch time: 55.58 s 
2025-06-16 00:16:39.003871: Yayy! New best EMA pseudo Dice: 0.7703 
2025-06-16 00:16:40.588903:  
2025-06-16 00:16:40.589477: Epoch 37 
2025-06-16 00:16:40.589912: Current learning rate: 0.00967 
2025-06-16 00:17:22.714755: train_loss -0.4865 
2025-06-16 00:17:23.125134: val_loss -0.5156 
2025-06-16 00:17:23.126340: Pseudo dice [0.5928, 0.8731, 0.8766, 0.8939] 
2025-06-16 00:17:23.162731: Epoch time: 42.13 s 
2025-06-16 00:17:23.164377: Yayy! New best EMA pseudo Dice: 0.7742 
2025-06-16 00:17:27.169583:  
2025-06-16 00:17:27.170320: Epoch 38 
2025-06-16 00:17:27.170951: Current learning rate: 0.00966 
2025-06-16 00:18:22.923076: train_loss -0.5043 
2025-06-16 00:18:22.925118: val_loss -0.5091 
2025-06-16 00:18:22.925651: Pseudo dice [0.6089, 0.8852, 0.8465, 0.8597] 
2025-06-16 00:18:22.926082: Epoch time: 55.75 s 
2025-06-16 00:18:22.926467: Yayy! New best EMA pseudo Dice: 0.7768 
2025-06-16 00:18:24.843862:  
2025-06-16 00:18:24.844473: Epoch 39 
2025-06-16 00:18:24.844863: Current learning rate: 0.00965 
2025-06-16 00:19:10.882404: train_loss -0.4936 
2025-06-16 00:19:10.883466: val_loss -0.5168 
2025-06-16 00:19:10.884351: Pseudo dice [0.7797, 0.885, 0.894, 0.8831] 
2025-06-16 00:19:10.884945: Epoch time: 46.04 s 
2025-06-16 00:19:10.885479: Yayy! New best EMA pseudo Dice: 0.7852 
2025-06-16 00:19:13.374291:  
2025-06-16 00:19:13.374950: Epoch 40 
2025-06-16 00:19:13.375354: Current learning rate: 0.00964 
2025-06-16 00:20:05.387129: train_loss -0.4855 
2025-06-16 00:20:05.388480: val_loss -0.4964 
2025-06-16 00:20:05.389378: Pseudo dice [0.4897, 0.8804, 0.831, 0.8943] 
2025-06-16 00:20:05.390075: Epoch time: 52.01 s 
2025-06-16 00:20:07.438435:  
2025-06-16 00:20:07.439362: Epoch 41 
2025-06-16 00:20:07.439852: Current learning rate: 0.00963 
2025-06-16 00:21:01.352951: train_loss -0.489 
2025-06-16 00:21:01.354096: val_loss -0.5323 
2025-06-16 00:21:01.354945: Pseudo dice [0.5892, 0.8883, 0.8678, 0.8774] 
2025-06-16 00:21:01.355659: Epoch time: 53.92 s 
2025-06-16 00:21:01.356218: Yayy! New best EMA pseudo Dice: 0.7862 
2025-06-16 00:21:03.716895:  
2025-06-16 00:21:03.717510: Epoch 42 
2025-06-16 00:21:03.717931: Current learning rate: 0.00962 
2025-06-16 00:21:43.932206: train_loss -0.5051 
2025-06-16 00:21:43.933048: val_loss -0.4941 
2025-06-16 00:21:43.933490: Pseudo dice [0.6267, 0.8475, 0.8818, 0.8504] 
2025-06-16 00:21:43.934045: Epoch time: 40.22 s 
2025-06-16 00:21:43.934429: Yayy! New best EMA pseudo Dice: 0.7877 
2025-06-16 00:21:47.347548:  
2025-06-16 00:21:47.348482: Epoch 43 
2025-06-16 00:21:47.349090: Current learning rate: 0.00961 
2025-06-16 00:22:36.206576: train_loss -0.51 
2025-06-16 00:22:36.207762: val_loss -0.5113 
2025-06-16 00:22:36.208651: Pseudo dice [0.555, 0.8966, 0.8627, 0.849] 
2025-06-16 00:22:36.209538: Epoch time: 48.86 s 
2025-06-16 00:22:36.210360: Yayy! New best EMA pseudo Dice: 0.788 
2025-06-16 00:22:38.536980:  
2025-06-16 00:22:38.537679: Epoch 44 
2025-06-16 00:22:38.538255: Current learning rate: 0.0096 
2025-06-16 00:23:33.539149: train_loss -0.4926 
2025-06-16 00:23:33.540002: val_loss -0.5533 
2025-06-16 00:23:33.540412: Pseudo dice [0.7106, 0.908, 0.9012, 0.8614] 
2025-06-16 00:23:33.540843: Epoch time: 55.0 s 
2025-06-16 00:23:33.541371: Yayy! New best EMA pseudo Dice: 0.7938 
2025-06-16 00:23:35.814051:  
2025-06-16 00:23:35.814704: Epoch 45 
2025-06-16 00:23:35.815129: Current learning rate: 0.00959 
2025-06-16 00:24:15.353759: train_loss -0.5049 
2025-06-16 00:24:15.354825: val_loss -0.5194 
2025-06-16 00:24:15.355462: Pseudo dice [0.6655, 0.8797, 0.8664, 0.8116] 
2025-06-16 00:24:15.356045: Epoch time: 39.54 s 
2025-06-16 00:24:15.356554: Yayy! New best EMA pseudo Dice: 0.795 
2025-06-16 00:24:17.522094:  
2025-06-16 00:24:17.522665: Epoch 46 
2025-06-16 00:24:17.523068: Current learning rate: 0.00959 
2025-06-16 00:25:09.994898: train_loss -0.4977 
2025-06-16 00:25:09.996226: val_loss -0.5203 
2025-06-16 00:25:09.997155: Pseudo dice [0.6008, 0.8915, 0.8695, 0.8756] 
2025-06-16 00:25:09.998343: Epoch time: 52.47 s 
2025-06-16 00:25:09.999286: Yayy! New best EMA pseudo Dice: 0.7964 
2025-06-16 00:25:12.097550:  
2025-06-16 00:25:12.098230: Epoch 47 
2025-06-16 00:25:12.098731: Current learning rate: 0.00958 
2025-06-16 00:26:03.210334: train_loss -0.5089 
2025-06-16 00:26:03.211427: val_loss -0.524 
2025-06-16 00:26:03.212103: Pseudo dice [0.6817, 0.8819, 0.9078, 0.8759] 
2025-06-16 00:26:03.212721: Epoch time: 51.11 s 
2025-06-16 00:26:03.213603: Yayy! New best EMA pseudo Dice: 0.8005 
2025-06-16 00:26:05.794811:  
2025-06-16 00:26:05.795487: Epoch 48 
2025-06-16 00:26:05.795912: Current learning rate: 0.00957 
2025-06-16 00:26:48.099504: train_loss -0.5008 
2025-06-16 00:26:48.100603: val_loss -0.5177 
2025-06-16 00:26:48.101244: Pseudo dice [0.62, 0.8803, 0.8799, 0.8624] 
2025-06-16 00:26:48.102015: Epoch time: 42.31 s 
2025-06-16 00:26:48.102430: Yayy! New best EMA pseudo Dice: 0.8015 
2025-06-16 00:26:50.236902:  
2025-06-16 00:26:50.237591: Epoch 49 
2025-06-16 00:26:50.238462: Current learning rate: 0.00956 
2025-06-16 00:27:46.472428: train_loss -0.4869 
2025-06-16 00:27:46.473897: val_loss -0.5212 
2025-06-16 00:27:46.474343: Pseudo dice [0.693, 0.9082, 0.8933, 0.8867] 
2025-06-16 00:27:46.474737: Epoch time: 56.24 s 
2025-06-16 00:27:46.951962: Yayy! New best EMA pseudo Dice: 0.8059 
2025-06-16 00:27:50.760445:  
2025-06-16 00:27:50.761038: Epoch 50 
2025-06-16 00:27:50.761476: Current learning rate: 0.00955 
2025-06-16 00:28:32.466881: train_loss -0.5056 
2025-06-16 00:28:32.468092: val_loss -0.5238 
2025-06-16 00:28:32.469090: Pseudo dice [0.6962, 0.8906, 0.8973, 0.8152] 
2025-06-16 00:28:32.470068: Epoch time: 41.71 s 
2025-06-16 00:28:32.470960: Yayy! New best EMA pseudo Dice: 0.8078 
2025-06-16 00:28:34.630252:  
2025-06-16 00:28:34.631229: Epoch 51 
2025-06-16 00:28:34.632103: Current learning rate: 0.00954 
2025-06-16 00:29:34.044579: train_loss -0.5053 
2025-06-16 00:29:34.045784: val_loss -0.5286 
2025-06-16 00:29:34.046633: Pseudo dice [0.7245, 0.9002, 0.9024, 0.8654] 
2025-06-16 00:29:34.047563: Epoch time: 59.42 s 
2025-06-16 00:29:34.048299: Yayy! New best EMA pseudo Dice: 0.8118 
2025-06-16 00:29:36.460791:  
2025-06-16 00:29:36.461463: Epoch 52 
2025-06-16 00:29:36.461897: Current learning rate: 0.00953 
2025-06-16 00:30:24.693897: train_loss -0.4982 
2025-06-16 00:30:24.694763: val_loss -0.517 
2025-06-16 00:30:24.695207: Pseudo dice [0.6008, 0.8796, 0.883, 0.8803] 
2025-06-16 00:30:24.695623: Epoch time: 48.23 s 
2025-06-16 00:30:25.981223:  
2025-06-16 00:30:25.981788: Epoch 53 
2025-06-16 00:30:25.982198: Current learning rate: 0.00952 
2025-06-16 00:31:09.869057: train_loss -0.5156 
2025-06-16 00:31:09.870173: val_loss -0.5494 
2025-06-16 00:31:09.870900: Pseudo dice [0.5137, 0.8969, 0.8734, 0.8857] 
2025-06-16 00:31:09.871537: Epoch time: 43.89 s 
2025-06-16 00:31:11.546276:  
2025-06-16 00:31:11.546985: Epoch 54 
2025-06-16 00:31:11.547725: Current learning rate: 0.00951 
2025-06-16 00:32:09.546481: train_loss -0.5068 
2025-06-16 00:32:09.547459: val_loss -0.518 
2025-06-16 00:32:09.548069: Pseudo dice [0.6435, 0.902, 0.8478, 0.8643] 
2025-06-16 00:32:09.548563: Epoch time: 58.0 s 
2025-06-16 00:32:11.605386:  
2025-06-16 00:32:11.605991: Epoch 55 
2025-06-16 00:32:11.606403: Current learning rate: 0.0095 
2025-06-16 00:32:57.899626: train_loss -0.4932 
2025-06-16 00:32:57.900405: val_loss -0.5178 
2025-06-16 00:32:57.900820: Pseudo dice [0.5521, 0.8911, 0.8666, 0.8708] 
2025-06-16 00:32:57.901205: Epoch time: 46.3 s 
2025-06-16 00:32:59.535144:  
2025-06-16 00:32:59.535747: Epoch 56 
2025-06-16 00:32:59.536180: Current learning rate: 0.00949 
2025-06-16 00:33:58.258585: train_loss -0.5063 
2025-06-16 00:33:58.259417: val_loss -0.5104 
2025-06-16 00:33:58.259846: Pseudo dice [0.6995, 0.895, 0.8783, 0.8768] 
2025-06-16 00:33:58.260236: Epoch time: 58.72 s 
2025-06-16 00:34:00.838994:  
2025-06-16 00:34:00.839652: Epoch 57 
2025-06-16 00:34:00.840091: Current learning rate: 0.00949 
2025-06-16 00:34:45.075455: train_loss -0.5044 
2025-06-16 00:34:45.076397: val_loss -0.5561 
2025-06-16 00:34:45.077094: Pseudo dice [0.6971, 0.896, 0.8861, 0.889] 
2025-06-16 00:34:45.077547: Epoch time: 44.24 s 
2025-06-16 00:34:45.078387: Yayy! New best EMA pseudo Dice: 0.8146 
2025-06-16 00:34:48.128140:  
2025-06-16 00:34:48.128792: Epoch 58 
2025-06-16 00:34:48.129258: Current learning rate: 0.00948 
2025-06-16 00:35:32.879664: train_loss -0.5076 
2025-06-16 00:35:32.880745: val_loss -0.532 
2025-06-16 00:35:32.881315: Pseudo dice [0.615, 0.8905, 0.8793, 0.8483] 
2025-06-16 00:35:32.882016: Epoch time: 44.75 s 
2025-06-16 00:35:34.698093:  
2025-06-16 00:35:34.698703: Epoch 59 
2025-06-16 00:35:34.699308: Current learning rate: 0.00947 
2025-06-16 00:36:31.783002: train_loss -0.5198 
2025-06-16 00:36:31.784346: val_loss -0.5422 
2025-06-16 00:36:31.784930: Pseudo dice [0.499, 0.8992, 0.8745, 0.8566] 
2025-06-16 00:36:31.785363: Epoch time: 57.09 s 
2025-06-16 00:36:33.425930:  
2025-06-16 00:36:33.426497: Epoch 60 
2025-06-16 00:36:33.426866: Current learning rate: 0.00946 
2025-06-16 00:37:15.432941: train_loss -0.5008 
2025-06-16 00:37:15.433954: val_loss -0.5415 
2025-06-16 00:37:15.434515: Pseudo dice [0.6287, 0.9059, 0.8778, 0.857] 
2025-06-16 00:37:15.435213: Epoch time: 42.01 s 
2025-06-16 00:37:17.115291:  
2025-06-16 00:37:17.115952: Epoch 61 
2025-06-16 00:37:17.116564: Current learning rate: 0.00945 
2025-06-16 00:38:13.127511: train_loss -0.5179 
2025-06-16 00:38:13.128226: val_loss -0.5397 
2025-06-16 00:38:13.128819: Pseudo dice [0.6315, 0.8926, 0.8519, 0.8896] 
2025-06-16 00:38:13.129295: Epoch time: 56.01 s 
2025-06-16 00:38:15.207547:  
2025-06-16 00:38:15.208137: Epoch 62 
2025-06-16 00:38:15.208555: Current learning rate: 0.00944 
2025-06-16 00:39:01.311402: train_loss -0.509 
2025-06-16 00:39:01.312465: val_loss -0.5333 
2025-06-16 00:39:01.312987: Pseudo dice [0.6934, 0.8942, 0.8964, 0.8812] 
2025-06-16 00:39:01.313521: Epoch time: 46.11 s 
2025-06-16 00:39:01.314118: Yayy! New best EMA pseudo Dice: 0.8149 
2025-06-16 00:39:03.425903:  
2025-06-16 00:39:03.426546: Epoch 63 
2025-06-16 00:39:03.427151: Current learning rate: 0.00943 
2025-06-16 00:39:45.747870: train_loss -0.5116 
2025-06-16 00:39:45.748932: val_loss -0.5057 
2025-06-16 00:39:45.749663: Pseudo dice [0.4845, 0.8919, 0.8626, 0.8561] 
2025-06-16 00:39:45.750338: Epoch time: 42.32 s 
2025-06-16 00:39:48.931235:  
2025-06-16 00:39:48.931964: Epoch 64 
2025-06-16 00:39:48.932470: Current learning rate: 0.00942 
2025-06-16 00:40:44.508197: train_loss -0.5121 
2025-06-16 00:40:44.509681: val_loss -0.5304 
2025-06-16 00:40:44.510341: Pseudo dice [0.757, 0.8998, 0.8855, 0.8648] 
2025-06-16 00:40:44.510939: Epoch time: 55.58 s 
2025-06-16 00:40:45.962604:  
2025-06-16 00:40:45.963264: Epoch 65 
2025-06-16 00:40:45.964217: Current learning rate: 0.00941 
2025-06-16 00:41:27.503782: train_loss -0.5249 
2025-06-16 00:41:27.505073: val_loss -0.5321 
2025-06-16 00:41:27.513085: Pseudo dice [0.7163, 0.8921, 0.8873, 0.8894] 
2025-06-16 00:41:27.513541: Epoch time: 41.54 s 
2025-06-16 00:41:27.513916: Yayy! New best EMA pseudo Dice: 0.818 
2025-06-16 00:41:28.979960:  
2025-06-16 00:41:28.980568: Epoch 66 
2025-06-16 00:41:28.980957: Current learning rate: 0.0094 
2025-06-16 00:42:11.444400: train_loss -0.5216 
2025-06-16 00:42:11.445314: val_loss -0.5157 
2025-06-16 00:42:11.445959: Pseudo dice [0.7137, 0.9001, 0.8715, 0.881] 
2025-06-16 00:42:11.446414: Epoch time: 42.47 s 
2025-06-16 00:42:11.446787: Yayy! New best EMA pseudo Dice: 0.8204 
2025-06-16 00:42:13.674075:  
2025-06-16 00:42:13.674811: Epoch 67 
2025-06-16 00:42:13.675359: Current learning rate: 0.00939 
2025-06-16 00:43:11.595400: train_loss -0.5079 
2025-06-16 00:43:11.596287: val_loss -0.5372 
2025-06-16 00:43:11.596874: Pseudo dice [0.7383, 0.9043, 0.8937, 0.9026] 
2025-06-16 00:43:11.597320: Epoch time: 57.92 s 
2025-06-16 00:43:11.597696: Yayy! New best EMA pseudo Dice: 0.8243 
2025-06-16 00:43:14.250275:  
2025-06-16 00:43:14.251184: Epoch 68 
2025-06-16 00:43:14.251916: Current learning rate: 0.00939 
2025-06-16 00:43:55.780019: train_loss -0.5242 
2025-06-16 00:43:55.781020: val_loss -0.556 
2025-06-16 00:43:55.781608: Pseudo dice [0.6775, 0.9019, 0.8913, 0.8903] 
2025-06-16 00:43:55.782128: Epoch time: 41.53 s 
2025-06-16 00:43:55.782653: Yayy! New best EMA pseudo Dice: 0.8259 
2025-06-16 00:43:57.908159:  
2025-06-16 00:43:57.908856: Epoch 69 
2025-06-16 00:43:57.909298: Current learning rate: 0.00938 
2025-06-16 00:44:39.031609: train_loss -0.5106 
2025-06-16 00:44:39.032672: val_loss -0.5285 
2025-06-16 00:44:39.033417: Pseudo dice [0.7688, 0.8992, 0.8882, 0.92] 
2025-06-16 00:44:39.033966: Epoch time: 41.12 s 
2025-06-16 00:44:39.034634: Yayy! New best EMA pseudo Dice: 0.8302 
2025-06-16 00:44:41.044033:  
2025-06-16 00:44:41.044720: Epoch 70 
2025-06-16 00:44:41.045216: Current learning rate: 0.00937 
2025-06-16 00:45:40.421084: train_loss -0.5165 
2025-06-16 00:45:40.422577: val_loss -0.5304 
2025-06-16 00:45:40.423176: Pseudo dice [0.7318, 0.9045, 0.8803, 0.8644] 
2025-06-16 00:45:40.423731: Epoch time: 59.38 s 
2025-06-16 00:45:40.424146: Yayy! New best EMA pseudo Dice: 0.8317 
2025-06-16 00:45:43.317304:  
2025-06-16 00:45:43.317973: Epoch 71 
2025-06-16 00:45:43.318388: Current learning rate: 0.00936 
2025-06-16 00:46:27.953232: train_loss -0.5179 
2025-06-16 00:46:27.954089: val_loss -0.562 
2025-06-16 00:46:27.954515: Pseudo dice [0.7122, 0.9031, 0.8942, 0.8919] 
2025-06-16 00:46:27.955115: Epoch time: 44.64 s 
2025-06-16 00:46:27.955491: Yayy! New best EMA pseudo Dice: 0.8336 
2025-06-16 00:46:30.914280:  
2025-06-16 00:46:30.915076: Epoch 72 
2025-06-16 00:46:30.915496: Current learning rate: 0.00935 
2025-06-16 00:47:11.290837: train_loss -0.5132 
2025-06-16 00:47:11.291845: val_loss -0.5259 
2025-06-16 00:47:11.292400: Pseudo dice [0.7235, 0.8958, 0.8908, 0.8891] 
2025-06-16 00:47:11.293082: Epoch time: 40.38 s 
2025-06-16 00:47:11.293577: Yayy! New best EMA pseudo Dice: 0.8352 
2025-06-16 00:47:13.433079:  
2025-06-16 00:47:13.433867: Epoch 73 
2025-06-16 00:47:13.434338: Current learning rate: 0.00934 
2025-06-16 00:48:11.691221: train_loss -0.5322 
2025-06-16 00:48:11.692074: val_loss -0.5171 
2025-06-16 00:48:11.692518: Pseudo dice [0.5269, 0.8829, 0.8617, 0.9143] 
2025-06-16 00:48:11.693112: Epoch time: 58.26 s 
2025-06-16 00:48:13.444948:  
2025-06-16 00:48:13.445565: Epoch 74 
2025-06-16 00:48:13.445941: Current learning rate: 0.00933 
2025-06-16 00:49:05.002257: train_loss -0.5275 
2025-06-16 00:49:05.008858: val_loss -0.5355 
2025-06-16 00:49:05.009596: Pseudo dice [0.7271, 0.9004, 0.8856, 0.8787] 
2025-06-16 00:49:05.010238: Epoch time: 51.56 s 
2025-06-16 00:49:07.087601:  
2025-06-16 00:49:07.088452: Epoch 75 
2025-06-16 00:49:07.088941: Current learning rate: 0.00932 
2025-06-16 00:50:03.545027: train_loss -0.5175 
2025-06-16 00:50:03.546240: val_loss -0.5598 
2025-06-16 00:50:03.546834: Pseudo dice [0.7645, 0.9099, 0.8987, 0.8793] 
2025-06-16 00:50:03.547443: Epoch time: 56.46 s 
2025-06-16 00:50:03.547956: Yayy! New best EMA pseudo Dice: 0.836 
2025-06-16 00:50:06.112591:  
2025-06-16 00:50:06.113307: Epoch 76 
2025-06-16 00:50:06.113783: Current learning rate: 0.00931 
2025-06-16 00:50:56.938409: train_loss -0.52 
2025-06-16 00:50:56.939196: val_loss -0.5607 
2025-06-16 00:50:56.939786: Pseudo dice [0.7243, 0.9103, 0.9081, 0.8489] 
2025-06-16 00:50:56.940169: Epoch time: 50.83 s 
2025-06-16 00:50:56.940470: Yayy! New best EMA pseudo Dice: 0.8372 
2025-06-16 00:50:58.683391:  
2025-06-16 00:50:58.684138: Epoch 77 
2025-06-16 00:50:58.684519: Current learning rate: 0.0093 
2025-06-16 00:51:39.837400: train_loss -0.5202 
2025-06-16 00:51:39.838420: val_loss -0.5451 
2025-06-16 00:51:39.838893: Pseudo dice [0.5242, 0.8999, 0.8936, 0.8942] 
2025-06-16 00:51:39.839858: Epoch time: 41.15 s 
2025-06-16 00:51:41.669841:  
2025-06-16 00:51:41.670584: Epoch 78 
2025-06-16 00:51:41.671146: Current learning rate: 0.0093 
2025-06-16 00:52:42.792289: train_loss -0.5303 
2025-06-16 00:52:42.793069: val_loss -0.5736 
2025-06-16 00:52:42.793524: Pseudo dice [0.7572, 0.9166, 0.8866, 0.8309] 
2025-06-16 00:52:42.794059: Epoch time: 61.12 s 
2025-06-16 00:52:46.028186:  
2025-06-16 00:52:46.029242: Epoch 79 
2025-06-16 00:52:46.029654: Current learning rate: 0.00929 
2025-06-16 00:53:31.400728: train_loss -0.5209 
2025-06-16 00:53:31.402629: val_loss -0.5519 
2025-06-16 00:53:31.403361: Pseudo dice [0.4786, 0.9102, 0.8557, 0.885] 
2025-06-16 00:53:31.404152: Epoch time: 45.37 s 
2025-06-16 00:53:33.197007:  
2025-06-16 00:53:33.197695: Epoch 80 
2025-06-16 00:53:33.198425: Current learning rate: 0.00928 
2025-06-16 00:54:28.415778: train_loss -0.521 
2025-06-16 00:54:28.416950: val_loss -0.5404 
2025-06-16 00:54:28.417637: Pseudo dice [0.7203, 0.9018, 0.8756, 0.8721] 
2025-06-16 00:54:28.418488: Epoch time: 55.22 s 
2025-06-16 00:54:30.622345:  
2025-06-16 00:54:30.623359: Epoch 81 
2025-06-16 00:54:30.624163: Current learning rate: 0.00927 
2025-06-16 00:55:24.351288: train_loss -0.5277 
2025-06-16 00:55:24.352634: val_loss -0.5296 
2025-06-16 00:55:24.353282: Pseudo dice [0.6602, 0.8974, 0.8933, 0.8597] 
2025-06-16 00:55:24.353753: Epoch time: 53.73 s 
2025-06-16 00:55:25.955276:  
2025-06-16 00:55:25.955928: Epoch 82 
2025-06-16 00:55:25.956306: Current learning rate: 0.00926 
2025-06-16 00:56:09.815921: train_loss -0.5273 
2025-06-16 00:56:09.816852: val_loss -0.5617 
2025-06-16 00:56:09.817317: Pseudo dice [0.7864, 0.9097, 0.9139, 0.9121] 
2025-06-16 00:56:09.817926: Epoch time: 43.86 s 
2025-06-16 00:56:11.738683:  
2025-06-16 00:56:11.739569: Epoch 83 
2025-06-16 00:56:11.740083: Current learning rate: 0.00925 
2025-06-16 00:57:15.451444: train_loss -0.5396 
2025-06-16 00:57:15.452261: val_loss -0.5218 
2025-06-16 00:57:15.452833: Pseudo dice [0.6465, 0.8778, 0.8741, 0.8895] 
2025-06-16 00:57:15.453259: Epoch time: 63.71 s 
2025-06-16 00:57:17.226507:  
2025-06-16 00:57:17.227082: Epoch 84 
2025-06-16 00:57:17.227487: Current learning rate: 0.00924 
2025-06-16 00:58:04.530553: train_loss -0.526 
2025-06-16 00:58:04.532118: val_loss -0.5046 
2025-06-16 00:58:04.532972: Pseudo dice [0.7388, 0.8895, 0.8879, 0.895] 
2025-06-16 00:58:04.534325: Epoch time: 47.31 s 
2025-06-16 00:58:06.468915:  
2025-06-16 00:58:06.469718: Epoch 85 
2025-06-16 00:58:06.470472: Current learning rate: 0.00923 
2025-06-16 00:59:07.600664: train_loss -0.5402 
2025-06-16 00:59:07.607508: val_loss -0.5592 
2025-06-16 00:59:07.608292: Pseudo dice [0.6822, 0.9032, 0.898, 0.8543] 
2025-06-16 00:59:07.609294: Epoch time: 61.13 s 
2025-06-16 00:59:10.889410:  
2025-06-16 00:59:10.890409: Epoch 86 
2025-06-16 00:59:10.891192: Current learning rate: 0.00922 
2025-06-16 00:59:56.264806: train_loss -0.5424 
2025-06-16 00:59:56.343969: val_loss -0.5504 
2025-06-16 00:59:56.344667: Pseudo dice [0.7835, 0.9182, 0.8994, 0.898] 
2025-06-16 00:59:56.362454: Epoch time: 45.38 s 
2025-06-16 00:59:56.368889: Yayy! New best EMA pseudo Dice: 0.8399 
2025-06-16 00:59:59.489681:  
2025-06-16 00:59:59.490299: Epoch 87 
2025-06-16 00:59:59.490718: Current learning rate: 0.00921 
2025-06-16 01:00:45.283520: train_loss -0.5204 
2025-06-16 01:00:45.284940: val_loss -0.5448 
2025-06-16 01:00:45.285483: Pseudo dice [0.7004, 0.9054, 0.8824, 0.8835] 
2025-06-16 01:00:45.286228: Epoch time: 45.8 s 
2025-06-16 01:00:45.286657: Yayy! New best EMA pseudo Dice: 0.8402 
2025-06-16 01:00:47.215699:  
2025-06-16 01:00:47.216398: Epoch 88 
2025-06-16 01:00:47.216903: Current learning rate: 0.0092 
2025-06-16 01:01:44.685172: train_loss -0.5356 
2025-06-16 01:01:44.697647: val_loss -0.5434 
2025-06-16 01:01:44.698091: Pseudo dice [0.788, 0.9097, 0.9107, 0.8747] 
2025-06-16 01:01:44.698465: Epoch time: 57.45 s 
2025-06-16 01:01:44.698770: Yayy! New best EMA pseudo Dice: 0.8433 
2025-06-16 01:01:46.957790:  
2025-06-16 01:01:46.958476: Epoch 89 
2025-06-16 01:01:46.958865: Current learning rate: 0.0092 
2025-06-16 01:02:30.460084: train_loss -0.5128 
2025-06-16 01:02:30.461125: val_loss -0.5499 
2025-06-16 01:02:30.461793: Pseudo dice [0.681, 0.8993, 0.8774, 0.8536] 
2025-06-16 01:02:30.462610: Epoch time: 43.5 s 
2025-06-16 01:02:32.086684:  
2025-06-16 01:02:32.087505: Epoch 90 
2025-06-16 01:02:32.088054: Current learning rate: 0.00919 
2025-06-16 01:03:31.199718: train_loss -0.5304 
2025-06-16 01:03:31.200547: val_loss -0.5896 
2025-06-16 01:03:31.201123: Pseudo dice [0.6402, 0.9057, 0.8869, 0.9052] 
2025-06-16 01:03:31.201538: Epoch time: 59.11 s 
2025-06-16 01:03:33.629862:  
2025-06-16 01:03:33.630431: Epoch 91 
2025-06-16 01:03:33.631027: Current learning rate: 0.00918 
2025-06-16 01:04:27.089665: train_loss -0.5379 
2025-06-16 01:04:27.090938: val_loss -0.5184 
2025-06-16 01:04:27.091626: Pseudo dice [0.6848, 0.9029, 0.9008, 0.8532] 
2025-06-16 01:04:27.092560: Epoch time: 53.46 s 
2025-06-16 01:04:28.762219:  
2025-06-16 01:04:28.763104: Epoch 92 
2025-06-16 01:04:28.763799: Current learning rate: 0.00917 
2025-06-16 01:05:29.016941: train_loss -0.5245 
2025-06-16 01:05:29.018413: val_loss -0.55 
2025-06-16 01:05:29.019413: Pseudo dice [0.7963, 0.9096, 0.888, 0.895] 
2025-06-16 01:05:29.020455: Epoch time: 60.26 s 
2025-06-16 01:05:29.021066: Yayy! New best EMA pseudo Dice: 0.8436 
2025-06-16 01:05:37.135325:  
2025-06-16 01:05:37.136312: Epoch 93 
2025-06-16 01:05:37.136831: Current learning rate: 0.00916 
2025-06-16 01:06:28.353306: train_loss -0.5328 
2025-06-16 01:06:28.369607: val_loss -0.5579 
2025-06-16 01:06:28.370090: Pseudo dice [0.6448, 0.9075, 0.8985, 0.8982] 
2025-06-16 01:06:28.370497: Epoch time: 51.22 s 
2025-06-16 01:06:29.935493:  
2025-06-16 01:06:29.936102: Epoch 94 
2025-06-16 01:06:29.936518: Current learning rate: 0.00915 
2025-06-16 01:07:19.737737: train_loss -0.5409 
2025-06-16 01:07:19.739033: val_loss -0.5343 
2025-06-16 01:07:19.739873: Pseudo dice [0.7863, 0.9, 0.9067, 0.9033] 
2025-06-16 01:07:19.740590: Epoch time: 49.8 s 
2025-06-16 01:07:19.741243: Yayy! New best EMA pseudo Dice: 0.8461 
2025-06-16 01:07:21.681604:  
2025-06-16 01:07:21.682308: Epoch 95 
2025-06-16 01:07:21.682773: Current learning rate: 0.00914 
2025-06-16 01:08:24.204521: train_loss -0.5354 
2025-06-16 01:08:24.209239: val_loss -0.5477 
2025-06-16 01:08:24.210022: Pseudo dice [0.6532, 0.8927, 0.9073, 0.8703] 
2025-06-16 01:08:24.211267: Epoch time: 62.49 s 
2025-06-16 01:08:26.600832:  
2025-06-16 01:08:26.601638: Epoch 96 
2025-06-16 01:08:26.602055: Current learning rate: 0.00913 
2025-06-16 01:09:07.483308: train_loss -0.54 
2025-06-16 01:09:07.484326: val_loss -0.5285 
2025-06-16 01:09:07.484843: Pseudo dice [0.7455, 0.9065, 0.8899, 0.8738] 
2025-06-16 01:09:07.485362: Epoch time: 40.88 s 
2025-06-16 01:09:09.220788:  
2025-06-16 01:09:09.221419: Epoch 97 
2025-06-16 01:09:09.221869: Current learning rate: 0.00912 
2025-06-16 01:09:57.700258: train_loss -0.5112 
2025-06-16 01:09:57.701257: val_loss -0.5369 
2025-06-16 01:09:57.701854: Pseudo dice [0.7029, 0.9057, 0.8833, 0.9102] 
2025-06-16 01:09:57.702630: Epoch time: 48.48 s 
2025-06-16 01:09:59.464912:  
2025-06-16 01:09:59.465629: Epoch 98 
2025-06-16 01:09:59.466175: Current learning rate: 0.00911 
2025-06-16 01:11:03.140534: train_loss -0.5366 
2025-06-16 01:11:03.218011: val_loss -0.5464 
2025-06-16 01:11:03.219042: Pseudo dice [0.6649, 0.9101, 0.8836, 0.9101] 
2025-06-16 01:11:03.235778: Epoch time: 63.68 s 
2025-06-16 01:11:05.262749:  
2025-06-16 01:11:05.263380: Epoch 99 
2025-06-16 01:11:05.263786: Current learning rate: 0.0091 
2025-06-16 01:11:55.324925: train_loss -0.5418 
2025-06-16 01:11:55.325932: val_loss -0.5385 
2025-06-16 01:11:55.326836: Pseudo dice [0.6688, 0.9128, 0.8975, 0.8847] 
2025-06-16 01:11:55.327728: Epoch time: 50.06 s 
2025-06-16 01:11:58.933206:  
2025-06-16 01:11:58.933894: Epoch 100 
2025-06-16 01:11:58.934472: Current learning rate: 0.0091 
2025-06-16 01:13:01.608392: train_loss -0.543 
2025-06-16 01:13:01.609112: val_loss -0.5627 
2025-06-16 01:13:01.609516: Pseudo dice [0.6097, 0.8837, 0.8801, 0.8349] 
2025-06-16 01:13:01.610042: Epoch time: 62.68 s 
2025-06-16 01:13:05.286711:  
2025-06-16 01:13:05.287335: Epoch 101 
2025-06-16 01:13:05.287832: Current learning rate: 0.00909 
2025-06-16 01:13:51.265119: train_loss -0.572 
2025-06-16 01:13:51.301554: val_loss -0.5634 
2025-06-16 01:13:51.302848: Pseudo dice [0.69, 0.8902, 0.8886, 0.8914] 
2025-06-16 01:13:51.304405: Epoch time: 45.95 s 
2025-06-16 01:13:53.307037:  
2025-06-16 01:13:53.307748: Epoch 102 
2025-06-16 01:13:53.308186: Current learning rate: 0.00908 
2025-06-16 01:14:36.533659: train_loss -0.5458 
2025-06-16 01:14:36.534770: val_loss -0.5787 
2025-06-16 01:14:36.535258: Pseudo dice [0.6912, 0.8852, 0.8827, 0.8871] 
2025-06-16 01:14:36.536135: Epoch time: 43.23 s 
2025-06-16 01:14:38.310718:  
2025-06-16 01:14:38.311404: Epoch 103 
2025-06-16 01:14:38.311796: Current learning rate: 0.00907 
2025-06-16 01:15:42.211402: train_loss -0.5457 
2025-06-16 01:15:42.212252: val_loss -0.5625 
2025-06-16 01:15:42.212805: Pseudo dice [0.7702, 0.8959, 0.9001, 0.882] 
2025-06-16 01:15:42.213247: Epoch time: 63.9 s 
2025-06-16 01:15:44.515293:  
2025-06-16 01:15:44.515864: Epoch 104 
2025-06-16 01:15:44.516266: Current learning rate: 0.00906 
2025-06-16 01:16:37.059912: train_loss -0.5559 
2025-06-16 01:16:37.061414: val_loss -0.5804 
2025-06-16 01:16:37.061877: Pseudo dice [0.7143, 0.9076, 0.878, 0.8999] 
2025-06-16 01:16:37.062308: Epoch time: 52.55 s 
2025-06-16 01:16:38.679492:  
2025-06-16 01:16:38.680151: Epoch 105 
2025-06-16 01:16:38.680591: Current learning rate: 0.00905 
2025-06-16 01:17:33.589845: train_loss -0.559 
2025-06-16 01:17:33.590736: val_loss -0.5955 
2025-06-16 01:17:33.591232: Pseudo dice [0.6686, 0.9075, 0.8855, 0.8994] 
2025-06-16 01:17:33.591829: Epoch time: 54.91 s 
2025-06-16 01:17:34.875849:  
2025-06-16 01:17:34.876454: Epoch 106 
2025-06-16 01:17:34.876983: Current learning rate: 0.00904 
2025-06-16 01:18:24.379534: train_loss -0.5554 
2025-06-16 01:18:24.457450: val_loss -0.581 
2025-06-16 01:18:24.458328: Pseudo dice [0.7588, 0.8974, 0.8878, 0.8328] 
2025-06-16 01:18:24.473959: Epoch time: 49.5 s 
2025-06-16 01:18:26.582549:  
2025-06-16 01:18:26.583161: Epoch 107 
2025-06-16 01:18:26.583565: Current learning rate: 0.00903 
2025-06-16 01:19:15.017353: train_loss -0.5568 
2025-06-16 01:19:15.066840: val_loss -0.5633 
2025-06-16 01:19:15.068128: Pseudo dice [0.7818, 0.9027, 0.9034, 0.8915] 
2025-06-16 01:19:15.074658: Epoch time: 48.41 s 
2025-06-16 01:19:19.184478:  
2025-06-16 01:19:19.185234: Epoch 108 
2025-06-16 01:19:19.185666: Current learning rate: 0.00902 
2025-06-16 01:20:01.659412: train_loss -0.5585 
2025-06-16 01:20:01.660729: val_loss -0.567 
2025-06-16 01:20:01.661412: Pseudo dice [0.6901, 0.9021, 0.9065, 0.8783] 
2025-06-16 01:20:01.662079: Epoch time: 42.48 s 
2025-06-16 01:20:03.370324:  
2025-06-16 01:20:03.371068: Epoch 109 
2025-06-16 01:20:03.371920: Current learning rate: 0.00901 
2025-06-16 01:21:05.739444: train_loss -0.5546 
2025-06-16 01:21:05.740326: val_loss -0.5957 
2025-06-16 01:21:05.740887: Pseudo dice [0.7468, 0.9177, 0.9181, 0.901] 
2025-06-16 01:21:05.741641: Epoch time: 62.37 s 
2025-06-16 01:21:05.742129: Yayy! New best EMA pseudo Dice: 0.8481 
2025-06-16 01:21:08.594481:  
2025-06-16 01:21:08.595116: Epoch 110 
2025-06-16 01:21:08.595612: Current learning rate: 0.009 
2025-06-16 01:21:59.072280: train_loss -0.5618 
2025-06-16 01:21:59.073134: val_loss -0.5379 
2025-06-16 01:21:59.073560: Pseudo dice [0.4527, 0.8958, 0.882, 0.8529] 
2025-06-16 01:21:59.073949: Epoch time: 50.48 s 
2025-06-16 01:22:01.337255:  
2025-06-16 01:22:01.337861: Epoch 111 
2025-06-16 01:22:01.338281: Current learning rate: 0.009 
2025-06-16 01:22:44.025359: train_loss -0.5522 
2025-06-16 01:22:44.026182: val_loss -0.5726 
2025-06-16 01:22:44.026809: Pseudo dice [0.8132, 0.9031, 0.8933, 0.8901] 
2025-06-16 01:22:44.027705: Epoch time: 42.69 s 
2025-06-16 01:22:45.605464:  
2025-06-16 01:22:45.606123: Epoch 112 
2025-06-16 01:22:45.606583: Current learning rate: 0.00899 
2025-06-16 01:23:27.977562: train_loss -0.5561 
2025-06-16 01:23:27.978806: val_loss -0.576 
2025-06-16 01:23:27.979776: Pseudo dice [0.6339, 0.9011, 0.8652, 0.8771] 
2025-06-16 01:23:27.980687: Epoch time: 42.37 s 
2025-06-16 01:23:29.757502:  
2025-06-16 01:23:29.758223: Epoch 113 
2025-06-16 01:23:29.758634: Current learning rate: 0.00898 
2025-06-16 01:24:25.679825: train_loss -0.5699 
2025-06-16 01:24:25.680778: val_loss -0.5753 
2025-06-16 01:24:25.681282: Pseudo dice [0.7502, 0.8913, 0.9051, 0.9326] 
2025-06-16 01:24:25.681905: Epoch time: 55.92 s 
2025-06-16 01:24:27.627869:  
2025-06-16 01:24:27.628522: Epoch 114 
2025-06-16 01:24:27.629125: Current learning rate: 0.00897 
2025-06-16 01:25:15.887119: train_loss -0.5653 
2025-06-16 01:25:15.888036: val_loss -0.5898 
2025-06-16 01:25:15.888544: Pseudo dice [0.5887, 0.8916, 0.8541, 0.8911] 
2025-06-16 01:25:15.889158: Epoch time: 48.26 s 
2025-06-16 01:25:17.650672:  
2025-06-16 01:25:17.651315: Epoch 115 
2025-06-16 01:25:17.651792: Current learning rate: 0.00896 
2025-06-16 01:26:23.251702: train_loss -0.5585 
2025-06-16 01:26:23.253089: val_loss -0.5699 
2025-06-16 01:26:23.253980: Pseudo dice [0.7246, 0.8793, 0.8869, 0.8562] 
2025-06-16 01:26:23.254768: Epoch time: 65.6 s 
2025-06-16 01:26:27.217088:  
2025-06-16 01:26:27.217760: Epoch 116 
2025-06-16 01:26:27.218202: Current learning rate: 0.00895 
2025-06-16 01:27:15.880161: train_loss -0.5637 
2025-06-16 01:27:16.255795: val_loss -0.5755 
2025-06-16 01:27:16.256436: Pseudo dice [0.7268, 0.905, 0.8932, 0.8951] 
2025-06-16 01:27:16.271350: Epoch time: 48.66 s 
2025-06-16 01:27:18.836385:  
2025-06-16 01:27:18.837211: Epoch 117 
2025-06-16 01:27:18.837645: Current learning rate: 0.00894 
2025-06-16 01:28:22.090124: train_loss -0.5717 
2025-06-16 01:28:22.091381: val_loss -0.5623 
2025-06-16 01:28:22.092415: Pseudo dice [0.7228, 0.9052, 0.8863, 0.8715] 
2025-06-16 01:28:22.093202: Epoch time: 63.25 s 
2025-06-16 01:28:24.059693:  
2025-06-16 01:28:24.060597: Epoch 118 
2025-06-16 01:28:24.061195: Current learning rate: 0.00893 
2025-06-16 01:29:17.890362: train_loss -0.5737 
2025-06-16 01:29:17.894845: val_loss -0.5787 
2025-06-16 01:29:17.895667: Pseudo dice [0.7599, 0.9043, 0.8997, 0.8837] 
2025-06-16 01:29:17.897304: Epoch time: 53.77 s 
2025-06-16 01:29:19.778039:  
2025-06-16 01:29:19.778882: Epoch 119 
2025-06-16 01:29:19.779292: Current learning rate: 0.00892 
2025-06-16 01:30:04.342788: train_loss -0.5593 
2025-06-16 01:30:04.343832: val_loss -0.5997 
2025-06-16 01:30:04.344721: Pseudo dice [0.7267, 0.9031, 0.8795, 0.9108] 
2025-06-16 01:30:04.345384: Epoch time: 44.57 s 
2025-06-16 01:30:06.082550:  
2025-06-16 01:30:06.083151: Epoch 120 
2025-06-16 01:30:06.083571: Current learning rate: 0.00891 
2025-06-16 01:31:07.750816: train_loss -0.5624 
2025-06-16 01:31:07.751677: val_loss -0.6059 
2025-06-16 01:31:07.752242: Pseudo dice [0.7587, 0.9097, 0.8936, 0.9069] 
2025-06-16 01:31:07.752702: Epoch time: 61.67 s 
2025-06-16 01:31:09.371243:  
2025-06-16 01:31:09.371860: Epoch 121 
2025-06-16 01:31:09.372279: Current learning rate: 0.0089 
2025-06-16 01:31:55.052907: train_loss -0.5525 
2025-06-16 01:31:55.053793: val_loss -0.5828 
2025-06-16 01:31:55.054393: Pseudo dice [0.5938, 0.9067, 0.8749, 0.89] 
2025-06-16 01:31:55.055088: Epoch time: 45.68 s 
2025-06-16 01:31:57.055484:  
2025-06-16 01:31:57.056426: Epoch 122 
2025-06-16 01:31:57.056916: Current learning rate: 0.00889 
2025-06-16 01:32:59.723945: train_loss -0.5732 
2025-06-16 01:32:59.724766: val_loss -0.5812 
2025-06-16 01:32:59.725193: Pseudo dice [0.5248, 0.9127, 0.8978, 0.9002] 
2025-06-16 01:32:59.725609: Epoch time: 62.67 s 
2025-06-16 01:33:02.856209:  
2025-06-16 01:33:02.856826: Epoch 123 
2025-06-16 01:33:02.857422: Current learning rate: 0.00889 
2025-06-16 01:33:51.554861: train_loss -0.5629 
2025-06-16 01:33:51.555752: val_loss -0.5664 
2025-06-16 01:33:51.556188: Pseudo dice [0.7441, 0.8987, 0.8802, 0.898] 
2025-06-16 01:33:51.556629: Epoch time: 48.7 s 
2025-06-16 01:33:53.117306:  
2025-06-16 01:33:53.118386: Epoch 124 
2025-06-16 01:33:53.119232: Current learning rate: 0.00888 
2025-06-16 01:34:31.490965: train_loss -0.567 
2025-06-16 01:34:31.491778: val_loss -0.6057 
2025-06-16 01:34:31.492338: Pseudo dice [0.8172, 0.9113, 0.9115, 0.8747] 
2025-06-16 01:34:31.492849: Epoch time: 38.37 s 
2025-06-16 01:34:33.190633:  
2025-06-16 01:34:33.191300: Epoch 125 
2025-06-16 01:34:33.191782: Current learning rate: 0.00887 
2025-06-16 01:35:20.539186: train_loss -0.575 
2025-06-16 01:35:20.540486: val_loss -0.577 
2025-06-16 01:35:20.541291: Pseudo dice [0.5202, 0.9063, 0.87, 0.9045] 
2025-06-16 01:35:20.542202: Epoch time: 47.35 s 
2025-06-16 01:35:22.473905:  
2025-06-16 01:35:22.474548: Epoch 126 
2025-06-16 01:35:22.475082: Current learning rate: 0.00886 
2025-06-16 01:36:25.442094: train_loss -0.5642 
2025-06-16 01:36:25.477688: val_loss -0.5674 
2025-06-16 01:36:25.478381: Pseudo dice [0.5915, 0.904, 0.8753, 0.8946] 
2025-06-16 01:36:25.479442: Epoch time: 62.94 s 
2025-06-16 01:36:28.349565:  
2025-06-16 01:36:28.350228: Epoch 127 
2025-06-16 01:36:28.350682: Current learning rate: 0.00885 
2025-06-16 01:37:08.096971: train_loss -0.5641 
2025-06-16 01:37:08.098013: val_loss -0.562 
2025-06-16 01:37:08.099059: Pseudo dice [0.7492, 0.9064, 0.8945, 0.8582] 
2025-06-16 01:37:08.099996: Epoch time: 39.75 s 
2025-06-16 01:37:09.749925:  
2025-06-16 01:37:09.750559: Epoch 128 
2025-06-16 01:37:09.751018: Current learning rate: 0.00884 
2025-06-16 01:37:50.319861: train_loss -0.549 
2025-06-16 01:37:50.320703: val_loss -0.5937 
2025-06-16 01:37:50.321377: Pseudo dice [0.6223, 0.9074, 0.8993, 0.8854] 
2025-06-16 01:37:50.321938: Epoch time: 40.57 s 
2025-06-16 01:37:52.050994:  
2025-06-16 01:37:52.051714: Epoch 129 
2025-06-16 01:37:52.052403: Current learning rate: 0.00883 
2025-06-16 01:38:52.344000: train_loss -0.5605 
2025-06-16 01:38:52.344788: val_loss -0.5892 
2025-06-16 01:38:52.345196: Pseudo dice [0.6534, 0.8942, 0.895, 0.8913] 
2025-06-16 01:38:52.345595: Epoch time: 60.29 s 
2025-06-16 01:38:54.045283:  
2025-06-16 01:38:54.045935: Epoch 130 
2025-06-16 01:38:54.046387: Current learning rate: 0.00882 
2025-06-16 01:39:46.627518: train_loss -0.5705 
2025-06-16 01:39:46.690539: val_loss -0.5795 
2025-06-16 01:39:46.691202: Pseudo dice [0.6647, 0.9113, 0.8998, 0.9088] 
2025-06-16 01:39:46.704612: Epoch time: 52.58 s 
2025-06-16 01:39:53.410773:  
2025-06-16 01:39:53.411602: Epoch 131 
2025-06-16 01:39:53.412166: Current learning rate: 0.00881 
2025-06-16 01:40:59.026134: train_loss -0.5519 
2025-06-16 01:40:59.027143: val_loss -0.608 
2025-06-16 01:40:59.028100: Pseudo dice [0.7334, 0.902, 0.8917, 0.8936] 
2025-06-16 01:40:59.029086: Epoch time: 65.62 s 
2025-06-16 01:41:00.937943:  
2025-06-16 01:41:00.938629: Epoch 132 
2025-06-16 01:41:00.939118: Current learning rate: 0.0088 
2025-06-16 01:41:57.407683: train_loss -0.5583 
2025-06-16 01:41:57.409017: val_loss -0.5802 
2025-06-16 01:41:57.409739: Pseudo dice [0.7662, 0.9009, 0.8769, 0.8716] 
2025-06-16 01:41:57.410537: Epoch time: 56.47 s 
2025-06-16 01:41:59.830366:  
2025-06-16 01:41:59.831024: Epoch 133 
2025-06-16 01:41:59.831459: Current learning rate: 0.00879 
2025-06-16 01:42:44.921309: train_loss -0.5563 
2025-06-16 01:42:44.922342: val_loss -0.5636 
2025-06-16 01:42:44.922948: Pseudo dice [0.7161, 0.9075, 0.8387, 0.9167] 
2025-06-16 01:42:44.923964: Epoch time: 45.09 s 
2025-06-16 01:42:46.817878:  
2025-06-16 01:42:46.818642: Epoch 134 
2025-06-16 01:42:46.819228: Current learning rate: 0.00879 
2025-06-16 01:43:50.613758: train_loss -0.5519 
2025-06-16 01:43:50.614613: val_loss -0.5736 
2025-06-16 01:43:50.615119: Pseudo dice [0.7752, 0.9004, 0.8831, 0.9125] 
2025-06-16 01:43:50.615619: Epoch time: 63.8 s 
2025-06-16 01:43:52.488213:  
2025-06-16 01:43:52.488911: Epoch 135 
2025-06-16 01:43:52.489336: Current learning rate: 0.00878 
2025-06-16 01:44:52.004655: train_loss -0.5795 
2025-06-16 01:44:52.100530: val_loss -0.6089 
2025-06-16 01:44:52.101788: Pseudo dice [0.822, 0.9294, 0.9225, 0.9042] 
2025-06-16 01:44:52.124811: Epoch time: 59.49 s 
2025-06-16 01:44:52.126399: Yayy! New best EMA pseudo Dice: 0.8499 
2025-06-16 01:44:55.745349:  
2025-06-16 01:44:55.745972: Epoch 136 
2025-06-16 01:44:55.746381: Current learning rate: 0.00877 
2025-06-16 01:45:38.153818: train_loss -0.5708 
2025-06-16 01:45:38.154707: val_loss -0.6126 
2025-06-16 01:45:38.155181: Pseudo dice [0.7559, 0.908, 0.9007, 0.8979] 
2025-06-16 01:45:38.155853: Epoch time: 42.41 s 
2025-06-16 01:45:38.156318: Yayy! New best EMA pseudo Dice: 0.8514 
2025-06-16 01:45:40.403990:  
2025-06-16 01:45:40.404640: Epoch 137 
2025-06-16 01:45:40.405391: Current learning rate: 0.00876 
2025-06-16 01:46:32.855448: train_loss -0.5611 
2025-06-16 01:46:32.857232: val_loss -0.5992 
2025-06-16 01:46:32.858121: Pseudo dice [0.7091, 0.9113, 0.9183, 0.8934] 
2025-06-16 01:46:32.859132: Epoch time: 52.45 s 
2025-06-16 01:46:32.860035: Yayy! New best EMA pseudo Dice: 0.8521 
2025-06-16 01:46:42.595184:  
2025-06-16 01:46:42.595958: Epoch 138 
2025-06-16 01:46:42.596742: Current learning rate: 0.00875 
2025-06-16 01:47:46.179922: train_loss -0.5778 
2025-06-16 01:47:46.181242: val_loss -0.572 
2025-06-16 01:47:46.181736: Pseudo dice [0.6496, 0.9152, 0.8347, 0.8793] 
2025-06-16 01:47:46.182112: Epoch time: 63.59 s 
2025-06-16 01:47:48.460497:  
2025-06-16 01:47:48.461032: Epoch 139 
2025-06-16 01:47:48.461483: Current learning rate: 0.00874 
2025-06-16 01:48:45.633003: train_loss -0.5697 
2025-06-16 01:48:45.633929: val_loss -0.572 
2025-06-16 01:48:45.634415: Pseudo dice [0.6315, 0.9174, 0.875, 0.8631] 
2025-06-16 01:48:45.635156: Epoch time: 57.17 s 
2025-06-16 01:48:47.414313:  
2025-06-16 01:48:47.415041: Epoch 140 
2025-06-16 01:48:47.415482: Current learning rate: 0.00873 
2025-06-16 01:49:49.804916: train_loss -0.5747 
2025-06-16 01:49:49.805653: val_loss -0.5615 
2025-06-16 01:49:49.806030: Pseudo dice [0.6574, 0.9064, 0.8686, 0.8666] 
2025-06-16 01:49:49.806381: Epoch time: 62.39 s 
2025-06-16 01:49:51.807816:  
2025-06-16 01:49:51.808421: Epoch 141 
2025-06-16 01:49:51.808840: Current learning rate: 0.00872 
2025-06-16 01:50:36.605570: train_loss -0.5616 
2025-06-16 01:50:36.606605: val_loss -0.5951 
2025-06-16 01:50:36.607194: Pseudo dice [0.7397, 0.9065, 0.8913, 0.8833] 
2025-06-16 01:50:36.607682: Epoch time: 44.8 s 
2025-06-16 01:50:38.472696:  
2025-06-16 01:50:38.473380: Epoch 142 
2025-06-16 01:50:38.473836: Current learning rate: 0.00871 
2025-06-16 01:51:43.938939: train_loss -0.5621 
2025-06-16 01:51:43.940125: val_loss -0.5313 
2025-06-16 01:51:43.940802: Pseudo dice [0.6301, 0.8969, 0.8777, 0.8691] 
2025-06-16 01:51:43.941678: Epoch time: 65.47 s 
2025-06-16 01:51:45.896279:  
2025-06-16 01:51:45.896913: Epoch 143 
2025-06-16 01:51:45.897338: Current learning rate: 0.0087 
2025-06-16 01:52:33.432975: train_loss -0.5637 
2025-06-16 01:52:33.505845: val_loss -0.5862 
2025-06-16 01:52:33.507141: Pseudo dice [0.706, 0.9154, 0.9008, 0.9065] 
2025-06-16 01:52:33.521631: Epoch time: 47.51 s 
2025-06-16 01:52:35.890631:  
2025-06-16 01:52:35.891436: Epoch 144 
2025-06-16 01:52:35.891844: Current learning rate: 0.00869 
2025-06-16 01:53:14.471292: train_loss -0.5653 
2025-06-16 01:53:14.472114: val_loss -0.5843 
2025-06-16 01:53:14.472545: Pseudo dice [0.6324, 0.9032, 0.9026, 0.8994] 
2025-06-16 01:53:14.473091: Epoch time: 38.58 s 
2025-06-16 01:53:18.945017:  
2025-06-16 01:53:18.946010: Epoch 145 
2025-06-16 01:53:18.946533: Current learning rate: 0.00868 
2025-06-16 01:54:12.543208: train_loss -0.5789 
2025-06-16 01:54:12.544161: val_loss -0.585 
2025-06-16 01:54:12.544788: Pseudo dice [0.7818, 0.8923, 0.8651, 0.9058] 
2025-06-16 01:54:12.545308: Epoch time: 53.6 s 
2025-06-16 01:54:14.463590:  
2025-06-16 01:54:14.464777: Epoch 146 
2025-06-16 01:54:14.465447: Current learning rate: 0.00868 
2025-06-16 01:55:16.239676: train_loss -0.5604 
2025-06-16 01:55:16.240658: val_loss -0.5903 
2025-06-16 01:55:16.241200: Pseudo dice [0.7481, 0.9041, 0.8668, 0.8927] 
2025-06-16 01:55:16.241872: Epoch time: 61.78 s 
2025-06-16 01:55:18.854113:  
2025-06-16 01:55:18.854816: Epoch 147 
2025-06-16 01:55:18.855287: Current learning rate: 0.00867 
2025-06-16 01:56:08.261818: train_loss -0.5649 
2025-06-16 01:56:08.263085: val_loss -0.5937 
2025-06-16 01:56:08.263999: Pseudo dice [0.6961, 0.9079, 0.8967, 0.8619] 
2025-06-16 01:56:08.264826: Epoch time: 49.41 s 
2025-06-16 01:56:09.958482:  
2025-06-16 01:56:09.959079: Epoch 148 
2025-06-16 01:56:09.959478: Current learning rate: 0.00866 
2025-06-16 01:57:17.145980: train_loss -0.5566 
2025-06-16 01:57:17.147409: val_loss -0.5763 
2025-06-16 01:57:17.147898: Pseudo dice [0.6861, 0.9103, 0.9112, 0.8562] 
2025-06-16 01:57:17.148305: Epoch time: 67.19 s 
2025-06-16 01:57:19.047782:  
2025-06-16 01:57:19.048527: Epoch 149 
2025-06-16 01:57:19.049101: Current learning rate: 0.00865 
2025-06-16 01:58:07.229531: train_loss -0.5698 
2025-06-16 01:58:07.230578: val_loss -0.5717 
2025-06-16 01:58:07.231593: Pseudo dice [0.6992, 0.9165, 0.9184, 0.8619] 
2025-06-16 01:58:07.232239: Epoch time: 48.18 s 
2025-06-16 01:58:10.293351:  
2025-06-16 01:58:10.294476: Epoch 150 
2025-06-16 01:58:10.295188: Current learning rate: 0.00864 
2025-06-16 01:59:10.944584: train_loss -0.561 
2025-06-16 01:59:10.945865: val_loss -0.5722 
2025-06-16 01:59:10.946666: Pseudo dice [0.6359, 0.9025, 0.9038, 0.8824] 
2025-06-16 01:59:10.947811: Epoch time: 60.65 s 
2025-06-16 01:59:13.160691:  
2025-06-16 01:59:13.161318: Epoch 151 
2025-06-16 01:59:13.161897: Current learning rate: 0.00863 
2025-06-16 02:00:06.511394: train_loss -0.5541 
2025-06-16 02:00:06.535285: val_loss -0.5869 
2025-06-16 02:00:06.535945: Pseudo dice [0.7498, 0.9001, 0.9061, 0.8918] 
2025-06-16 02:00:06.536869: Epoch time: 53.33 s 
2025-06-16 02:00:08.685589:  
2025-06-16 02:00:08.686163: Epoch 152 
2025-06-16 02:00:08.686584: Current learning rate: 0.00862 
2025-06-16 02:00:47.289108: train_loss -0.5798 
2025-06-16 02:00:47.289997: val_loss -0.578 
2025-06-16 02:00:47.290595: Pseudo dice [0.6229, 0.9074, 0.9087, 0.8805] 
2025-06-16 02:00:47.291153: Epoch time: 38.6 s 
2025-06-16 02:00:51.088742:  
2025-06-16 02:00:51.089723: Epoch 153 
2025-06-16 02:00:51.090450: Current learning rate: 0.00861 
2025-06-16 02:01:39.726265: train_loss -0.5687 
2025-06-16 02:01:39.727421: val_loss -0.577 
2025-06-16 02:01:39.728510: Pseudo dice [0.754, 0.9039, 0.908, 0.8987] 
2025-06-16 02:01:39.729238: Epoch time: 48.64 s 
2025-06-16 02:01:41.435698:  
2025-06-16 02:01:41.436336: Epoch 154 
2025-06-16 02:01:41.436768: Current learning rate: 0.0086 
2025-06-16 02:02:44.587210: train_loss -0.5714 
2025-06-16 02:02:44.592799: val_loss -0.5772 
2025-06-16 02:02:44.593597: Pseudo dice [0.7632, 0.8903, 0.8878, 0.8849] 
2025-06-16 02:02:44.594995: Epoch time: 63.15 s 
2025-06-16 02:02:47.510479:  
2025-06-16 02:02:47.511056: Epoch 155 
2025-06-16 02:02:47.511449: Current learning rate: 0.00859 
2025-06-16 02:03:38.579297: train_loss -0.56 
2025-06-16 02:03:38.580644: val_loss -0.5776 
2025-06-16 02:03:38.581673: Pseudo dice [0.7595, 0.8981, 0.9157, 0.877] 
2025-06-16 02:03:38.582648: Epoch time: 51.07 s 
2025-06-16 02:03:40.297317:  
2025-06-16 02:03:40.298193: Epoch 156 
2025-06-16 02:03:40.298736: Current learning rate: 0.00858 
2025-06-16 02:04:44.630383: train_loss -0.5751 
2025-06-16 02:04:44.631278: val_loss -0.5634 
2025-06-16 02:04:44.631848: Pseudo dice [0.686, 0.8912, 0.8833, 0.9264] 
2025-06-16 02:04:44.632747: Epoch time: 64.33 s 
2025-06-16 02:04:46.364931:  
2025-06-16 02:04:46.365573: Epoch 157 
2025-06-16 02:04:46.365982: Current learning rate: 0.00858 
2025-06-16 02:05:38.297597: train_loss -0.5754 
2025-06-16 02:05:38.326130: val_loss -0.6026 
2025-06-16 02:05:38.327243: Pseudo dice [0.7677, 0.8997, 0.9252, 0.8997] 
2025-06-16 02:05:38.328815: Epoch time: 51.9 s 
2025-06-16 02:05:40.519867:  
2025-06-16 02:05:40.520792: Epoch 158 
2025-06-16 02:05:40.521547: Current learning rate: 0.00857 
2025-06-16 02:06:43.151091: train_loss -0.5719 
2025-06-16 02:06:43.152614: val_loss -0.5773 
2025-06-16 02:06:43.153589: Pseudo dice [0.6654, 0.9139, 0.9087, 0.906] 
2025-06-16 02:06:43.154474: Epoch time: 62.63 s 
2025-06-16 02:06:48.584989:  
2025-06-16 02:06:48.585774: Epoch 159 
2025-06-16 02:06:48.586298: Current learning rate: 0.00856 
2025-06-16 02:07:40.232349: train_loss -0.5822 
2025-06-16 02:07:40.233240: val_loss -0.5939 
2025-06-16 02:07:40.233845: Pseudo dice [0.7149, 0.9124, 0.8807, 0.9121] 
2025-06-16 02:07:40.234283: Epoch time: 51.65 s 
2025-06-16 02:07:42.367543:  
2025-06-16 02:07:42.368147: Epoch 160 
2025-06-16 02:07:42.368575: Current learning rate: 0.00855 
2025-06-16 02:08:34.338260: train_loss -0.573 
2025-06-16 02:08:34.339461: val_loss -0.5936 
2025-06-16 02:08:34.340318: Pseudo dice [0.7775, 0.9142, 0.8844, 0.8698] 
2025-06-16 02:08:34.341039: Epoch time: 51.97 s 
2025-06-16 02:08:34.341621: Yayy! New best EMA pseudo Dice: 0.8522 
2025-06-16 02:08:37.725300:  
2025-06-16 02:08:37.726027: Epoch 161 
2025-06-16 02:08:37.726545: Current learning rate: 0.00854 
2025-06-16 02:09:43.252698: train_loss -0.5727 
2025-06-16 02:09:43.254216: val_loss -0.5943 
2025-06-16 02:09:43.254742: Pseudo dice [0.7382, 0.9116, 0.8891, 0.8883] 
2025-06-16 02:09:43.255183: Epoch time: 65.53 s 
2025-06-16 02:09:43.255571: Yayy! New best EMA pseudo Dice: 0.8527 
2025-06-16 02:09:46.041927:  
2025-06-16 02:09:46.042519: Epoch 162 
2025-06-16 02:09:46.042966: Current learning rate: 0.00853 
2025-06-16 02:10:31.219444: train_loss -0.5717 
2025-06-16 02:10:31.220822: val_loss -0.5706 
2025-06-16 02:10:31.221863: Pseudo dice [0.5803, 0.8984, 0.8318, 0.8874] 
2025-06-16 02:10:31.222633: Epoch time: 45.18 s 
2025-06-16 02:10:33.114850:  
2025-06-16 02:10:33.115841: Epoch 163 
2025-06-16 02:10:33.116647: Current learning rate: 0.00852 
2025-06-16 02:11:35.285820: train_loss -0.5619 
2025-06-16 02:11:35.294799: val_loss -0.575 
2025-06-16 02:11:35.295576: Pseudo dice [0.6972, 0.8968, 0.9016, 0.8678] 
2025-06-16 02:11:35.296289: Epoch time: 62.17 s 
2025-06-16 02:11:37.336855:  
2025-06-16 02:11:37.337559: Epoch 164 
2025-06-16 02:11:37.338032: Current learning rate: 0.00851 
2025-06-16 02:12:25.925476: train_loss -0.5674 
2025-06-16 02:12:25.935298: val_loss -0.6207 
2025-06-16 02:12:25.936108: Pseudo dice [0.6879, 0.9119, 0.8839, 0.9008] 
2025-06-16 02:12:25.937277: Epoch time: 48.56 s 
2025-06-16 02:12:28.175781:  
2025-06-16 02:12:28.176860: Epoch 165 
2025-06-16 02:12:28.177642: Current learning rate: 0.0085 
2025-06-16 02:13:17.597282: train_loss -0.5533 
2025-06-16 02:13:17.598402: val_loss -0.5277 
2025-06-16 02:13:17.599093: Pseudo dice [0.6698, 0.8945, 0.8729, 0.8192] 
2025-06-16 02:13:17.599931: Epoch time: 49.42 s 
2025-06-16 02:13:22.511129:  
2025-06-16 02:13:22.512107: Epoch 166 
2025-06-16 02:13:22.512630: Current learning rate: 0.00849 
2025-06-16 02:14:25.265504: train_loss -0.5481 
2025-06-16 02:14:25.266344: val_loss -0.5671 
2025-06-16 02:14:25.266974: Pseudo dice [0.7274, 0.8993, 0.901, 0.8699] 
2025-06-16 02:14:25.267424: Epoch time: 62.76 s 
2025-06-16 02:14:27.224277:  
2025-06-16 02:14:27.225078: Epoch 167 
2025-06-16 02:14:27.225521: Current learning rate: 0.00848 
2025-06-16 02:15:10.858512: train_loss -0.5632 
2025-06-16 02:15:10.859575: val_loss -0.5789 
2025-06-16 02:15:10.860062: Pseudo dice [0.7932, 0.8919, 0.8868, 0.8493] 
2025-06-16 02:15:10.860493: Epoch time: 43.64 s 
2025-06-16 02:15:12.489005:  
2025-06-16 02:15:12.489638: Epoch 168 
2025-06-16 02:15:12.490121: Current learning rate: 0.00847 
2025-06-16 02:15:58.036655: train_loss -0.5612 
2025-06-16 02:15:58.037449: val_loss -0.5857 
2025-06-16 02:15:58.037980: Pseudo dice [0.7556, 0.9112, 0.9003, 0.89] 
2025-06-16 02:15:58.038364: Epoch time: 45.55 s 
2025-06-16 02:15:59.323714:  
2025-06-16 02:15:59.324426: Epoch 169 
2025-06-16 02:15:59.324875: Current learning rate: 0.00847 
2025-06-16 02:17:04.257249: train_loss -0.577 
2025-06-16 02:17:04.258113: val_loss -0.5805 
2025-06-16 02:17:04.258581: Pseudo dice [0.6691, 0.8923, 0.9047, 0.8562] 
2025-06-16 02:17:04.259146: Epoch time: 64.93 s 
2025-06-16 02:17:06.164383:  
2025-06-16 02:17:06.165035: Epoch 170 
2025-06-16 02:17:06.165467: Current learning rate: 0.00846 
2025-06-16 02:17:55.394686: train_loss -0.5729 
2025-06-16 02:17:55.466961: val_loss -0.5953 
2025-06-16 02:17:55.468177: Pseudo dice [0.7389, 0.9053, 0.8834, 0.8888] 
2025-06-16 02:17:55.487945: Epoch time: 49.2 s 
2025-06-16 02:17:58.120882:  
2025-06-16 02:17:58.121589: Epoch 171 
2025-06-16 02:17:58.122015: Current learning rate: 0.00845 
2025-06-16 02:18:38.138343: train_loss -0.5704 
2025-06-16 02:18:38.139778: val_loss -0.5751 
2025-06-16 02:18:38.140586: Pseudo dice [0.6187, 0.8992, 0.8899, 0.8988] 
2025-06-16 02:18:38.141385: Epoch time: 40.02 s 
2025-06-16 02:18:40.183943:  
2025-06-16 02:18:40.184484: Epoch 172 
2025-06-16 02:18:40.184891: Current learning rate: 0.00844 
2025-06-16 02:19:34.414682: train_loss -0.5773 
2025-06-16 02:19:34.415760: val_loss -0.589 
2025-06-16 02:19:34.416235: Pseudo dice [0.7544, 0.9042, 0.8927, 0.898] 
2025-06-16 02:19:34.417162: Epoch time: 54.23 s 
2025-06-16 02:19:36.198798:  
2025-06-16 02:19:36.199569: Epoch 173 
2025-06-16 02:19:36.200310: Current learning rate: 0.00843 
2025-06-16 02:20:42.117691: train_loss -0.566 
2025-06-16 02:20:42.119865: val_loss -0.5809 
2025-06-16 02:20:42.120641: Pseudo dice [0.7453, 0.9109, 0.8827, 0.8704] 
2025-06-16 02:20:42.121401: Epoch time: 65.92 s 
2025-06-16 02:20:45.752636:  
2025-06-16 02:20:45.753252: Epoch 174 
2025-06-16 02:20:45.753846: Current learning rate: 0.00842 
2025-06-16 02:21:37.741531: train_loss -0.5693 
2025-06-16 02:21:37.742742: val_loss -0.5956 
2025-06-16 02:21:37.743714: Pseudo dice [0.7336, 0.9116, 0.896, 0.8934] 
2025-06-16 02:21:37.744444: Epoch time: 51.99 s 
2025-06-16 02:21:39.633012:  
2025-06-16 02:21:39.633604: Epoch 175 
2025-06-16 02:21:39.634029: Current learning rate: 0.00841 
2025-06-16 02:22:47.018878: train_loss -0.5824 
2025-06-16 02:22:47.019718: val_loss -0.5953 
2025-06-16 02:22:47.020153: Pseudo dice [0.6397, 0.9043, 0.8908, 0.8978] 
2025-06-16 02:22:47.020533: Epoch time: 67.39 s 
2025-06-16 02:22:48.876030:  
2025-06-16 02:22:48.876696: Epoch 176 
2025-06-16 02:22:48.877114: Current learning rate: 0.0084 
2025-06-16 02:23:40.297426: train_loss -0.5752 
2025-06-16 02:23:40.303434: val_loss -0.6003 
2025-06-16 02:23:40.304352: Pseudo dice [0.616, 0.9164, 0.8916, 0.8751] 
2025-06-16 02:23:40.306465: Epoch time: 51.4 s 
2025-06-16 02:23:43.068691:  
2025-06-16 02:23:43.069509: Epoch 177 
2025-06-16 02:23:43.070084: Current learning rate: 0.00839 
2025-06-16 02:24:39.616619: train_loss -0.5801 
2025-06-16 02:24:39.618097: val_loss -0.594 
2025-06-16 02:24:39.618939: Pseudo dice [0.7515, 0.9167, 0.9098, 0.8899] 
2025-06-16 02:24:39.619864: Epoch time: 56.55 s 
2025-06-16 02:24:41.849023:  
2025-06-16 02:24:41.849836: Epoch 178 
2025-06-16 02:24:41.850665: Current learning rate: 0.00838 
2025-06-16 02:25:40.356147: train_loss -0.5783 
2025-06-16 02:25:40.356840: val_loss -0.5673 
2025-06-16 02:25:40.357213: Pseudo dice [0.7705, 0.8785, 0.9006, 0.8695] 
2025-06-16 02:25:40.357618: Epoch time: 58.51 s 
2025-06-16 02:25:42.434345:  
2025-06-16 02:25:42.434975: Epoch 179 
2025-06-16 02:25:42.435428: Current learning rate: 0.00837 
2025-06-16 02:26:26.670336: train_loss -0.5754 
2025-06-16 02:26:26.671060: val_loss -0.5906 
2025-06-16 02:26:26.671475: Pseudo dice [0.8024, 0.9032, 0.8988, 0.8963] 
2025-06-16 02:26:26.672080: Epoch time: 44.24 s 
2025-06-16 02:26:28.538352:  
2025-06-16 02:26:28.538972: Epoch 180 
2025-06-16 02:26:28.539437: Current learning rate: 0.00836 
2025-06-16 02:27:26.487357: train_loss -0.5698 
2025-06-16 02:27:26.488307: val_loss -0.5611 
2025-06-16 02:27:26.488825: Pseudo dice [0.6305, 0.9017, 0.8863, 0.859] 
2025-06-16 02:27:26.489217: Epoch time: 57.95 s 
2025-06-16 02:27:29.377589:  
2025-06-16 02:27:29.378228: Epoch 181 
2025-06-16 02:27:29.378826: Current learning rate: 0.00836 
2025-06-16 02:28:16.633460: train_loss -0.5926 
2025-06-16 02:28:16.707158: val_loss -0.6014 
2025-06-16 02:28:16.708451: Pseudo dice [0.7523, 0.9192, 0.8513, 0.8789] 
2025-06-16 02:28:16.720855: Epoch time: 47.26 s 
2025-06-16 02:28:20.003005:  
2025-06-16 02:28:20.003626: Epoch 182 
2025-06-16 02:28:20.004117: Current learning rate: 0.00835 
2025-06-16 02:29:18.590243: train_loss -0.5683 
2025-06-16 02:29:18.591457: val_loss -0.5792 
2025-06-16 02:29:18.592376: Pseudo dice [0.7215, 0.8949, 0.9107, 0.87] 
2025-06-16 02:29:18.593120: Epoch time: 58.59 s 
2025-06-16 02:29:20.747866:  
2025-06-16 02:29:20.748766: Epoch 183 
2025-06-16 02:29:20.749233: Current learning rate: 0.00834 
2025-06-16 02:30:16.758293: train_loss -0.5784 
2025-06-16 02:30:16.782636: val_loss -0.5979 
2025-06-16 02:30:16.783596: Pseudo dice [0.6343, 0.9223, 0.902, 0.9072] 
2025-06-16 02:30:16.784888: Epoch time: 55.98 s 
2025-06-16 02:30:18.953359:  
2025-06-16 02:30:18.954152: Epoch 184 
2025-06-16 02:30:18.954621: Current learning rate: 0.00833 
2025-06-16 02:31:01.463169: train_loss -0.5802 
2025-06-16 02:31:01.464079: val_loss -0.5992 
2025-06-16 02:31:01.464958: Pseudo dice [0.5694, 0.9087, 0.8872, 0.8934] 
2025-06-16 02:31:01.465478: Epoch time: 42.51 s 
2025-06-16 02:31:03.527641:  
2025-06-16 02:31:03.528283: Epoch 185 
2025-06-16 02:31:03.528730: Current learning rate: 0.00832 
2025-06-16 02:32:12.381002: train_loss -0.5748 
2025-06-16 02:32:12.382009: val_loss -0.6173 
2025-06-16 02:32:12.382634: Pseudo dice [0.7392, 0.9129, 0.8992, 0.8705] 
2025-06-16 02:32:12.383381: Epoch time: 68.85 s 
2025-06-16 02:32:14.227479:  
2025-06-16 02:32:14.228193: Epoch 186 
2025-06-16 02:32:14.228652: Current learning rate: 0.00831 
2025-06-16 02:33:06.611949: train_loss -0.5654 
2025-06-16 02:33:06.613948: val_loss -0.6007 
2025-06-16 02:33:06.614901: Pseudo dice [0.6377, 0.9031, 0.8883, 0.8547] 
2025-06-16 02:33:06.615750: Epoch time: 52.39 s 
2025-06-16 02:33:09.116948:  
2025-06-16 02:33:09.117588: Epoch 187 
2025-06-16 02:33:09.118091: Current learning rate: 0.0083 
2025-06-16 02:34:07.889854: train_loss -0.5836 
2025-06-16 02:34:07.890899: val_loss -0.5768 
2025-06-16 02:34:07.891844: Pseudo dice [0.6718, 0.8928, 0.8742, 0.8944] 
2025-06-16 02:34:07.892447: Epoch time: 58.77 s 
2025-06-16 02:34:16.290174:  
2025-06-16 02:34:16.291209: Epoch 188 
2025-06-16 02:34:16.292126: Current learning rate: 0.00829 
2025-06-16 02:35:10.402886: train_loss -0.5766 
2025-06-16 02:35:10.404277: val_loss -0.5879 
2025-06-16 02:35:10.405227: Pseudo dice [0.7811, 0.9096, 0.9034, 0.9039] 
2025-06-16 02:35:10.406115: Epoch time: 54.11 s 
2025-06-16 02:35:12.197961:  
2025-06-16 02:35:12.198629: Epoch 189 
2025-06-16 02:35:12.199064: Current learning rate: 0.00828 
2025-06-16 02:35:59.844176: train_loss -0.5676 
2025-06-16 02:35:59.845362: val_loss -0.5785 
2025-06-16 02:35:59.845989: Pseudo dice [0.7448, 0.8955, 0.8947, 0.9076] 
2025-06-16 02:35:59.846653: Epoch time: 47.65 s 
2025-06-16 02:36:01.614285:  
2025-06-16 02:36:01.614865: Epoch 190 
2025-06-16 02:36:01.615339: Current learning rate: 0.00827 
2025-06-16 02:37:00.952975: train_loss -0.5824 
2025-06-16 02:37:00.961763: val_loss -0.5869 
2025-06-16 02:37:00.962429: Pseudo dice [0.6862, 0.9042, 0.8846, 0.8794] 
2025-06-16 02:37:00.963864: Epoch time: 59.29 s 
2025-06-16 02:37:03.282847:  
2025-06-16 02:37:03.283453: Epoch 191 
2025-06-16 02:37:03.283961: Current learning rate: 0.00826 
2025-06-16 02:37:53.449193: train_loss -0.5738 
2025-06-16 02:37:53.450266: val_loss -0.5853 
2025-06-16 02:37:53.451018: Pseudo dice [0.6809, 0.9046, 0.8942, 0.8812] 
2025-06-16 02:37:53.451638: Epoch time: 50.17 s 
2025-06-16 02:37:55.414497:  
2025-06-16 02:37:55.415127: Epoch 192 
2025-06-16 02:37:55.415564: Current learning rate: 0.00825 
2025-06-16 02:38:34.781523: train_loss -0.5713 
2025-06-16 02:38:34.782270: val_loss -0.591 
2025-06-16 02:38:34.782676: Pseudo dice [0.7674, 0.8953, 0.8754, 0.8745] 
2025-06-16 02:38:34.783055: Epoch time: 39.37 s 
2025-06-16 02:38:36.698488:  
2025-06-16 02:38:36.699045: Epoch 193 
2025-06-16 02:38:36.699442: Current learning rate: 0.00824 
2025-06-16 02:39:30.438496: train_loss -0.5791 
2025-06-16 02:39:30.439811: val_loss -0.6055 
2025-06-16 02:39:30.440396: Pseudo dice [0.7191, 0.9093, 0.9096, 0.9023] 
2025-06-16 02:39:30.441183: Epoch time: 53.74 s 
2025-06-16 02:39:32.188124:  
2025-06-16 02:39:32.188813: Epoch 194 
2025-06-16 02:39:32.189550: Current learning rate: 0.00824 
2025-06-16 02:40:36.985359: train_loss -0.577 
2025-06-16 02:40:36.986268: val_loss -0.5726 
2025-06-16 02:40:36.986893: Pseudo dice [0.712, 0.9041, 0.9148, 0.8572] 
2025-06-16 02:40:36.987428: Epoch time: 64.8 s 
2025-06-16 02:40:39.191631:  
2025-06-16 02:40:39.192265: Epoch 195 
2025-06-16 02:40:39.192753: Current learning rate: 0.00823 
2025-06-16 02:41:29.115206: train_loss -0.5665 
2025-06-16 02:41:29.116467: val_loss -0.5604 
2025-06-16 02:41:29.117286: Pseudo dice [0.5228, 0.9008, 0.8975, 0.8485] 
2025-06-16 02:41:29.117995: Epoch time: 49.92 s 
2025-06-16 02:41:33.772602:  
2025-06-16 02:41:33.773303: Epoch 196 
2025-06-16 02:41:33.773840: Current learning rate: 0.00822 
2025-06-16 02:42:35.751280: train_loss -0.5788 
2025-06-16 02:42:35.756915: val_loss -0.5885 
2025-06-16 02:42:35.757417: Pseudo dice [0.7087, 0.9166, 0.9034, 0.8938] 
2025-06-16 02:42:35.757784: Epoch time: 61.98 s 
2025-06-16 02:42:37.209691:  
2025-06-16 02:42:37.210398: Epoch 197 
2025-06-16 02:42:37.210801: Current learning rate: 0.00821 
2025-06-16 02:43:27.576794: train_loss -0.5746 
2025-06-16 02:43:28.063731: val_loss -0.5765 
2025-06-16 02:43:28.064675: Pseudo dice [0.7356, 0.8935, 0.8893, 0.8827] 
2025-06-16 02:43:28.080264: Epoch time: 50.37 s 
2025-06-16 02:43:30.739177:  
2025-06-16 02:43:30.739797: Epoch 198 
2025-06-16 02:43:30.740219: Current learning rate: 0.0082 
2025-06-16 02:44:33.518336: train_loss -0.5742 
2025-06-16 02:44:33.519658: val_loss -0.5827 
2025-06-16 02:44:33.520592: Pseudo dice [0.6556, 0.9208, 0.8871, 0.8469] 
2025-06-16 02:44:33.521393: Epoch time: 62.78 s 
2025-06-16 02:44:35.575006:  
2025-06-16 02:44:35.575725: Epoch 199 
2025-06-16 02:44:35.576230: Current learning rate: 0.00819 
2025-06-16 02:45:33.111869: train_loss -0.5818 
2025-06-16 02:45:33.113720: val_loss -0.5955 
2025-06-16 02:45:33.114427: Pseudo dice [0.694, 0.9062, 0.8916, 0.8818] 
2025-06-16 02:45:33.115026: Epoch time: 57.54 s 
2025-06-16 02:45:36.220244:  
2025-06-16 02:45:36.220835: Epoch 200 
2025-06-16 02:45:36.221279: Current learning rate: 0.00818 
2025-06-16 02:46:31.200989: train_loss -0.5719 
2025-06-16 02:46:31.202119: val_loss -0.5915 
2025-06-16 02:46:31.206021: Pseudo dice [0.7785, 0.9033, 0.8983, 0.8467] 
2025-06-16 02:46:31.206689: Epoch time: 54.98 s 
2025-06-16 02:46:33.229947:  
2025-06-16 02:46:33.230883: Epoch 201 
2025-06-16 02:46:33.231644: Current learning rate: 0.00817 
2025-06-16 02:47:39.274542: train_loss -0.5855 
2025-06-16 02:47:39.318329: val_loss -0.6089 
2025-06-16 02:47:39.319345: Pseudo dice [0.7142, 0.9084, 0.8966, 0.8705] 
2025-06-16 02:47:39.325856: Epoch time: 66.01 s 
2025-06-16 02:47:41.778063:  
2025-06-16 02:47:41.778829: Epoch 202 
2025-06-16 02:47:41.779284: Current learning rate: 0.00816 
2025-06-16 02:48:33.662169: train_loss -0.59 
2025-06-16 02:48:33.663069: val_loss -0.6048 
2025-06-16 02:48:33.663777: Pseudo dice [0.7623, 0.9136, 0.8996, 0.899] 
2025-06-16 02:48:33.664479: Epoch time: 51.89 s 
2025-06-16 02:48:38.676677:  
2025-06-16 02:48:38.677389: Epoch 203 
2025-06-16 02:48:38.677933: Current learning rate: 0.00815 
2025-06-16 02:49:43.954709: train_loss -0.5806 
2025-06-16 02:49:43.955629: val_loss -0.5866 
2025-06-16 02:49:43.956228: Pseudo dice [0.6625, 0.9149, 0.9054, 0.8714] 
2025-06-16 02:49:43.956693: Epoch time: 65.28 s 
2025-06-16 02:49:45.818808:  
2025-06-16 02:49:45.819469: Epoch 204 
2025-06-16 02:49:45.819905: Current learning rate: 0.00814 
2025-06-16 02:50:31.592998: train_loss -0.5776 
2025-06-16 02:50:31.594295: val_loss -0.5925 
2025-06-16 02:50:31.595018: Pseudo dice [0.7705, 0.9016, 0.9126, 0.8943] 
2025-06-16 02:50:31.595565: Epoch time: 45.78 s 
2025-06-16 02:50:33.710065:  
2025-06-16 02:50:33.710796: Epoch 205 
2025-06-16 02:50:33.711333: Current learning rate: 0.00813 
2025-06-16 02:51:39.608751: train_loss -0.5722 
2025-06-16 02:51:39.609999: val_loss -0.5951 
2025-06-16 02:51:39.611095: Pseudo dice [0.7906, 0.9091, 0.8997, 0.8964] 
2025-06-16 02:51:39.611842: Epoch time: 65.9 s 
2025-06-16 02:51:41.648628:  
2025-06-16 02:51:41.649274: Epoch 206 
2025-06-16 02:51:41.649935: Current learning rate: 0.00813 
2025-06-16 02:52:35.867520: train_loss -0.5799 
2025-06-16 02:52:35.868663: val_loss -0.6051 
2025-06-16 02:52:35.869151: Pseudo dice [0.7435, 0.8888, 0.9193, 0.834] 
2025-06-16 02:52:35.869602: Epoch time: 54.22 s 
2025-06-16 02:52:38.063642:  
2025-06-16 02:52:38.064442: Epoch 207 
2025-06-16 02:52:38.064988: Current learning rate: 0.00812 
2025-06-16 02:53:43.211095: train_loss -0.5866 
2025-06-16 02:53:43.212390: val_loss -0.6045 
2025-06-16 02:53:43.213363: Pseudo dice [0.7515, 0.9064, 0.9187, 0.8853] 
2025-06-16 02:53:43.214201: Epoch time: 65.15 s 
2025-06-16 02:53:45.161860:  
2025-06-16 02:53:45.162755: Epoch 208 
2025-06-16 02:53:45.163352: Current learning rate: 0.00811 
2025-06-16 02:54:46.552428: train_loss -0.5813 
2025-06-16 02:54:46.669961: val_loss -0.5994 
2025-06-16 02:54:46.670969: Pseudo dice [0.6772, 0.915, 0.9037, 0.9167] 
2025-06-16 02:54:46.686718: Epoch time: 61.37 s 
2025-06-16 02:54:49.632117:  
2025-06-16 02:54:49.632705: Epoch 209 
2025-06-16 02:54:49.633167: Current learning rate: 0.0081 
2025-06-16 02:55:42.034961: train_loss -0.5866 
2025-06-16 02:55:42.036299: val_loss -0.605 
2025-06-16 02:55:42.037198: Pseudo dice [0.7792, 0.9124, 0.898, 0.9074] 
2025-06-16 02:55:42.038277: Epoch time: 52.4 s 
2025-06-16 02:55:42.038967: Yayy! New best EMA pseudo Dice: 0.8542 
2025-06-16 02:55:48.697964:  
2025-06-16 02:55:48.698634: Epoch 210 
2025-06-16 02:55:48.699245: Current learning rate: 0.00809 
2025-06-16 02:56:51.579299: train_loss -0.5858 
2025-06-16 02:56:51.580826: val_loss -0.5836 
2025-06-16 02:56:51.581386: Pseudo dice [0.8299, 0.9181, 0.897, 0.8699] 
2025-06-16 02:56:51.581859: Epoch time: 62.88 s 
2025-06-16 02:56:51.582297: Yayy! New best EMA pseudo Dice: 0.8567 
2025-06-16 02:56:53.626983:  
2025-06-16 02:56:53.627628: Epoch 211 
2025-06-16 02:56:53.628081: Current learning rate: 0.00808 
2025-06-16 02:57:42.296370: train_loss -0.5956 
2025-06-16 02:57:42.297347: val_loss -0.5747 
2025-06-16 02:57:42.298194: Pseudo dice [0.7133, 0.9016, 0.8959, 0.8796] 
2025-06-16 02:57:42.298716: Epoch time: 48.67 s 
2025-06-16 02:57:44.350800:  
2025-06-16 02:57:44.351447: Epoch 212 
2025-06-16 02:57:44.352184: Current learning rate: 0.00807 
2025-06-16 02:58:45.708899: train_loss -0.5682 
2025-06-16 02:58:45.709712: val_loss -0.5442 
2025-06-16 02:58:45.710209: Pseudo dice [0.7856, 0.8999, 0.894, 0.8395] 
2025-06-16 02:58:45.710852: Epoch time: 61.36 s 
2025-06-16 02:58:47.457648:  
2025-06-16 02:58:47.458246: Epoch 213 
2025-06-16 02:58:47.458687: Current learning rate: 0.00806 
2025-06-16 02:59:38.799988: train_loss -0.5741 
2025-06-16 02:59:38.800869: val_loss -0.5796 
2025-06-16 02:59:38.801291: Pseudo dice [0.7549, 0.9014, 0.8881, 0.8759] 
2025-06-16 02:59:38.801875: Epoch time: 51.34 s 
2025-06-16 02:59:40.945239:  
2025-06-16 02:59:40.945936: Epoch 214 
2025-06-16 02:59:40.946320: Current learning rate: 0.00805 
2025-06-16 03:00:26.223354: train_loss -0.5796 
2025-06-16 03:00:26.224597: val_loss -0.6323 
2025-06-16 03:00:26.225111: Pseudo dice [0.7613, 0.905, 0.9116, 0.9147] 
2025-06-16 03:00:26.225857: Epoch time: 45.28 s 
2025-06-16 03:00:26.226413: Yayy! New best EMA pseudo Dice: 0.8574 
2025-06-16 03:00:28.596871:  
2025-06-16 03:00:28.597824: Epoch 215 
2025-06-16 03:00:28.598413: Current learning rate: 0.00804 
2025-06-16 03:01:26.682085: train_loss -0.5716 
2025-06-16 03:01:26.683138: val_loss -0.5549 
2025-06-16 03:01:26.683692: Pseudo dice [0.6562, 0.8883, 0.8676, 0.8584] 
2025-06-16 03:01:26.684122: Epoch time: 58.09 s 
2025-06-16 03:01:28.340221:  
2025-06-16 03:01:28.340974: Epoch 216 
2025-06-16 03:01:28.341423: Current learning rate: 0.00803 
2025-06-16 03:02:19.706139: train_loss -0.5718 
2025-06-16 03:02:19.710433: val_loss -0.5906 
2025-06-16 03:02:19.711112: Pseudo dice [0.7509, 0.9075, 0.8878, 0.8784] 
2025-06-16 03:02:19.713940: Epoch time: 51.35 s 
2025-06-16 03:02:21.837318:  
2025-06-16 03:02:21.838088: Epoch 217 
2025-06-16 03:02:21.838518: Current learning rate: 0.00802 
2025-06-16 03:03:02.077844: train_loss -0.5678 
2025-06-16 03:03:02.078689: val_loss -0.589 
2025-06-16 03:03:02.079342: Pseudo dice [0.5659, 0.9079, 0.893, 0.8956] 
2025-06-16 03:03:02.079793: Epoch time: 40.24 s 
2025-06-16 03:03:05.384944:  
2025-06-16 03:03:05.385921: Epoch 218 
2025-06-16 03:03:05.386482: Current learning rate: 0.00801 
2025-06-16 03:03:56.494434: train_loss -0.5799 
2025-06-16 03:03:56.495250: val_loss -0.599 
2025-06-16 03:03:56.496162: Pseudo dice [0.7448, 0.9069, 0.9093, 0.9165] 
2025-06-16 03:03:56.496591: Epoch time: 51.11 s 
2025-06-16 03:03:58.023950:  
2025-06-16 03:03:58.024736: Epoch 219 
2025-06-16 03:03:58.025277: Current learning rate: 0.00801 
2025-06-16 03:05:02.635677: train_loss -0.5818 
2025-06-16 03:05:02.735174: val_loss -0.5888 
2025-06-16 03:05:02.736377: Pseudo dice [0.6508, 0.9083, 0.899, 0.8866] 
2025-06-16 03:05:02.760218: Epoch time: 64.61 s 
2025-06-16 03:05:05.553696:  
2025-06-16 03:05:05.554254: Epoch 220 
2025-06-16 03:05:05.554669: Current learning rate: 0.008 
2025-06-16 03:05:52.786092: train_loss -0.5849 
2025-06-16 03:05:52.787160: val_loss -0.5958 
2025-06-16 03:05:52.787856: Pseudo dice [0.785, 0.9185, 0.8813, 0.914] 
2025-06-16 03:05:52.788465: Epoch time: 47.23 s 
2025-06-16 03:05:54.229831:  
2025-06-16 03:05:54.230694: Epoch 221 
2025-06-16 03:05:54.231230: Current learning rate: 0.00799 
2025-06-16 03:06:50.941099: train_loss -0.5677 
2025-06-16 03:06:50.943333: val_loss -0.5735 
2025-06-16 03:06:50.944269: Pseudo dice [0.7172, 0.8897, 0.89, 0.8524] 
2025-06-16 03:06:50.945283: Epoch time: 56.71 s 
2025-06-16 03:06:52.764196:  
2025-06-16 03:06:52.765016: Epoch 222 
2025-06-16 03:06:52.765598: Current learning rate: 0.00798 
2025-06-16 03:08:00.600315: train_loss -0.5674 
2025-06-16 03:08:00.627071: val_loss -0.5796 
2025-06-16 03:08:00.627845: Pseudo dice [0.6321, 0.8875, 0.8955, 0.8783] 
2025-06-16 03:08:00.629044: Epoch time: 67.82 s 
2025-06-16 03:08:02.901028:  
2025-06-16 03:08:02.901701: Epoch 223 
2025-06-16 03:08:02.902154: Current learning rate: 0.00797 
2025-06-16 03:08:59.130210: train_loss -0.5748 
2025-06-16 03:08:59.131446: val_loss -0.5725 
2025-06-16 03:08:59.132207: Pseudo dice [0.7757, 0.9078, 0.903, 0.906] 
2025-06-16 03:08:59.133129: Epoch time: 56.23 s 
2025-06-16 03:09:01.336478:  
2025-06-16 03:09:01.337429: Epoch 224 
2025-06-16 03:09:01.337890: Current learning rate: 0.00796 
2025-06-16 03:10:10.841071: train_loss -0.5677 
2025-06-16 03:10:10.842319: val_loss -0.5938 
2025-06-16 03:10:10.843221: Pseudo dice [0.7716, 0.9048, 0.8947, 0.8973] 
2025-06-16 03:10:10.843950: Epoch time: 69.51 s 
2025-06-16 03:10:12.975212:  
2025-06-16 03:10:12.975879: Epoch 225 
2025-06-16 03:10:12.976337: Current learning rate: 0.00795 
2025-06-16 03:11:00.846405: train_loss -0.5697 
2025-06-16 03:11:00.847377: val_loss -0.5724 
2025-06-16 03:11:00.847936: Pseudo dice [0.5848, 0.8928, 0.8764, 0.897] 
2025-06-16 03:11:00.848443: Epoch time: 47.87 s 
2025-06-16 03:11:05.967265:  
2025-06-16 03:11:05.967919: Epoch 226 
2025-06-16 03:11:05.968404: Current learning rate: 0.00794 
2025-06-16 03:12:10.726871: train_loss -0.5829 
2025-06-16 03:12:10.727921: val_loss -0.5943 
2025-06-16 03:12:10.728896: Pseudo dice [0.573, 0.9078, 0.8823, 0.8818] 
2025-06-16 03:12:10.729660: Epoch time: 64.76 s 
2025-06-16 03:12:12.463078:  
2025-06-16 03:12:12.464034: Epoch 227 
2025-06-16 03:12:12.464561: Current learning rate: 0.00793 
2025-06-16 03:13:08.356863: train_loss -0.5601 
2025-06-16 03:13:08.358444: val_loss -0.575 
2025-06-16 03:13:08.359596: Pseudo dice [0.5555, 0.9119, 0.8866, 0.8564] 
2025-06-16 03:13:08.360662: Epoch time: 55.89 s 
2025-06-16 03:13:10.688365:  
2025-06-16 03:13:10.689046: Epoch 228 
2025-06-16 03:13:10.689458: Current learning rate: 0.00792 
2025-06-16 03:14:08.481388: train_loss -0.5718 
2025-06-16 03:14:08.482690: val_loss -0.5874 
2025-06-16 03:14:08.483649: Pseudo dice [0.742, 0.9105, 0.9061, 0.8799] 
2025-06-16 03:14:08.484530: Epoch time: 57.79 s 
2025-06-16 03:14:10.385183:  
2025-06-16 03:14:10.385847: Epoch 229 
2025-06-16 03:14:10.386394: Current learning rate: 0.00791 
2025-06-16 03:15:10.878108: train_loss -0.5826 
2025-06-16 03:15:10.899085: val_loss -0.5791 
2025-06-16 03:15:10.899636: Pseudo dice [0.7628, 0.9133, 0.9078, 0.8937] 
2025-06-16 03:15:10.900527: Epoch time: 60.47 s 
2025-06-16 03:15:13.414284:  
2025-06-16 03:15:13.414887: Epoch 230 
2025-06-16 03:15:13.415311: Current learning rate: 0.0079 
2025-06-16 03:16:01.410160: train_loss -0.5844 
2025-06-16 03:16:01.411146: val_loss -0.6003 
2025-06-16 03:16:01.411793: Pseudo dice [0.7359, 0.9119, 0.9049, 0.8999] 
2025-06-16 03:16:01.412344: Epoch time: 48.0 s 
2025-06-16 03:16:03.086830:  
2025-06-16 03:16:03.087469: Epoch 231 
2025-06-16 03:16:03.088451: Current learning rate: 0.00789 
2025-06-16 03:17:05.749550: train_loss -0.5843 
2025-06-16 03:17:05.750529: val_loss -0.6162 
2025-06-16 03:17:05.751194: Pseudo dice [0.6839, 0.9198, 0.9033, 0.8708] 
2025-06-16 03:17:05.751699: Epoch time: 62.66 s 
2025-06-16 03:17:07.417050:  
2025-06-16 03:17:07.417578: Epoch 232 
2025-06-16 03:17:07.418004: Current learning rate: 0.00789 
2025-06-16 03:17:56.998067: train_loss -0.593 
2025-06-16 03:17:57.070051: val_loss -0.5819 
2025-06-16 03:17:57.070726: Pseudo dice [0.7343, 0.8955, 0.8968, 0.8928] 
2025-06-16 03:17:57.084662: Epoch time: 49.58 s 
2025-06-16 03:17:59.029181:  
2025-06-16 03:17:59.029720: Epoch 233 
2025-06-16 03:17:59.030139: Current learning rate: 0.00788 
2025-06-16 03:18:53.451473: train_loss -0.5823 
2025-06-16 03:18:53.452611: val_loss -0.6157 
2025-06-16 03:18:53.453482: Pseudo dice [0.7318, 0.9191, 0.8975, 0.9066] 
2025-06-16 03:18:53.454166: Epoch time: 54.42 s 
2025-06-16 03:18:57.531303:  
2025-06-16 03:18:57.531968: Epoch 234 
2025-06-16 03:18:57.532409: Current learning rate: 0.00787 
2025-06-16 03:20:00.038313: train_loss -0.5719 
2025-06-16 03:20:00.039099: val_loss -0.5886 
2025-06-16 03:20:00.039549: Pseudo dice [0.7688, 0.9035, 0.8913, 0.878] 
2025-06-16 03:20:00.040185: Epoch time: 62.51 s 
2025-06-16 03:20:01.987755:  
2025-06-16 03:20:01.988425: Epoch 235 
2025-06-16 03:20:01.988841: Current learning rate: 0.00786 
2025-06-16 03:20:54.668408: train_loss -0.5785 
2025-06-16 03:20:54.669248: val_loss -0.6032 
2025-06-16 03:20:54.669827: Pseudo dice [0.8124, 0.9109, 0.9035, 0.8914] 
2025-06-16 03:20:54.670269: Epoch time: 52.68 s 
2025-06-16 03:20:56.377311:  
2025-06-16 03:20:56.377923: Epoch 236 
2025-06-16 03:20:56.378336: Current learning rate: 0.00785 
2025-06-16 03:22:01.331312: train_loss -0.5894 
2025-06-16 03:22:01.344884: val_loss -0.6001 
2025-06-16 03:22:01.345987: Pseudo dice [0.7537, 0.9192, 0.8984, 0.9046] 
2025-06-16 03:22:01.347811: Epoch time: 64.93 s 
2025-06-16 03:22:03.941721:  
2025-06-16 03:22:03.942351: Epoch 237 
2025-06-16 03:22:03.942792: Current learning rate: 0.00784 
2025-06-16 03:22:57.470456: train_loss -0.5879 
2025-06-16 03:22:57.471554: val_loss -0.5998 
2025-06-16 03:22:57.472149: Pseudo dice [0.685, 0.8997, 0.9047, 0.8975] 
2025-06-16 03:22:57.472857: Epoch time: 53.53 s 
2025-06-16 03:22:59.654063:  
2025-06-16 03:22:59.654750: Epoch 238 
2025-06-16 03:22:59.655379: Current learning rate: 0.00783 
2025-06-16 03:24:03.740432: train_loss -0.5783 
2025-06-16 03:24:03.741336: val_loss -0.5997 
2025-06-16 03:24:03.741811: Pseudo dice [0.7841, 0.889, 0.9011, 0.8693] 
2025-06-16 03:24:03.742224: Epoch time: 64.09 s 
2025-06-16 03:24:05.371799:  
2025-06-16 03:24:05.372442: Epoch 239 
2025-06-16 03:24:05.372895: Current learning rate: 0.00782 
2025-06-16 03:24:55.625277: train_loss -0.5908 
2025-06-16 03:24:55.626305: val_loss -0.5735 
2025-06-16 03:24:55.626932: Pseudo dice [0.6247, 0.902, 0.8889, 0.8935] 
2025-06-16 03:24:55.627426: Epoch time: 50.25 s 
2025-06-16 03:24:57.503898:  
2025-06-16 03:24:57.504416: Epoch 240 
2025-06-16 03:24:57.504997: Current learning rate: 0.00781 
2025-06-16 03:25:57.841991: train_loss -0.5857 
2025-06-16 03:25:57.843198: val_loss -0.5932 
2025-06-16 03:25:57.844037: Pseudo dice [0.7602, 0.92, 0.8751, 0.9062] 
2025-06-16 03:25:57.844809: Epoch time: 60.34 s 
2025-06-16 03:25:59.989331:  
2025-06-16 03:25:59.989991: Epoch 241 
2025-06-16 03:25:59.990479: Current learning rate: 0.0078 
2025-06-16 03:26:57.042480: train_loss -0.5791 
2025-06-16 03:26:57.043374: val_loss -0.6156 
2025-06-16 03:26:57.043862: Pseudo dice [0.8613, 0.9055, 0.9086, 0.8659] 
2025-06-16 03:26:57.044324: Epoch time: 57.05 s 
2025-06-16 03:27:00.957413:  
2025-06-16 03:27:00.958106: Epoch 242 
2025-06-16 03:27:00.958588: Current learning rate: 0.00779 
2025-06-16 03:27:44.437395: train_loss -0.5893 
2025-06-16 03:27:44.438189: val_loss -0.6215 
2025-06-16 03:27:44.438611: Pseudo dice [0.7358, 0.9119, 0.9153, 0.9017] 
2025-06-16 03:27:44.438980: Epoch time: 43.48 s 
2025-06-16 03:27:44.439296: Yayy! New best EMA pseudo Dice: 0.8574 
2025-06-16 03:27:46.687065:  
2025-06-16 03:27:46.687594: Epoch 243 
2025-06-16 03:27:46.687962: Current learning rate: 0.00778 
2025-06-16 03:28:36.048991: train_loss -0.6199 
2025-06-16 03:28:36.050021: val_loss -0.6096 
2025-06-16 03:28:36.050528: Pseudo dice [0.6761, 0.9089, 0.9036, 0.9198] 
2025-06-16 03:28:36.051019: Epoch time: 49.36 s 
2025-06-16 03:28:37.979511:  
2025-06-16 03:28:37.980155: Epoch 244 
2025-06-16 03:28:37.980564: Current learning rate: 0.00777 
2025-06-16 03:29:43.309430: train_loss -0.5924 
2025-06-16 03:29:43.335538: val_loss -0.6265 
2025-06-16 03:29:43.336114: Pseudo dice [0.6582, 0.8897, 0.8686, 0.9184] 
2025-06-16 03:29:43.337030: Epoch time: 65.31 s 
2025-06-16 03:29:45.824438:  
2025-06-16 03:29:45.825041: Epoch 245 
2025-06-16 03:29:45.825471: Current learning rate: 0.00777 
2025-06-16 03:30:39.682364: train_loss -0.6089 
2025-06-16 03:30:39.683226: val_loss -0.6154 
2025-06-16 03:30:39.683826: Pseudo dice [0.8287, 0.9009, 0.9184, 0.9023] 
2025-06-16 03:30:39.684316: Epoch time: 53.86 s 
2025-06-16 03:30:39.684736: Yayy! New best EMA pseudo Dice: 0.8579 
2025-06-16 03:30:41.822003:  
2025-06-16 03:30:41.822715: Epoch 246 
2025-06-16 03:30:41.823748: Current learning rate: 0.00776 
2025-06-16 03:31:45.433186: train_loss -0.6117 
2025-06-16 03:31:45.434019: val_loss -0.6352 
2025-06-16 03:31:45.434565: Pseudo dice [0.698, 0.9166, 0.9025, 0.8951] 
2025-06-16 03:31:45.435152: Epoch time: 63.61 s 
2025-06-16 03:31:47.062809:  
2025-06-16 03:31:47.063381: Epoch 247 
2025-06-16 03:31:47.063964: Current learning rate: 0.00775 
2025-06-16 03:32:37.848866: train_loss -0.6032 
2025-06-16 03:32:37.850090: val_loss -0.6261 
2025-06-16 03:32:37.850921: Pseudo dice [0.6762, 0.9039, 0.8939, 0.9125] 
2025-06-16 03:32:37.851599: Epoch time: 50.79 s 
2025-06-16 03:32:39.910915:  
2025-06-16 03:32:39.911522: Epoch 248 
2025-06-16 03:32:39.911960: Current learning rate: 0.00774 
2025-06-16 03:33:26.393603: train_loss -0.6004 
2025-06-16 03:33:26.394597: val_loss -0.633 
2025-06-16 03:33:26.395423: Pseudo dice [0.7828, 0.9109, 0.8865, 0.8984] 
2025-06-16 03:33:26.396114: Epoch time: 46.48 s 
2025-06-16 03:33:30.619124:  
2025-06-16 03:33:30.620265: Epoch 249 
2025-06-16 03:33:30.621274: Current learning rate: 0.00773 
2025-06-16 03:34:35.045233: train_loss -0.6084 
2025-06-16 03:34:35.046526: val_loss -0.6429 
2025-06-16 03:34:35.047338: Pseudo dice [0.7762, 0.9149, 0.9078, 0.9057] 
2025-06-16 03:34:35.048183: Epoch time: 64.43 s 
2025-06-16 03:34:35.891015: Yayy! New best EMA pseudo Dice: 0.8595 
2025-06-16 03:34:38.399096:  
2025-06-16 03:34:38.399864: Epoch 250 
2025-06-16 03:34:38.400357: Current learning rate: 0.00772 
2025-06-16 03:35:33.053555: train_loss -0.6087 
2025-06-16 03:35:33.138762: val_loss -0.6313 
2025-06-16 03:35:33.139954: Pseudo dice [0.8253, 0.9014, 0.8961, 0.8959] 
2025-06-16 03:35:33.154311: Epoch time: 54.64 s 
2025-06-16 03:35:33.156083: Yayy! New best EMA pseudo Dice: 0.8615 
2025-06-16 03:35:36.444177:  
2025-06-16 03:35:36.444888: Epoch 251 
2025-06-16 03:35:36.445297: Current learning rate: 0.00771 
2025-06-16 03:36:27.921493: train_loss -0.6096 
2025-06-16 03:36:27.922529: val_loss -0.6085 
2025-06-16 03:36:27.923139: Pseudo dice [0.7796, 0.9077, 0.8981, 0.8727] 
2025-06-16 03:36:27.923856: Epoch time: 51.48 s 
2025-06-16 03:36:27.924396: Yayy! New best EMA pseudo Dice: 0.8618 
2025-06-16 03:36:30.091945:  
2025-06-16 03:36:30.092535: Epoch 252 
2025-06-16 03:36:30.092943: Current learning rate: 0.0077 
2025-06-16 03:37:38.842212: train_loss -0.6057 
2025-06-16 03:37:38.843557: val_loss -0.6274 
2025-06-16 03:37:38.844571: Pseudo dice [0.6691, 0.9177, 0.9178, 0.925] 
2025-06-16 03:37:38.845414: Epoch time: 68.75 s 
2025-06-16 03:37:40.797353:  
2025-06-16 03:37:40.798215: Epoch 253 
2025-06-16 03:37:40.798813: Current learning rate: 0.00769 
2025-06-16 03:38:30.174945: train_loss -0.6202 
2025-06-16 03:38:30.175856: val_loss -0.675 
2025-06-16 03:38:30.176507: Pseudo dice [0.7685, 0.917, 0.9149, 0.8953] 
2025-06-16 03:38:30.176990: Epoch time: 49.38 s 
2025-06-16 03:38:30.177464: Yayy! New best EMA pseudo Dice: 0.8626 
2025-06-16 03:38:31.958505:  
2025-06-16 03:38:31.959135: Epoch 254 
2025-06-16 03:38:31.959570: Current learning rate: 0.00768 
2025-06-16 03:39:24.683248: train_loss -0.5986 
2025-06-16 03:39:24.684678: val_loss -0.6071 
2025-06-16 03:39:24.685282: Pseudo dice [0.8035, 0.9038, 0.8979, 0.8817] 
2025-06-16 03:39:24.686282: Epoch time: 52.73 s 
2025-06-16 03:39:24.686863: Yayy! New best EMA pseudo Dice: 0.8635 
2025-06-16 03:39:26.860070:  
2025-06-16 03:39:26.860726: Epoch 255 
2025-06-16 03:39:26.861185: Current learning rate: 0.00767 
2025-06-16 03:40:28.954941: train_loss -0.6004 
2025-06-16 03:40:28.956597: val_loss -0.617 
2025-06-16 03:40:28.957120: Pseudo dice [0.7092, 0.9085, 0.9056, 0.9087] 
2025-06-16 03:40:28.957599: Epoch time: 62.1 s 
2025-06-16 03:40:30.853899:  
2025-06-16 03:40:30.854493: Epoch 256 
2025-06-16 03:40:30.855041: Current learning rate: 0.00766 
2025-06-16 03:41:16.980179: train_loss -0.6053 
2025-06-16 03:41:16.981069: val_loss -0.6128 
2025-06-16 03:41:16.981528: Pseudo dice [0.676, 0.904, 0.8802, 0.8778] 
2025-06-16 03:41:16.982108: Epoch time: 46.13 s 
2025-06-16 03:41:20.625949:  
2025-06-16 03:41:20.626796: Epoch 257 
2025-06-16 03:41:20.627225: Current learning rate: 0.00765 
2025-06-16 03:42:11.172573: train_loss -0.6018 
2025-06-16 03:42:11.173606: val_loss -0.615 
2025-06-16 03:42:11.174249: Pseudo dice [0.6797, 0.9187, 0.8855, 0.9086] 
2025-06-16 03:42:11.174879: Epoch time: 50.55 s 
2025-06-16 03:42:12.990662:  
2025-06-16 03:42:12.991355: Epoch 258 
2025-06-16 03:42:12.991946: Current learning rate: 0.00764 
2025-06-16 03:43:17.581908: train_loss -0.6018 
2025-06-16 03:43:17.613034: val_loss -0.6456 
2025-06-16 03:43:17.614118: Pseudo dice [0.7584, 0.9244, 0.9129, 0.8953] 
2025-06-16 03:43:17.621382: Epoch time: 64.56 s 
2025-06-16 03:43:19.918465:  
2025-06-16 03:43:19.919084: Epoch 259 
2025-06-16 03:43:19.919660: Current learning rate: 0.00764 
2025-06-16 03:44:16.559203: train_loss -0.6062 
2025-06-16 03:44:16.560173: val_loss -0.6265 
2025-06-16 03:44:16.560912: Pseudo dice [0.776, 0.9059, 0.9142, 0.9123] 
2025-06-16 03:44:16.561562: Epoch time: 56.64 s 
2025-06-16 03:44:18.373448:  
2025-06-16 03:44:18.374073: Epoch 260 
2025-06-16 03:44:18.374472: Current learning rate: 0.00763 
2025-06-16 03:45:19.189271: train_loss -0.6138 
2025-06-16 03:45:19.190232: val_loss -0.609 
2025-06-16 03:45:19.190816: Pseudo dice [0.7376, 0.9003, 0.9022, 0.8569] 
2025-06-16 03:45:19.191263: Epoch time: 60.82 s 
2025-06-16 03:45:20.923082:  
2025-06-16 03:45:20.923717: Epoch 261 
2025-06-16 03:45:20.924133: Current learning rate: 0.00762 
2025-06-16 03:46:12.050478: train_loss -0.6069 
2025-06-16 03:46:12.051342: val_loss -0.6345 
2025-06-16 03:46:12.051971: Pseudo dice [0.7979, 0.918, 0.9126, 0.8912] 
2025-06-16 03:46:12.052431: Epoch time: 51.13 s 
2025-06-16 03:46:14.108628:  
2025-06-16 03:46:14.109481: Epoch 262 
2025-06-16 03:46:14.109916: Current learning rate: 0.00761 
2025-06-16 03:47:09.591222: train_loss -0.5917 
2025-06-16 03:47:09.592544: val_loss -0.6054 
2025-06-16 03:47:09.593508: Pseudo dice [0.7952, 0.9029, 0.9211, 0.884] 
2025-06-16 03:47:09.594360: Epoch time: 55.48 s 
2025-06-16 03:47:09.595258: Yayy! New best EMA pseudo Dice: 0.864 
2025-06-16 03:47:12.662796:  
2025-06-16 03:47:12.663585: Epoch 263 
2025-06-16 03:47:12.664102: Current learning rate: 0.0076 
2025-06-16 03:48:13.510706: train_loss -0.6094 
2025-06-16 03:48:13.548692: val_loss -0.6148 
2025-06-16 03:48:13.549668: Pseudo dice [0.737, 0.9141, 0.8798, 0.8895] 
2025-06-16 03:48:13.551040: Epoch time: 60.85 s 
2025-06-16 03:48:17.348922:  
2025-06-16 03:48:17.349532: Epoch 264 
2025-06-16 03:48:17.349954: Current learning rate: 0.00759 
2025-06-16 03:49:02.347069: train_loss -0.604 
2025-06-16 03:49:02.347952: val_loss -0.6246 
2025-06-16 03:49:02.348421: Pseudo dice [0.8307, 0.9117, 0.9256, 0.9066] 
2025-06-16 03:49:02.348894: Epoch time: 45.0 s 
2025-06-16 03:49:02.349305: Yayy! New best EMA pseudo Dice: 0.8661 
2025-06-16 03:49:04.427521:  
2025-06-16 03:49:04.428195: Epoch 265 
2025-06-16 03:49:04.428635: Current learning rate: 0.00758 
2025-06-16 03:49:54.510152: train_loss -0.6023 
2025-06-16 03:49:54.511143: val_loss -0.5906 
2025-06-16 03:49:54.511979: Pseudo dice [0.6558, 0.9067, 0.8749, 0.8873] 
2025-06-16 03:49:54.512537: Epoch time: 50.08 s 
2025-06-16 03:49:56.289016:  
2025-06-16 03:49:56.289633: Epoch 266 
2025-06-16 03:49:56.290076: Current learning rate: 0.00757 
2025-06-16 03:50:58.679978: train_loss -0.6038 
2025-06-16 03:50:58.680927: val_loss -0.6095 
2025-06-16 03:50:58.681461: Pseudo dice [0.7146, 0.8928, 0.8864, 0.888] 
2025-06-16 03:50:58.682146: Epoch time: 62.39 s 
2025-06-16 03:51:00.452929:  
2025-06-16 03:51:00.453578: Epoch 267 
2025-06-16 03:51:00.453974: Current learning rate: 0.00756 
2025-06-16 03:51:55.694009: train_loss -0.6035 
2025-06-16 03:51:55.701139: val_loss -0.6172 
2025-06-16 03:51:55.701740: Pseudo dice [0.7285, 0.9047, 0.9073, 0.8919] 
2025-06-16 03:51:55.703007: Epoch time: 55.22 s 
2025-06-16 03:51:58.201454:  
2025-06-16 03:51:58.202163: Epoch 268 
2025-06-16 03:51:58.202590: Current learning rate: 0.00755 
2025-06-16 03:52:51.025617: train_loss -0.6139 
2025-06-16 03:52:51.026759: val_loss -0.6141 
2025-06-16 03:52:51.027396: Pseudo dice [0.7465, 0.9076, 0.8579, 0.8854] 
2025-06-16 03:52:51.028323: Epoch time: 52.83 s 
2025-06-16 03:52:52.796674:  
2025-06-16 03:52:52.797211: Epoch 269 
2025-06-16 03:52:52.797771: Current learning rate: 0.00754 
2025-06-16 03:53:54.324099: train_loss -0.5985 
2025-06-16 03:53:54.324996: val_loss -0.6163 
2025-06-16 03:53:54.325560: Pseudo dice [0.7876, 0.9123, 0.9234, 0.901] 
2025-06-16 03:53:54.325997: Epoch time: 61.53 s 
2025-06-16 03:53:55.988344:  
2025-06-16 03:53:55.989085: Epoch 270 
2025-06-16 03:53:55.989515: Current learning rate: 0.00753 
2025-06-16 03:54:46.159081: train_loss -0.6087 
2025-06-16 03:54:46.227550: val_loss -0.5934 
2025-06-16 03:54:46.228755: Pseudo dice [0.6254, 0.8944, 0.8813, 0.88] 
2025-06-16 03:54:46.241269: Epoch time: 50.17 s 
2025-06-16 03:54:48.239201:  
2025-06-16 03:54:48.239927: Epoch 271 
2025-06-16 03:54:48.240376: Current learning rate: 0.00752 
2025-06-16 03:55:48.538607: train_loss -0.5945 
2025-06-16 03:55:48.540113: val_loss -0.6189 
2025-06-16 03:55:48.540964: Pseudo dice [0.6971, 0.9101, 0.873, 0.914] 
2025-06-16 03:55:48.541743: Epoch time: 60.3 s 
2025-06-16 03:55:57.844408:  
2025-06-16 03:55:57.845040: Epoch 272 
2025-06-16 03:55:57.845786: Current learning rate: 0.00751 
2025-06-16 03:56:49.330588: train_loss -0.598 
2025-06-16 03:56:49.331386: val_loss -0.6178 
2025-06-16 03:56:49.331849: Pseudo dice [0.6339, 0.9136, 0.8995, 0.8879] 
2025-06-16 03:56:49.332584: Epoch time: 51.49 s 
2025-06-16 03:56:50.804442:  
2025-06-16 03:56:50.805041: Epoch 273 
2025-06-16 03:56:50.805589: Current learning rate: 0.00751 
2025-06-16 03:57:33.688444: train_loss -0.6006 
2025-06-16 03:57:33.689155: val_loss -0.6017 
2025-06-16 03:57:33.689545: Pseudo dice [0.682, 0.9131, 0.9017, 0.8899] 
2025-06-16 03:57:33.690058: Epoch time: 42.89 s 
2025-06-16 03:57:35.387552:  
2025-06-16 03:57:35.388212: Epoch 274 
2025-06-16 03:57:35.388647: Current learning rate: 0.0075 
2025-06-16 03:58:26.444404: train_loss -0.6006 
2025-06-16 03:58:26.445361: val_loss -0.6338 
2025-06-16 03:58:26.446141: Pseudo dice [0.7886, 0.9118, 0.9004, 0.8908] 
2025-06-16 03:58:26.446733: Epoch time: 51.06 s 
2025-06-16 03:58:28.226183:  
2025-06-16 03:58:28.226786: Epoch 275 
2025-06-16 03:58:28.227377: Current learning rate: 0.00749 
2025-06-16 03:59:32.355649: train_loss -0.613 
2025-06-16 03:59:32.360889: val_loss -0.6203 
2025-06-16 03:59:32.361784: Pseudo dice [0.7588, 0.919, 0.917, 0.9138] 
2025-06-16 03:59:32.363357: Epoch time: 64.1 s 
2025-06-16 03:59:34.550741:  
2025-06-16 03:59:34.551369: Epoch 276 
2025-06-16 03:59:34.551943: Current learning rate: 0.00748 
2025-06-16 04:00:28.929101: train_loss -0.6163 
2025-06-16 04:00:28.930155: val_loss -0.5553 
2025-06-16 04:00:28.930693: Pseudo dice [0.246, 0.8997, 0.7614, 0.9075] 
2025-06-16 04:00:28.931475: Epoch time: 54.38 s 
2025-06-16 04:00:30.821606:  
2025-06-16 04:00:30.822342: Epoch 277 
2025-06-16 04:00:30.822846: Current learning rate: 0.00747 
2025-06-16 04:01:31.205270: train_loss -0.5822 
2025-06-16 04:01:31.210587: val_loss -0.6168 
2025-06-16 04:01:31.211085: Pseudo dice [0.724, 0.8941, 0.8715, 0.895] 
2025-06-16 04:01:31.211480: Epoch time: 60.38 s 
2025-06-16 04:01:32.853235:  
2025-06-16 04:01:32.853997: Epoch 278 
2025-06-16 04:01:32.854414: Current learning rate: 0.00746 
2025-06-16 04:02:21.742834: train_loss -0.615 
2025-06-16 04:02:21.743750: val_loss -0.6241 
2025-06-16 04:02:21.744268: Pseudo dice [0.7851, 0.9197, 0.9042, 0.8955] 
2025-06-16 04:02:21.744901: Epoch time: 48.89 s 
2025-06-16 04:02:25.282397:  
2025-06-16 04:02:25.283179: Epoch 279 
2025-06-16 04:02:25.283615: Current learning rate: 0.00745 
2025-06-16 04:03:08.647959: train_loss -0.6215 
2025-06-16 04:03:08.648861: val_loss -0.6251 
2025-06-16 04:03:08.649335: Pseudo dice [0.8131, 0.9015, 0.9129, 0.8918] 
2025-06-16 04:03:08.649764: Epoch time: 43.37 s 
2025-06-16 04:03:09.995538:  
2025-06-16 04:03:09.996177: Epoch 280 
2025-06-16 04:03:09.996673: Current learning rate: 0.00744 
2025-06-16 04:04:01.245717: train_loss -0.602 
2025-06-16 04:04:01.246698: val_loss -0.6021 
2025-06-16 04:04:01.247272: Pseudo dice [0.6676, 0.9139, 0.8986, 0.8762] 
2025-06-16 04:04:01.247774: Epoch time: 51.25 s 
2025-06-16 04:04:02.984709:  
2025-06-16 04:04:02.985320: Epoch 281 
2025-06-16 04:04:02.986097: Current learning rate: 0.00743 
2025-06-16 04:05:02.853818: train_loss -0.6158 
2025-06-16 04:05:02.949918: val_loss -0.6277 
2025-06-16 04:05:02.950532: Pseudo dice [0.7, 0.9053, 0.9108, 0.9184] 
2025-06-16 04:05:02.972361: Epoch time: 59.87 s 
2025-06-16 04:05:05.057899:  
2025-06-16 04:05:05.058515: Epoch 282 
2025-06-16 04:05:05.058909: Current learning rate: 0.00742 
2025-06-16 04:05:58.991244: train_loss -0.6128 
2025-06-16 04:05:58.992445: val_loss -0.6258 
2025-06-16 04:05:58.993164: Pseudo dice [0.7474, 0.9188, 0.9109, 0.8871] 
2025-06-16 04:05:58.993962: Epoch time: 53.93 s 
2025-06-16 04:06:00.954079:  
2025-06-16 04:06:00.954832: Epoch 283 
2025-06-16 04:06:00.955422: Current learning rate: 0.00741 
2025-06-16 04:07:03.900304: train_loss -0.6151 
2025-06-16 04:07:03.901376: val_loss -0.6281 
2025-06-16 04:07:03.902143: Pseudo dice [0.7309, 0.914, 0.9078, 0.9266] 
2025-06-16 04:07:03.902861: Epoch time: 62.95 s 
2025-06-16 04:07:05.769436:  
2025-06-16 04:07:05.770076: Epoch 284 
2025-06-16 04:07:05.770461: Current learning rate: 0.0074 
2025-06-16 04:07:55.041022: train_loss -0.6116 
2025-06-16 04:07:55.041752: val_loss -0.6254 
2025-06-16 04:07:55.042180: Pseudo dice [0.774, 0.9034, 0.8858, 0.9044] 
2025-06-16 04:07:55.042551: Epoch time: 49.27 s 
2025-06-16 04:07:56.629101:  
2025-06-16 04:07:56.629707: Epoch 285 
2025-06-16 04:07:56.630306: Current learning rate: 0.00739 
2025-06-16 04:08:49.592130: train_loss -0.6209 
2025-06-16 04:08:49.593201: val_loss -0.61 
2025-06-16 04:08:49.593951: Pseudo dice [0.7201, 0.9031, 0.8668, 0.8888] 
2025-06-16 04:08:49.594542: Epoch time: 52.96 s 
2025-06-16 04:08:51.492644:  
2025-06-16 04:08:51.493336: Epoch 286 
2025-06-16 04:08:51.493880: Current learning rate: 0.00738 
2025-06-16 04:09:55.597917: train_loss -0.6138 
2025-06-16 04:09:55.599011: val_loss -0.6341 
2025-06-16 04:09:55.599585: Pseudo dice [0.8577, 0.9084, 0.9153, 0.9011] 
2025-06-16 04:09:55.600322: Epoch time: 64.11 s 
2025-06-16 04:09:59.227352:  
2025-06-16 04:09:59.227951: Epoch 287 
2025-06-16 04:09:59.228373: Current learning rate: 0.00738 
2025-06-16 04:10:46.277275: train_loss -0.6136 
2025-06-16 04:10:46.278332: val_loss -0.6096 
2025-06-16 04:10:46.279091: Pseudo dice [0.7325, 0.9151, 0.9136, 0.8771] 
2025-06-16 04:10:46.279673: Epoch time: 47.05 s 
2025-06-16 04:10:47.774365:  
2025-06-16 04:10:47.774898: Epoch 288 
2025-06-16 04:10:47.775336: Current learning rate: 0.00737 
2025-06-16 04:11:38.119182: train_loss -0.6131 
2025-06-16 04:11:38.120159: val_loss -0.6119 
2025-06-16 04:11:38.120886: Pseudo dice [0.8182, 0.9163, 0.8671, 0.9128] 
2025-06-16 04:11:38.121433: Epoch time: 50.35 s 
2025-06-16 04:11:40.053882:  
2025-06-16 04:11:40.054761: Epoch 289 
2025-06-16 04:11:40.055260: Current learning rate: 0.00736 
2025-06-16 04:12:40.999019: train_loss -0.6122 
2025-06-16 04:12:41.000158: val_loss -0.5678 
2025-06-16 04:12:41.000940: Pseudo dice [0.7299, 0.9207, 0.8722, 0.8951] 
2025-06-16 04:12:41.001736: Epoch time: 60.95 s 
2025-06-16 04:12:43.017118:  
2025-06-16 04:12:43.017868: Epoch 290 
2025-06-16 04:12:43.018279: Current learning rate: 0.00735 
2025-06-16 04:13:38.094988: train_loss -0.599 
2025-06-16 04:13:38.106811: val_loss -0.6135 
2025-06-16 04:13:38.107829: Pseudo dice [0.7323, 0.9066, 0.9117, 0.8769] 
2025-06-16 04:13:38.109576: Epoch time: 55.04 s 
2025-06-16 04:13:40.843956:  
2025-06-16 04:13:40.844620: Epoch 291 
2025-06-16 04:13:40.845037: Current learning rate: 0.00734 
2025-06-16 04:14:37.355630: train_loss -0.6099 
2025-06-16 04:14:37.356807: val_loss -0.6028 
2025-06-16 04:14:37.357531: Pseudo dice [0.5376, 0.9038, 0.9011, 0.9098] 
2025-06-16 04:14:37.358272: Epoch time: 56.51 s 
2025-06-16 04:14:39.480779:  
2025-06-16 04:14:39.481417: Epoch 292 
2025-06-16 04:14:39.481822: Current learning rate: 0.00733 
2025-06-16 04:15:41.900045: train_loss -0.5922 
2025-06-16 04:15:41.901438: val_loss -0.5977 
2025-06-16 04:15:41.901995: Pseudo dice [0.7094, 0.8863, 0.8959, 0.8578] 
2025-06-16 04:15:41.902470: Epoch time: 62.42 s 
2025-06-16 04:15:44.083445:  
2025-06-16 04:15:44.084198: Epoch 293 
2025-06-16 04:15:44.084636: Current learning rate: 0.00732 
2025-06-16 04:16:37.813950: train_loss -0.6098 
2025-06-16 04:16:37.815150: val_loss -0.6308 
2025-06-16 04:16:37.816051: Pseudo dice [0.6962, 0.9096, 0.8855, 0.8907] 
2025-06-16 04:16:37.823113: Epoch time: 53.73 s 
2025-06-16 04:16:43.619805:  
2025-06-16 04:16:43.620465: Epoch 294 
2025-06-16 04:16:43.620884: Current learning rate: 0.00731 
2025-06-16 04:17:45.027294: train_loss -0.6091 
2025-06-16 04:17:45.028294: val_loss -0.625 
2025-06-16 04:17:45.029234: Pseudo dice [0.6916, 0.9063, 0.8835, 0.9076] 
2025-06-16 04:17:45.030006: Epoch time: 61.41 s 
2025-06-16 04:17:46.362418:  
2025-06-16 04:17:46.363001: Epoch 295 
2025-06-16 04:17:46.363368: Current learning rate: 0.0073 
2025-06-16 04:18:36.354568: train_loss -0.6179 
2025-06-16 04:18:36.355586: val_loss -0.6376 
2025-06-16 04:18:36.356073: Pseudo dice [0.7654, 0.9191, 0.9152, 0.8919] 
2025-06-16 04:18:36.356524: Epoch time: 49.99 s 
2025-06-16 04:18:37.589533:  
2025-06-16 04:18:37.590142: Epoch 296 
2025-06-16 04:18:37.590575: Current learning rate: 0.00729 
2025-06-16 04:19:24.791362: train_loss -0.6141 
2025-06-16 04:19:24.792550: val_loss -0.6306 
2025-06-16 04:19:24.793371: Pseudo dice [0.7188, 0.9139, 0.9037, 0.8863] 
2025-06-16 04:19:24.794039: Epoch time: 47.2 s 
2025-06-16 04:19:26.260852:  
2025-06-16 04:19:26.261557: Epoch 297 
2025-06-16 04:19:26.262021: Current learning rate: 0.00728 
2025-06-16 04:20:25.349520: train_loss -0.6142 
2025-06-16 04:20:25.350565: val_loss -0.6238 
2025-06-16 04:20:25.351129: Pseudo dice [0.7903, 0.9004, 0.9056, 0.8893] 
2025-06-16 04:20:25.351920: Epoch time: 59.09 s 
2025-06-16 04:20:27.307981:  
2025-06-16 04:20:27.308702: Epoch 298 
2025-06-16 04:20:27.309226: Current learning rate: 0.00727 
2025-06-16 04:21:25.764836: train_loss -0.6136 
2025-06-16 04:21:25.790269: val_loss -0.6485 
2025-06-16 04:21:25.791172: Pseudo dice [0.8426, 0.9079, 0.8946, 0.9032] 
2025-06-16 04:21:25.792386: Epoch time: 58.43 s 
2025-06-16 04:21:28.525345:  
2025-06-16 04:21:28.526068: Epoch 299 
2025-06-16 04:21:28.526534: Current learning rate: 0.00726 
2025-06-16 04:22:25.668807: train_loss -0.6296 
2025-06-16 04:22:25.669697: val_loss -0.6221 
2025-06-16 04:22:25.670316: Pseudo dice [0.7674, 0.9064, 0.9054, 0.8759] 
2025-06-16 04:22:25.670935: Epoch time: 57.14 s 
2025-06-16 04:22:28.308065:  
2025-06-16 04:22:28.308776: Epoch 300 
2025-06-16 04:22:28.309379: Current learning rate: 0.00725 
2025-06-16 04:23:32.641683: train_loss -0.5911 
2025-06-16 04:23:32.643108: val_loss -0.5787 
2025-06-16 04:23:32.643982: Pseudo dice [0.5366, 0.8947, 0.8698, 0.8852] 
2025-06-16 04:23:32.644708: Epoch time: 64.33 s 
2025-06-16 04:23:34.027830:  
2025-06-16 04:23:34.028409: Epoch 301 
2025-06-16 04:23:34.028802: Current learning rate: 0.00724 
2025-06-16 04:24:29.488406: train_loss -0.5873 
2025-06-16 04:24:29.489378: val_loss -0.6144 
2025-06-16 04:24:29.489972: Pseudo dice [0.7886, 0.9058, 0.914, 0.8806] 
2025-06-16 04:24:29.490543: Epoch time: 55.46 s 
2025-06-16 04:24:34.804111:  
2025-06-16 04:24:34.805131: Epoch 302 
2025-06-16 04:24:34.805616: Current learning rate: 0.00724 
2025-06-16 04:25:39.568563: train_loss -0.57 
2025-06-16 04:25:39.569276: val_loss -0.5727 
2025-06-16 04:25:39.569784: Pseudo dice [0.67, 0.8826, 0.8855, 0.8401] 
2025-06-16 04:25:39.570168: Epoch time: 64.77 s 
2025-06-16 04:25:40.901654:  
2025-06-16 04:25:40.902282: Epoch 303 
2025-06-16 04:25:40.902709: Current learning rate: 0.00723 
2025-06-16 04:26:29.867936: train_loss -0.5738 
2025-06-16 04:26:29.868824: val_loss -0.6071 
2025-06-16 04:26:29.869275: Pseudo dice [0.7362, 0.9083, 0.9052, 0.8607] 
2025-06-16 04:26:29.869820: Epoch time: 48.97 s 
2025-06-16 04:26:31.583586:  
2025-06-16 04:26:31.584203: Epoch 304 
2025-06-16 04:26:31.584636: Current learning rate: 0.00722 
2025-06-16 04:27:19.718252: train_loss -0.5937 
2025-06-16 04:27:19.719739: val_loss -0.6093 
2025-06-16 04:27:19.720448: Pseudo dice [0.582, 0.9084, 0.8905, 0.8795] 
2025-06-16 04:27:19.721488: Epoch time: 48.14 s 
2025-06-16 04:27:21.762735:  
2025-06-16 04:27:21.763384: Epoch 305 
2025-06-16 04:27:21.763953: Current learning rate: 0.00721 
2025-06-16 04:28:24.556032: train_loss -0.6225 
2025-06-16 04:28:24.557432: val_loss -0.6295 
2025-06-16 04:28:24.558704: Pseudo dice [0.7353, 0.9094, 0.8859, 0.866] 
2025-06-16 04:28:24.559521: Epoch time: 62.79 s 
2025-06-16 04:28:26.763816:  
2025-06-16 04:28:26.764581: Epoch 306 
2025-06-16 04:28:26.765238: Current learning rate: 0.0072 
2025-06-16 04:29:22.335038: train_loss -0.627 
2025-06-16 04:29:22.429710: val_loss -0.6413 
2025-06-16 04:29:22.430397: Pseudo dice [0.7714, 0.9205, 0.916, 0.9093] 
2025-06-16 04:29:22.445837: Epoch time: 55.53 s 
2025-06-16 04:29:24.587717:  
2025-06-16 04:29:24.588270: Epoch 307 
2025-06-16 04:29:24.588643: Current learning rate: 0.00719 
2025-06-16 04:30:15.990726: train_loss -0.6111 
2025-06-16 04:30:15.991881: val_loss -0.6346 
2025-06-16 04:30:15.992516: Pseudo dice [0.7577, 0.9091, 0.8902, 0.9008] 
2025-06-16 04:30:15.993474: Epoch time: 51.4 s 
2025-06-16 04:30:17.785633:  
2025-06-16 04:30:17.786234: Epoch 308 
2025-06-16 04:30:17.786638: Current learning rate: 0.00718 
2025-06-16 04:31:22.160124: train_loss -0.6217 
2025-06-16 04:31:22.161361: val_loss -0.6468 
2025-06-16 04:31:22.162209: Pseudo dice [0.8253, 0.9086, 0.9294, 0.927] 
2025-06-16 04:31:22.162946: Epoch time: 64.38 s 
2025-06-16 04:31:24.193467:  
2025-06-16 04:31:24.194081: Epoch 309 
2025-06-16 04:31:24.194508: Current learning rate: 0.00717 
2025-06-16 04:32:17.928094: train_loss -0.609 
2025-06-16 04:32:17.929281: val_loss -0.6178 
2025-06-16 04:32:17.930188: Pseudo dice [0.736, 0.9154, 0.9181, 0.8627] 
2025-06-16 04:32:17.930881: Epoch time: 53.74 s 
2025-06-16 04:32:22.878533:  
2025-06-16 04:32:22.879278: Epoch 310 
2025-06-16 04:32:22.879705: Current learning rate: 0.00716 
2025-06-16 04:33:27.767388: train_loss -0.6072 
2025-06-16 04:33:27.768272: val_loss -0.6327 
2025-06-16 04:33:27.768738: Pseudo dice [0.8267, 0.9136, 0.8802, 0.9011] 
2025-06-16 04:33:27.769164: Epoch time: 64.89 s 
2025-06-16 04:33:29.476912:  
2025-06-16 04:33:29.477529: Epoch 311 
2025-06-16 04:33:29.478109: Current learning rate: 0.00715 
2025-06-16 04:34:23.475198: train_loss -0.6103 
2025-06-16 04:34:23.476398: val_loss -0.6345 
2025-06-16 04:34:23.477294: Pseudo dice [0.7951, 0.8991, 0.915, 0.9028] 
2025-06-16 04:34:23.477900: Epoch time: 54.0 s 
2025-06-16 04:34:25.721802:  
2025-06-16 04:34:25.722385: Epoch 312 
2025-06-16 04:34:25.722994: Current learning rate: 0.00714 
2025-06-16 04:35:22.453122: train_loss -0.6264 
2025-06-16 04:35:22.454203: val_loss -0.6181 
2025-06-16 04:35:22.455352: Pseudo dice [0.7447, 0.9117, 0.9006, 0.8832] 
2025-06-16 04:35:22.455991: Epoch time: 56.73 s 
2025-06-16 04:35:24.559927:  
2025-06-16 04:35:24.560634: Epoch 313 
2025-06-16 04:35:24.561133: Current learning rate: 0.00713 
2025-06-16 04:36:27.413556: train_loss -0.6164 
2025-06-16 04:36:27.418308: val_loss -0.6127 
2025-06-16 04:36:27.418941: Pseudo dice [0.62, 0.9077, 0.9042, 0.876] 
2025-06-16 04:36:27.420125: Epoch time: 62.82 s 
2025-06-16 04:36:29.535254:  
2025-06-16 04:36:29.535914: Epoch 314 
2025-06-16 04:36:29.536327: Current learning rate: 0.00712 
2025-06-16 04:37:22.013893: train_loss -0.6181 
2025-06-16 04:37:22.014869: val_loss -0.6224 
2025-06-16 04:37:22.015409: Pseudo dice [0.739, 0.9134, 0.9176, 0.9011] 
2025-06-16 04:37:22.016108: Epoch time: 52.48 s 
2025-06-16 04:37:23.767932:  
2025-06-16 04:37:23.768481: Epoch 315 
2025-06-16 04:37:23.768867: Current learning rate: 0.00711 
2025-06-16 04:38:23.006023: train_loss -0.6241 
2025-06-16 04:38:23.006952: val_loss -0.6285 
2025-06-16 04:38:23.007467: Pseudo dice [0.7612, 0.9153, 0.9119, 0.9193] 
2025-06-16 04:38:23.008149: Epoch time: 59.24 s 
2025-06-16 04:38:24.761408:  
2025-06-16 04:38:24.762055: Epoch 316 
2025-06-16 04:38:24.762470: Current learning rate: 0.0071 
2025-06-16 04:39:15.024465: train_loss -0.6165 
2025-06-16 04:39:15.025216: val_loss -0.6316 
2025-06-16 04:39:15.025908: Pseudo dice [0.8193, 0.9183, 0.9287, 0.8944] 
2025-06-16 04:39:15.026454: Epoch time: 50.26 s 
2025-06-16 04:39:18.534694:  
2025-06-16 04:39:18.535319: Epoch 317 
2025-06-16 04:39:18.535777: Current learning rate: 0.0071 
2025-06-16 04:40:09.150195: train_loss -0.6206 
2025-06-16 04:40:09.151266: val_loss -0.6249 
2025-06-16 04:40:09.152209: Pseudo dice [0.6276, 0.9117, 0.8547, 0.841] 
2025-06-16 04:40:09.152887: Epoch time: 50.62 s 
2025-06-16 04:40:11.168673:  
2025-06-16 04:40:11.169665: Epoch 318 
2025-06-16 04:40:11.170157: Current learning rate: 0.00709 
2025-06-16 04:41:13.656188: train_loss -0.6134 
2025-06-16 04:41:13.657235: val_loss -0.6297 
2025-06-16 04:41:13.658201: Pseudo dice [0.7858, 0.9162, 0.9021, 0.9147] 
2025-06-16 04:41:13.658887: Epoch time: 62.49 s 
2025-06-16 04:41:15.430658:  
2025-06-16 04:41:15.431264: Epoch 319 
2025-06-16 04:41:15.431702: Current learning rate: 0.00708 
2025-06-16 04:42:12.907166: train_loss -0.616 
2025-06-16 04:42:13.007529: val_loss -0.6275 
2025-06-16 04:42:13.008570: Pseudo dice [0.7881, 0.9141, 0.8937, 0.8486] 
2025-06-16 04:42:13.053876: Epoch time: 57.45 s 
2025-06-16 04:42:15.977677:  
2025-06-16 04:42:15.978269: Epoch 320 
2025-06-16 04:42:15.978705: Current learning rate: 0.00707 
2025-06-16 04:43:10.507571: train_loss -0.6144 
2025-06-16 04:43:10.508914: val_loss -0.6342 
2025-06-16 04:43:10.509936: Pseudo dice [0.7657, 0.9205, 0.9013, 0.8879] 
2025-06-16 04:43:10.510824: Epoch time: 54.53 s 
2025-06-16 04:43:12.471694:  
2025-06-16 04:43:12.472324: Epoch 321 
2025-06-16 04:43:12.472831: Current learning rate: 0.00706 
2025-06-16 04:44:17.016317: train_loss -0.6267 
2025-06-16 04:44:17.017281: val_loss -0.6275 
2025-06-16 04:44:17.018016: Pseudo dice [0.8006, 0.9064, 0.8845, 0.8947] 
2025-06-16 04:44:17.018612: Epoch time: 64.55 s 
2025-06-16 04:44:18.855628:  
2025-06-16 04:44:18.856461: Epoch 322 
2025-06-16 04:44:18.856898: Current learning rate: 0.00705 
2025-06-16 04:45:14.466305: train_loss -0.6045 
2025-06-16 04:45:14.467323: val_loss -0.6048 
2025-06-16 04:45:14.468047: Pseudo dice [0.6163, 0.9103, 0.8777, 0.8947] 
2025-06-16 04:45:14.468699: Epoch time: 55.61 s 
2025-06-16 04:45:16.697290:  
2025-06-16 04:45:16.698096: Epoch 323 
2025-06-16 04:45:16.698628: Current learning rate: 0.00704 
2025-06-16 04:46:27.038364: train_loss -0.5878 
2025-06-16 04:46:27.039596: val_loss -0.6285 
2025-06-16 04:46:27.040489: Pseudo dice [0.7075, 0.9085, 0.9054, 0.8652] 
2025-06-16 04:46:27.041245: Epoch time: 70.34 s 
2025-06-16 04:46:30.843184:  
2025-06-16 04:46:30.843939: Epoch 324 
2025-06-16 04:46:30.844835: Current learning rate: 0.00703 
2025-06-16 04:47:23.161161: train_loss -0.6029 
2025-06-16 04:47:23.162079: val_loss -0.6069 
2025-06-16 04:47:23.162591: Pseudo dice [0.5257, 0.9082, 0.8795, 0.9144] 
2025-06-16 04:47:23.163032: Epoch time: 52.32 s 
2025-06-16 04:47:24.880210:  
2025-06-16 04:47:24.880860: Epoch 325 
2025-06-16 04:47:24.881263: Current learning rate: 0.00702 
2025-06-16 04:48:18.515580: train_loss -0.6083 
2025-06-16 04:48:18.516458: val_loss -0.6278 
2025-06-16 04:48:18.517244: Pseudo dice [0.7226, 0.9185, 0.9169, 0.8982] 
2025-06-16 04:48:18.517969: Epoch time: 53.64 s 
2025-06-16 04:48:20.377635:  
2025-06-16 04:48:20.378253: Epoch 326 
2025-06-16 04:48:20.378671: Current learning rate: 0.00701 
2025-06-16 04:49:21.312983: train_loss -0.603 
2025-06-16 04:49:21.313802: val_loss -0.6303 
2025-06-16 04:49:21.314244: Pseudo dice [0.7459, 0.9081, 0.8839, 0.8828] 
2025-06-16 04:49:21.314618: Epoch time: 60.94 s 
2025-06-16 04:49:23.195602:  
2025-06-16 04:49:23.196259: Epoch 327 
2025-06-16 04:49:23.196791: Current learning rate: 0.007 
2025-06-16 04:50:22.169556: train_loss -0.6192 
2025-06-16 04:50:22.203795: val_loss -0.6265 
2025-06-16 04:50:22.204944: Pseudo dice [0.8175, 0.9104, 0.9176, 0.8926] 
2025-06-16 04:50:22.212286: Epoch time: 58.95 s 
2025-06-16 04:50:24.726184:  
2025-06-16 04:50:24.726820: Epoch 328 
2025-06-16 04:50:24.727239: Current learning rate: 0.00699 
2025-06-16 04:51:31.028395: train_loss -0.6078 
2025-06-16 04:51:31.029204: val_loss -0.6274 
2025-06-16 04:51:31.029643: Pseudo dice [0.7145, 0.9051, 0.905, 0.9068] 
2025-06-16 04:51:31.030053: Epoch time: 66.3 s 
2025-06-16 04:51:32.682521:  
2025-06-16 04:51:32.683086: Epoch 329 
2025-06-16 04:51:32.683592: Current learning rate: 0.00698 
2025-06-16 04:52:24.887416: train_loss -0.626 
2025-06-16 04:52:24.888400: val_loss -0.6396 
2025-06-16 04:52:24.889112: Pseudo dice [0.8492, 0.9199, 0.9032, 0.9054] 
2025-06-16 04:52:24.889865: Epoch time: 52.21 s 
2025-06-16 04:52:26.897456:  
2025-06-16 04:52:26.898079: Epoch 330 
2025-06-16 04:52:26.898493: Current learning rate: 0.00697 
2025-06-16 04:53:22.569244: train_loss -0.6195 
2025-06-16 04:53:22.570756: val_loss -0.6064 
2025-06-16 04:53:22.571596: Pseudo dice [0.6243, 0.8981, 0.9304, 0.8969] 
2025-06-16 04:53:22.572594: Epoch time: 55.67 s 
2025-06-16 04:53:24.516916:  
2025-06-16 04:53:24.517592: Epoch 331 
2025-06-16 04:53:24.518009: Current learning rate: 0.00696 
2025-06-16 04:54:26.588387: train_loss -0.6258 
2025-06-16 04:54:26.589651: val_loss -0.6391 
2025-06-16 04:54:26.590073: Pseudo dice [0.8294, 0.9069, 0.9017, 0.9232] 
2025-06-16 04:54:26.590435: Epoch time: 62.07 s 
2025-06-16 04:54:30.419448:  
2025-06-16 04:54:30.420154: Epoch 332 
2025-06-16 04:54:30.420658: Current learning rate: 0.00696 
2025-06-16 04:55:22.317688: train_loss -0.5807 
2025-06-16 04:55:22.318703: val_loss -0.5881 
2025-06-16 04:55:22.319263: Pseudo dice [0.6689, 0.8821, 0.89, 0.9037] 
2025-06-16 04:55:22.320235: Epoch time: 51.9 s 
2025-06-16 04:55:24.080156:  
2025-06-16 04:55:24.080797: Epoch 333 
2025-06-16 04:55:24.081322: Current learning rate: 0.00695 
2025-06-16 04:56:28.175127: train_loss -0.5921 
2025-06-16 04:56:28.175987: val_loss -0.6036 
2025-06-16 04:56:28.180116: Pseudo dice [0.682, 0.8921, 0.8913, 0.8597] 
2025-06-16 04:56:28.180572: Epoch time: 64.1 s 
2025-06-16 04:56:29.918919:  
2025-06-16 04:56:29.919595: Epoch 334 
2025-06-16 04:56:29.920141: Current learning rate: 0.00694 
2025-06-16 04:57:23.455430: train_loss -0.607 
2025-06-16 04:57:23.576077: val_loss -0.6177 
2025-06-16 04:57:23.577357: Pseudo dice [0.8151, 0.9066, 0.9067, 0.9152] 
2025-06-16 04:57:23.596761: Epoch time: 53.52 s 
2025-06-16 04:57:26.512686:  
2025-06-16 04:57:26.513301: Epoch 335 
2025-06-16 04:57:26.513810: Current learning rate: 0.00693 
2025-06-16 04:58:14.750353: train_loss -0.6268 
2025-06-16 04:58:14.751721: val_loss -0.6688 
2025-06-16 04:58:14.752432: Pseudo dice [0.7309, 0.9182, 0.8938, 0.8862] 
2025-06-16 04:58:14.753459: Epoch time: 48.24 s 
2025-06-16 04:58:16.798516:  
2025-06-16 04:58:16.799423: Epoch 336 
2025-06-16 04:58:16.800003: Current learning rate: 0.00692 
2025-06-16 04:59:13.757586: train_loss -0.6138 
2025-06-16 04:59:13.764354: val_loss -0.6303 
2025-06-16 04:59:13.765002: Pseudo dice [0.7413, 0.9078, 0.9085, 0.9072] 
2025-06-16 04:59:13.765422: Epoch time: 56.96 s 
2025-06-16 04:59:15.645878:  
2025-06-16 04:59:15.646547: Epoch 337 
2025-06-16 04:59:15.646960: Current learning rate: 0.00691 
2025-06-16 05:00:10.592660: train_loss -0.6184 
2025-06-16 05:00:10.618435: val_loss -0.6397 
2025-06-16 05:00:10.619436: Pseudo dice [0.7887, 0.9198, 0.9047, 0.8989] 
2025-06-16 05:00:10.641396: Epoch time: 54.93 s 
2025-06-16 05:00:12.850796:  
2025-06-16 05:00:12.851388: Epoch 338 
2025-06-16 05:00:12.851836: Current learning rate: 0.0069 
2025-06-16 05:01:06.085527: train_loss -0.6121 
2025-06-16 05:01:06.086991: val_loss -0.6369 
2025-06-16 05:01:06.087963: Pseudo dice [0.8227, 0.9152, 0.9213, 0.89] 
2025-06-16 05:01:06.088689: Epoch time: 53.24 s 
2025-06-16 05:01:09.868251:  
2025-06-16 05:01:09.868982: Epoch 339 
2025-06-16 05:01:09.869411: Current learning rate: 0.00689 
2025-06-16 05:02:03.758380: train_loss -0.6226 
2025-06-16 05:02:03.759345: val_loss -0.6179 
2025-06-16 05:02:03.759874: Pseudo dice [0.7755, 0.9054, 0.9071, 0.904] 
2025-06-16 05:02:03.760336: Epoch time: 53.89 s 
2025-06-16 05:02:06.015656:  
2025-06-16 05:02:06.016296: Epoch 340 
2025-06-16 05:02:06.016743: Current learning rate: 0.00688 
2025-06-16 05:02:58.882709: train_loss -0.6234 
2025-06-16 05:02:58.883559: val_loss -0.6224 
2025-06-16 05:02:58.884014: Pseudo dice [0.7359, 0.9172, 0.8966, 0.8517] 
2025-06-16 05:02:58.884455: Epoch time: 52.87 s 
2025-06-16 05:03:00.637470:  
2025-06-16 05:03:00.638556: Epoch 341 
2025-06-16 05:03:00.639483: Current learning rate: 0.00687 
2025-06-16 05:03:52.875065: train_loss -0.6161 
2025-06-16 05:03:52.875984: val_loss -0.6374 
2025-06-16 05:03:52.876493: Pseudo dice [0.6712, 0.9117, 0.883, 0.8991] 
2025-06-16 05:03:52.877141: Epoch time: 52.24 s 
2025-06-16 05:03:54.615748:  
2025-06-16 05:03:54.616693: Epoch 342 
2025-06-16 05:03:54.617413: Current learning rate: 0.00686 
2025-06-16 05:04:44.231292: train_loss -0.5979 
2025-06-16 05:04:44.232202: val_loss -0.6155 
2025-06-16 05:04:44.233122: Pseudo dice [0.5394, 0.905, 0.8622, 0.9157] 
2025-06-16 05:04:44.233999: Epoch time: 49.62 s 
2025-06-16 05:04:46.016767:  
2025-06-16 05:04:46.017452: Epoch 343 
2025-06-16 05:04:46.017906: Current learning rate: 0.00685 
2025-06-16 05:05:39.128028: train_loss -0.6153 
2025-06-16 05:05:39.129494: val_loss -0.6378 
2025-06-16 05:05:39.129980: Pseudo dice [0.8129, 0.9135, 0.8768, 0.9141] 
2025-06-16 05:05:39.130434: Epoch time: 53.11 s 
2025-06-16 05:05:41.220501:  
2025-06-16 05:05:41.221256: Epoch 344 
2025-06-16 05:05:41.221803: Current learning rate: 0.00684 
2025-06-16 05:06:33.122091: train_loss -0.6078 
2025-06-16 05:06:33.123199: val_loss -0.6238 
2025-06-16 05:06:33.123860: Pseudo dice [0.8176, 0.9108, 0.9126, 0.9079] 
2025-06-16 05:06:33.124487: Epoch time: 51.9 s 
2025-06-16 05:06:34.940487:  
2025-06-16 05:06:34.941226: Epoch 345 
2025-06-16 05:06:34.941643: Current learning rate: 0.00683 
2025-06-16 05:07:28.026432: train_loss -0.6074 
2025-06-16 05:07:28.043030: val_loss -0.6038 
2025-06-16 05:07:28.044034: Pseudo dice [0.6902, 0.9112, 0.9022, 0.8721] 
2025-06-16 05:07:28.045754: Epoch time: 53.06 s 
2025-06-16 05:07:32.574504:  
2025-06-16 05:07:32.575141: Epoch 346 
2025-06-16 05:07:32.575663: Current learning rate: 0.00682 
2025-06-16 05:08:24.802645: train_loss -0.626 
2025-06-16 05:08:24.803398: val_loss -0.6196 
2025-06-16 05:08:24.803828: Pseudo dice [0.7626, 0.9144, 0.907, 0.8991] 
2025-06-16 05:08:24.804384: Epoch time: 52.23 s 
2025-06-16 05:08:26.705413:  
2025-06-16 05:08:26.706067: Epoch 347 
2025-06-16 05:08:26.706577: Current learning rate: 0.00681 
2025-06-16 05:09:23.251126: train_loss -0.6164 
2025-06-16 05:09:23.252322: val_loss -0.6162 
2025-06-16 05:09:23.253209: Pseudo dice [0.8231, 0.889, 0.9048, 0.8719] 
2025-06-16 05:09:23.253957: Epoch time: 56.55 s 
2025-06-16 05:09:25.010690:  
2025-06-16 05:09:25.011292: Epoch 348 
2025-06-16 05:09:25.011743: Current learning rate: 0.0068 
2025-06-16 05:10:26.824170: train_loss -0.604 
2025-06-16 05:10:26.825463: val_loss -0.615 
2025-06-16 05:10:26.826067: Pseudo dice [0.697, 0.9023, 0.9075, 0.9036] 
2025-06-16 05:10:26.826712: Epoch time: 61.81 s 
2025-06-16 05:10:28.776922:  
2025-06-16 05:10:28.777753: Epoch 349 
2025-06-16 05:10:28.778261: Current learning rate: 0.0068 
2025-06-16 05:11:34.502732: train_loss -0.5977 
2025-06-16 05:11:34.507417: val_loss -0.6242 
2025-06-16 05:11:34.507939: Pseudo dice [0.7539, 0.9154, 0.8948, 0.8904] 
2025-06-16 05:11:34.508860: Epoch time: 65.73 s 
2025-06-16 05:11:38.455178:  
2025-06-16 05:11:38.455874: Epoch 350 
2025-06-16 05:11:38.456306: Current learning rate: 0.00679 
2025-06-16 05:12:29.583843: train_loss -0.6149 
2025-06-16 05:12:29.585009: val_loss -0.5948 
2025-06-16 05:12:29.585689: Pseudo dice [0.6404, 0.8846, 0.9014, 0.8397] 
2025-06-16 05:12:29.586633: Epoch time: 51.13 s 
2025-06-16 05:12:31.656878:  
2025-06-16 05:12:31.657510: Epoch 351 
2025-06-16 05:12:31.657964: Current learning rate: 0.00678 
2025-06-16 05:13:24.331814: train_loss -0.609 
2025-06-16 05:13:24.332808: val_loss -0.6294 
2025-06-16 05:13:24.333283: Pseudo dice [0.7169, 0.9135, 0.9074, 0.8886] 
2025-06-16 05:13:24.333867: Epoch time: 52.68 s 
2025-06-16 05:13:26.128912:  
2025-06-16 05:13:26.129963: Epoch 352 
2025-06-16 05:13:26.130694: Current learning rate: 0.00677 
2025-06-16 05:14:18.842099: train_loss -0.6148 
2025-06-16 05:14:18.842954: val_loss -0.6489 
2025-06-16 05:14:18.843405: Pseudo dice [0.7978, 0.9148, 0.8815, 0.9075] 
2025-06-16 05:14:18.844096: Epoch time: 52.72 s 
2025-06-16 05:14:22.157280:  
2025-06-16 05:14:22.157869: Epoch 353 
2025-06-16 05:14:22.158306: Current learning rate: 0.00676 
2025-06-16 05:15:18.280004: train_loss -0.6132 
2025-06-16 05:15:18.285587: val_loss -0.6444 
2025-06-16 05:15:18.286870: Pseudo dice [0.7698, 0.9144, 0.9115, 0.8871] 
2025-06-16 05:15:18.288865: Epoch time: 56.1 s 
2025-06-16 05:15:20.329246:  
2025-06-16 05:15:20.329830: Epoch 354 
2025-06-16 05:15:20.330227: Current learning rate: 0.00675 
2025-06-16 05:16:18.275451: train_loss -0.6157 
2025-06-16 05:16:18.276543: val_loss -0.6025 
2025-06-16 05:16:18.277216: Pseudo dice [0.621, 0.9066, 0.902, 0.9182] 
2025-06-16 05:16:18.278038: Epoch time: 57.95 s 
2025-06-16 05:16:20.373702:  
2025-06-16 05:16:20.374491: Epoch 355 
2025-06-16 05:16:20.375000: Current learning rate: 0.00674 
2025-06-16 05:17:26.439046: train_loss -0.6076 
2025-06-16 05:17:26.440144: val_loss -0.6509 
2025-06-16 05:17:26.440976: Pseudo dice [0.7896, 0.9133, 0.9224, 0.8632] 
2025-06-16 05:17:26.441793: Epoch time: 66.07 s 
2025-06-16 05:17:28.835358:  
2025-06-16 05:17:28.835995: Epoch 356 
2025-06-16 05:17:28.836412: Current learning rate: 0.00673 
2025-06-16 05:18:22.745478: train_loss -0.6285 
2025-06-16 05:18:22.746282: val_loss -0.6403 
2025-06-16 05:18:22.746855: Pseudo dice [0.8137, 0.9162, 0.902, 0.8982] 
2025-06-16 05:18:22.747313: Epoch time: 53.91 s 
2025-06-16 05:18:24.678494:  
2025-06-16 05:18:24.679081: Epoch 357 
2025-06-16 05:18:24.679479: Current learning rate: 0.00672 
2025-06-16 05:19:29.756796: train_loss -0.6251 
2025-06-16 05:19:29.758176: val_loss -0.616 
2025-06-16 05:19:29.758985: Pseudo dice [0.7505, 0.9034, 0.9097, 0.8772] 
2025-06-16 05:19:29.759694: Epoch time: 65.08 s 
2025-06-16 05:19:31.739193:  
2025-06-16 05:19:31.739827: Epoch 358 
2025-06-16 05:19:31.740251: Current learning rate: 0.00671 
2025-06-16 05:20:31.960277: train_loss -0.6339 
2025-06-16 05:20:31.961120: val_loss -0.6397 
2025-06-16 05:20:31.961810: Pseudo dice [0.7956, 0.9313, 0.921, 0.9117] 
2025-06-16 05:20:31.962382: Epoch time: 60.22 s 
2025-06-16 05:20:34.076917:  
2025-06-16 05:20:34.077541: Epoch 359 
2025-06-16 05:20:34.078206: Current learning rate: 0.0067 
2025-06-16 05:21:48.898402: train_loss -0.646 
2025-06-16 05:21:48.899445: val_loss -0.6358 
2025-06-16 05:21:48.900030: Pseudo dice [0.7983, 0.9137, 0.8925, 0.9105] 
2025-06-16 05:21:48.900872: Epoch time: 74.82 s 
2025-06-16 05:21:50.632056:  
2025-06-16 05:21:50.632833: Epoch 360 
2025-06-16 05:21:50.633292: Current learning rate: 0.00669 
2025-06-16 05:22:43.613215: train_loss -0.6383 
2025-06-16 05:22:43.721691: val_loss -0.6208 
2025-06-16 05:22:43.722565: Pseudo dice [0.7936, 0.9139, 0.9092, 0.9076] 
2025-06-16 05:22:43.754352: Epoch time: 52.98 s 
2025-06-16 05:22:43.771575: Yayy! New best EMA pseudo Dice: 0.867 
2025-06-16 05:22:48.639379:  
2025-06-16 05:22:48.639987: Epoch 361 
2025-06-16 05:22:48.640395: Current learning rate: 0.00668 
2025-06-16 05:23:40.596079: train_loss -0.6244 
2025-06-16 05:23:40.597406: val_loss -0.6184 
2025-06-16 05:23:40.598157: Pseudo dice [0.7887, 0.9114, 0.9137, 0.9279] 
2025-06-16 05:23:40.598890: Epoch time: 51.96 s 
2025-06-16 05:23:40.599477: Yayy! New best EMA pseudo Dice: 0.8689 
2025-06-16 05:23:43.012865:  
2025-06-16 05:23:43.013554: Epoch 362 
2025-06-16 05:23:43.013980: Current learning rate: 0.00667 
2025-06-16 05:24:41.858221: train_loss -0.6141 
2025-06-16 05:24:41.858994: val_loss -0.6178 
2025-06-16 05:24:41.859420: Pseudo dice [0.7238, 0.8915, 0.8744, 0.8755] 
2025-06-16 05:24:41.859824: Epoch time: 58.85 s 
2025-06-16 05:24:43.208899:  
2025-06-16 05:24:43.209533: Epoch 363 
2025-06-16 05:24:43.210054: Current learning rate: 0.00666 
2025-06-16 05:25:37.020999: train_loss -0.6145 
2025-06-16 05:25:37.022079: val_loss -0.6236 
2025-06-16 05:25:37.022696: Pseudo dice [0.7327, 0.9161, 0.9087, 0.9134] 
2025-06-16 05:25:37.023432: Epoch time: 53.81 s 
2025-06-16 05:25:39.429211:  
2025-06-16 05:25:39.430007: Epoch 364 
2025-06-16 05:25:39.430748: Current learning rate: 0.00665 
2025-06-16 05:26:50.278696: train_loss -0.6128 
2025-06-16 05:26:50.279600: val_loss -0.61 
2025-06-16 05:26:50.280235: Pseudo dice [0.7798, 0.8734, 0.8932, 0.8818] 
2025-06-16 05:26:50.280747: Epoch time: 70.85 s 
2025-06-16 05:26:51.978011:  
2025-06-16 05:26:51.978645: Epoch 365 
2025-06-16 05:26:51.979104: Current learning rate: 0.00665 
2025-06-16 05:27:41.960187: train_loss -0.608 
2025-06-16 05:27:41.989468: val_loss -0.6322 
2025-06-16 05:27:41.990371: Pseudo dice [0.7791, 0.9192, 0.8884, 0.8964] 
2025-06-16 05:27:41.991579: Epoch time: 49.98 s 
2025-06-16 05:27:44.064734:  
2025-06-16 05:27:44.065313: Epoch 366 
2025-06-16 05:27:44.065909: Current learning rate: 0.00664 
2025-06-16 05:28:37.136497: train_loss -0.6289 
2025-06-16 05:28:37.146884: val_loss -0.6391 
2025-06-16 05:28:37.147448: Pseudo dice [0.8073, 0.9123, 0.9205, 0.888] 
2025-06-16 05:28:37.147979: Epoch time: 53.07 s 
2025-06-16 05:28:40.485601:  
2025-06-16 05:28:40.486144: Epoch 367 
2025-06-16 05:28:40.486698: Current learning rate: 0.00663 
2025-06-16 05:29:46.945758: train_loss -0.6238 
2025-06-16 05:29:47.026391: val_loss -0.6149 
2025-06-16 05:29:47.027142: Pseudo dice [0.7751, 0.8856, 0.9152, 0.8737] 
2025-06-16 05:29:47.042625: Epoch time: 66.46 s 
2025-06-16 05:29:49.332897:  
2025-06-16 05:29:49.333535: Epoch 368 
2025-06-16 05:29:49.333942: Current learning rate: 0.00662 
2025-06-16 05:30:42.669934: train_loss -0.6188 
2025-06-16 05:30:42.696583: val_loss -0.6422 
2025-06-16 05:30:42.697450: Pseudo dice [0.7547, 0.9158, 0.9052, 0.9079] 
2025-06-16 05:30:42.698902: Epoch time: 53.32 s 
2025-06-16 05:30:45.235290:  
2025-06-16 05:30:45.236244: Epoch 369 
2025-06-16 05:30:45.237149: Current learning rate: 0.00661 
2025-06-16 05:31:41.823211: train_loss -0.6247 
2025-06-16 05:31:41.824079: val_loss -0.6538 
2025-06-16 05:31:41.824941: Pseudo dice [0.791, 0.9121, 0.9057, 0.9151] 
2025-06-16 05:31:41.825453: Epoch time: 56.59 s 
2025-06-16 05:31:43.622387:  
2025-06-16 05:31:43.623129: Epoch 370 
2025-06-16 05:31:43.623666: Current learning rate: 0.0066 
2025-06-16 05:32:44.323591: train_loss -0.6261 
2025-06-16 05:32:44.324738: val_loss -0.5946 
2025-06-16 05:32:44.325315: Pseudo dice [0.5446, 0.9024, 0.8225, 0.8959] 
2025-06-16 05:32:44.326029: Epoch time: 60.7 s 
2025-06-16 05:32:46.228675:  
2025-06-16 05:32:46.229412: Epoch 371 
2025-06-16 05:32:46.229899: Current learning rate: 0.00659 
2025-06-16 05:33:39.094978: train_loss -0.625 
2025-06-16 05:33:39.096052: val_loss -0.6169 
2025-06-16 05:33:39.096862: Pseudo dice [0.8343, 0.9085, 0.9134, 0.8772] 
2025-06-16 05:33:39.097650: Epoch time: 52.87 s 
2025-06-16 05:33:40.924892:  
2025-06-16 05:33:40.925491: Epoch 372 
2025-06-16 05:33:40.925904: Current learning rate: 0.00658 
2025-06-16 05:34:43.966622: train_loss -0.6212 
2025-06-16 05:34:43.967899: val_loss -0.6003 
2025-06-16 05:34:43.968556: Pseudo dice [0.7267, 0.9095, 0.9042, 0.905] 
2025-06-16 05:34:43.969319: Epoch time: 63.04 s 
2025-06-16 05:34:46.106747:  
2025-06-16 05:34:46.107519: Epoch 373 
2025-06-16 05:34:46.108151: Current learning rate: 0.00657 
2025-06-16 05:35:36.492304: train_loss -0.6222 
2025-06-16 05:35:36.493490: val_loss -0.6373 
2025-06-16 05:35:36.494236: Pseudo dice [0.7447, 0.9104, 0.9073, 0.9054] 
2025-06-16 05:35:36.494914: Epoch time: 50.39 s 
2025-06-16 05:35:38.242926:  
2025-06-16 05:35:38.243476: Epoch 374 
2025-06-16 05:35:38.244023: Current learning rate: 0.00656 
2025-06-16 05:36:33.579356: train_loss -0.6266 
2025-06-16 05:36:33.580334: val_loss -0.607 
2025-06-16 05:36:33.581232: Pseudo dice [0.6275, 0.9263, 0.8939, 0.9177] 
2025-06-16 05:36:33.581681: Epoch time: 55.34 s 
2025-06-16 05:36:38.703930:  
2025-06-16 05:36:38.704635: Epoch 375 
2025-06-16 05:36:38.705439: Current learning rate: 0.00655 
2025-06-16 05:37:40.006352: train_loss -0.6213 
2025-06-16 05:37:40.027676: val_loss -0.6174 
2025-06-16 05:37:40.028635: Pseudo dice [0.7238, 0.9131, 0.8883, 0.8847] 
2025-06-16 05:37:40.030083: Epoch time: 61.27 s 
2025-06-16 05:37:42.532360:  
2025-06-16 05:37:42.533139: Epoch 376 
2025-06-16 05:37:42.533552: Current learning rate: 0.00654 
2025-06-16 05:38:38.713673: train_loss -0.6071 
2025-06-16 05:38:38.714731: val_loss -0.6362 
2025-06-16 05:38:38.715394: Pseudo dice [0.7713, 0.908, 0.9127, 0.8776] 
2025-06-16 05:38:38.716089: Epoch time: 56.18 s 
2025-06-16 05:38:40.897162:  
2025-06-16 05:38:40.897797: Epoch 377 
2025-06-16 05:38:40.898299: Current learning rate: 0.00653 
2025-06-16 05:39:43.652652: train_loss -0.6109 
2025-06-16 05:39:43.653854: val_loss -0.6306 
2025-06-16 05:39:43.654684: Pseudo dice [0.7659, 0.9061, 0.9123, 0.9108] 
2025-06-16 05:39:43.655369: Epoch time: 62.76 s 
2025-06-16 05:39:45.539154:  
2025-06-16 05:39:45.539750: Epoch 378 
2025-06-16 05:39:45.540164: Current learning rate: 0.00652 
2025-06-16 05:40:40.300127: train_loss -0.6199 
2025-06-16 05:40:40.301961: val_loss -0.6535 
2025-06-16 05:40:40.303103: Pseudo dice [0.8401, 0.9207, 0.9374, 0.9166] 
2025-06-16 05:40:40.303623: Epoch time: 54.76 s 
2025-06-16 05:40:42.281373:  
2025-06-16 05:40:42.281992: Epoch 379 
2025-06-16 05:40:42.282410: Current learning rate: 0.00651 
2025-06-16 05:41:47.530570: train_loss -0.6286 
2025-06-16 05:41:47.531460: val_loss -0.654 
2025-06-16 05:41:47.532303: Pseudo dice [0.7759, 0.9239, 0.9159, 0.9155] 
2025-06-16 05:41:47.532871: Epoch time: 65.25 s 
2025-06-16 05:41:49.499316:  
2025-06-16 05:41:49.499949: Epoch 380 
2025-06-16 05:41:49.500419: Current learning rate: 0.0065 
2025-06-16 05:42:42.959932: train_loss -0.6112 
2025-06-16 05:42:43.036007: val_loss -0.6382 
2025-06-16 05:42:43.037088: Pseudo dice [0.7592, 0.9145, 0.9117, 0.8932] 
2025-06-16 05:42:43.284165: Epoch time: 53.46 s 
2025-06-16 05:42:46.394708:  
2025-06-16 05:42:46.395456: Epoch 381 
2025-06-16 05:42:46.395891: Current learning rate: 0.00649 
2025-06-16 05:43:48.468484: train_loss -0.6145 
2025-06-16 05:43:48.469975: val_loss -0.6061 
2025-06-16 05:43:48.470797: Pseudo dice [0.7134, 0.9034, 0.9149, 0.8856] 
2025-06-16 05:43:48.471645: Epoch time: 62.07 s 
2025-06-16 05:43:56.598994:  
2025-06-16 05:43:56.599674: Epoch 382 
2025-06-16 05:43:56.600418: Current learning rate: 0.00648 
2025-06-16 05:44:51.076234: train_loss -0.6116 
2025-06-16 05:44:51.116134: val_loss -0.6127 
2025-06-16 05:44:51.116724: Pseudo dice [0.747, 0.8874, 0.9044, 0.8951] 
2025-06-16 05:44:51.117678: Epoch time: 54.41 s 
2025-06-16 05:44:53.478836:  
2025-06-16 05:44:53.479433: Epoch 383 
2025-06-16 05:44:53.479838: Current learning rate: 0.00648 
2025-06-16 05:45:50.971553: train_loss -0.6177 
2025-06-16 05:45:50.972423: val_loss -0.6557 
2025-06-16 05:45:50.973186: Pseudo dice [0.8393, 0.9219, 0.9028, 0.9066] 
2025-06-16 05:45:50.973765: Epoch time: 57.49 s 
2025-06-16 05:45:52.933405:  
2025-06-16 05:45:52.934216: Epoch 384 
2025-06-16 05:45:52.934772: Current learning rate: 0.00647 
2025-06-16 05:46:55.409976: train_loss -0.6265 
2025-06-16 05:46:55.411040: val_loss -0.6368 
2025-06-16 05:46:55.411566: Pseudo dice [0.7968, 0.8979, 0.8981, 0.9104] 
2025-06-16 05:46:55.412035: Epoch time: 62.48 s 
2025-06-16 05:46:55.412444: Yayy! New best EMA pseudo Dice: 0.8694 
2025-06-16 05:46:58.231543:  
2025-06-16 05:46:58.232218: Epoch 385 
2025-06-16 05:46:58.232632: Current learning rate: 0.00646 
2025-06-16 05:47:51.474219: train_loss -0.6227 
2025-06-16 05:47:51.475292: val_loss -0.6233 
2025-06-16 05:47:51.476157: Pseudo dice [0.7301, 0.9154, 0.9129, 0.8731] 
2025-06-16 05:47:51.476846: Epoch time: 53.24 s 
2025-06-16 05:47:53.300168:  
2025-06-16 05:47:53.300780: Epoch 386 
2025-06-16 05:47:53.301454: Current learning rate: 0.00645 
2025-06-16 05:48:55.655900: train_loss -0.6317 
2025-06-16 05:48:55.656657: val_loss -0.6377 
2025-06-16 05:48:55.657127: Pseudo dice [0.8095, 0.9072, 0.9241, 0.9156] 
2025-06-16 05:48:55.657509: Epoch time: 62.36 s 
2025-06-16 05:48:55.658033: Yayy! New best EMA pseudo Dice: 0.8703 
2025-06-16 05:48:57.396810:  
2025-06-16 05:48:57.397397: Epoch 387 
2025-06-16 05:48:57.397792: Current learning rate: 0.00644 
2025-06-16 05:49:45.258039: train_loss -0.6166 
2025-06-16 05:49:45.259386: val_loss -0.6334 
2025-06-16 05:49:45.260456: Pseudo dice [0.709, 0.9015, 0.9028, 0.9252] 
2025-06-16 05:49:45.260990: Epoch time: 47.86 s 
2025-06-16 05:49:47.344781:  
2025-06-16 05:49:47.345551: Epoch 388 
2025-06-16 05:49:47.346019: Current learning rate: 0.00643 
2025-06-16 05:50:44.149941: train_loss -0.6143 
2025-06-16 05:50:44.151108: val_loss -0.6215 
2025-06-16 05:50:44.152103: Pseudo dice [0.7455, 0.908, 0.9001, 0.8835] 
2025-06-16 05:50:44.153111: Epoch time: 56.81 s 
2025-06-16 05:50:52.008562:  
2025-06-16 05:50:52.009265: Epoch 389 
2025-06-16 05:50:52.009982: Current learning rate: 0.00642 
2025-06-16 05:51:47.889945: train_loss -0.6132 
2025-06-16 05:51:47.894051: val_loss -0.605 
2025-06-16 05:51:47.894816: Pseudo dice [0.8188, 0.9147, 0.9072, 0.8786] 
2025-06-16 05:51:47.896144: Epoch time: 55.86 s 
2025-06-16 05:51:50.203707:  
2025-06-16 05:51:50.204314: Epoch 390 
2025-06-16 05:51:50.204861: Current learning rate: 0.00641 
2025-06-16 05:52:41.503882: train_loss -0.6267 
2025-06-16 05:52:41.504937: val_loss -0.6282 
2025-06-16 05:52:41.505426: Pseudo dice [0.734, 0.9099, 0.901, 0.82] 
2025-06-16 05:52:41.506185: Epoch time: 51.3 s 
2025-06-16 05:52:43.286254:  
2025-06-16 05:52:43.286866: Epoch 391 
2025-06-16 05:52:43.287597: Current learning rate: 0.0064 
2025-06-16 05:53:47.030942: train_loss -0.6099 
2025-06-16 05:53:47.031921: val_loss -0.623 
2025-06-16 05:53:47.032554: Pseudo dice [0.806, 0.9122, 0.9186, 0.8981] 
2025-06-16 05:53:47.033303: Epoch time: 63.75 s 
2025-06-16 05:53:48.937809:  
2025-06-16 05:53:48.938356: Epoch 392 
2025-06-16 05:53:48.938783: Current learning rate: 0.00639 
2025-06-16 05:54:44.155123: train_loss -0.6269 
2025-06-16 05:54:44.242218: val_loss -0.6462 
2025-06-16 05:54:44.243160: Pseudo dice [0.7893, 0.8989, 0.9133, 0.8974] 
2025-06-16 05:54:44.258247: Epoch time: 55.22 s 
2025-06-16 05:54:47.809164:  
2025-06-16 05:54:47.810289: Epoch 393 
2025-06-16 05:54:47.810959: Current learning rate: 0.00638 
2025-06-16 05:55:48.876937: train_loss -0.6316 
2025-06-16 05:55:48.877917: val_loss -0.6243 
2025-06-16 05:55:48.878773: Pseudo dice [0.7736, 0.9026, 0.8802, 0.8981] 
2025-06-16 05:55:48.879452: Epoch time: 61.07 s 
2025-06-16 05:55:50.950905:  
2025-06-16 05:55:50.951750: Epoch 394 
2025-06-16 05:55:50.952344: Current learning rate: 0.00637 
2025-06-16 05:56:47.490150: train_loss -0.6207 
2025-06-16 05:56:47.491261: val_loss -0.6424 
2025-06-16 05:56:47.492329: Pseudo dice [0.7852, 0.9196, 0.9053, 0.885] 
2025-06-16 05:56:47.493148: Epoch time: 56.54 s 
2025-06-16 05:56:49.483717:  
2025-06-16 05:56:49.484780: Epoch 395 
2025-06-16 05:56:49.485579: Current learning rate: 0.00636 
2025-06-16 05:57:41.060256: train_loss -0.6122 
2025-06-16 05:57:41.061539: val_loss -0.6313 
2025-06-16 05:57:41.062437: Pseudo dice [0.7321, 0.9282, 0.9009, 0.8965] 
2025-06-16 05:57:41.063198: Epoch time: 51.58 s 
2025-06-16 05:57:45.239284:  
2025-06-16 05:57:45.239997: Epoch 396 
2025-06-16 05:57:45.240477: Current learning rate: 0.00635 
2025-06-16 05:58:49.184008: train_loss -0.6137 
2025-06-16 05:58:49.184875: val_loss -0.6018 
2025-06-16 05:58:49.185372: Pseudo dice [0.6954, 0.9006, 0.8927, 0.8673] 
2025-06-16 05:58:49.185864: Epoch time: 63.95 s 
2025-06-16 05:58:50.944089:  
2025-06-16 05:58:50.944791: Epoch 397 
2025-06-16 05:58:50.945328: Current learning rate: 0.00634 
2025-06-16 05:59:46.748852: train_loss -0.6201 
2025-06-16 05:59:46.750118: val_loss -0.6521 
2025-06-16 05:59:46.750748: Pseudo dice [0.6962, 0.9159, 0.8872, 0.893] 
2025-06-16 05:59:46.751362: Epoch time: 55.81 s 
2025-06-16 05:59:48.712855:  
2025-06-16 05:59:48.713440: Epoch 398 
2025-06-16 05:59:48.714005: Current learning rate: 0.00633 
2025-06-16 06:00:39.168833: train_loss -0.6369 
2025-06-16 06:00:39.170005: val_loss -0.6437 
2025-06-16 06:00:39.170674: Pseudo dice [0.7997, 0.918, 0.9063, 0.873] 
2025-06-16 06:00:39.171528: Epoch time: 50.46 s 
2025-06-16 06:00:40.939307:  
2025-06-16 06:00:40.939947: Epoch 399 
2025-06-16 06:00:40.940382: Current learning rate: 0.00632 
2025-06-16 06:01:29.700466: train_loss -0.616 
2025-06-16 06:01:29.705246: val_loss -0.6137 
2025-06-16 06:01:29.706517: Pseudo dice [0.7665, 0.9082, 0.8917, 0.9066] 
2025-06-16 06:01:29.708155: Epoch time: 48.75 s 
2025-06-16 06:01:33.105875:  
2025-06-16 06:01:33.106462: Epoch 400 
2025-06-16 06:01:33.106880: Current learning rate: 0.00631 
2025-06-16 06:02:24.057867: train_loss -0.6164 
2025-06-16 06:02:24.058518: val_loss -0.6161 
2025-06-16 06:02:24.059057: Pseudo dice [0.8659, 0.9086, 0.8991, 0.8976] 
2025-06-16 06:02:24.059462: Epoch time: 50.95 s 
2025-06-16 06:02:25.542639:  
2025-06-16 06:02:25.543221: Epoch 401 
2025-06-16 06:02:25.543622: Current learning rate: 0.0063 
2025-06-16 06:03:17.434703: train_loss -0.6133 
2025-06-16 06:03:17.435417: val_loss -0.6043 
2025-06-16 06:03:17.435833: Pseudo dice [0.7298, 0.8903, 0.8886, 0.8817] 
2025-06-16 06:03:17.436195: Epoch time: 51.89 s 
2025-06-16 06:03:19.296671:  
2025-06-16 06:03:19.297230: Epoch 402 
2025-06-16 06:03:19.297656: Current learning rate: 0.0063 
2025-06-16 06:04:21.206726: train_loss -0.6108 
2025-06-16 06:04:21.207794: val_loss -0.594 
2025-06-16 06:04:21.208337: Pseudo dice [0.7691, 0.887, 0.9005, 0.8676] 
2025-06-16 06:04:21.208819: Epoch time: 61.91 s 
2025-06-16 06:04:24.540790:  
2025-06-16 06:04:24.541412: Epoch 403 
2025-06-16 06:04:24.541837: Current learning rate: 0.00629 
2025-06-16 06:05:17.016804: train_loss -0.5917 
2025-06-16 06:05:17.018028: val_loss -0.5962 
2025-06-16 06:05:17.019063: Pseudo dice [0.8043, 0.9208, 0.9168, 0.8879] 
2025-06-16 06:05:17.019714: Epoch time: 52.48 s 
2025-06-16 06:05:19.428958:  
2025-06-16 06:05:19.429745: Epoch 404 
2025-06-16 06:05:19.430519: Current learning rate: 0.00628 
2025-06-16 06:06:18.188145: train_loss -0.6057 
2025-06-16 06:06:18.189301: val_loss -0.6298 
2025-06-16 06:06:18.190560: Pseudo dice [0.7905, 0.9018, 0.9229, 0.9014] 
2025-06-16 06:06:18.191620: Epoch time: 58.76 s 
2025-06-16 06:06:20.273569:  
2025-06-16 06:06:20.274186: Epoch 405 
2025-06-16 06:06:20.274673: Current learning rate: 0.00627 
2025-06-16 06:07:14.853047: train_loss -0.6091 
2025-06-16 06:07:14.897615: val_loss -0.615 
2025-06-16 06:07:14.898358: Pseudo dice [0.8396, 0.9179, 0.9192, 0.896] 
2025-06-16 06:07:14.899488: Epoch time: 54.53 s 
2025-06-16 06:07:14.900002: Yayy! New best EMA pseudo Dice: 0.8705 
2025-06-16 06:07:17.776590:  
2025-06-16 06:07:17.777295: Epoch 406 
2025-06-16 06:07:17.777728: Current learning rate: 0.00626 
2025-06-16 06:08:12.229281: train_loss -0.5972 
2025-06-16 06:08:12.230350: val_loss -0.6001 
2025-06-16 06:08:12.231274: Pseudo dice [0.6796, 0.9121, 0.8552, 0.8908] 
2025-06-16 06:08:12.232231: Epoch time: 54.45 s 
2025-06-16 06:08:14.267171:  
2025-06-16 06:08:14.267763: Epoch 407 
2025-06-16 06:08:14.268280: Current learning rate: 0.00625 
2025-06-16 06:09:13.672249: train_loss -0.5989 
2025-06-16 06:09:13.673286: val_loss -0.6301 
2025-06-16 06:09:13.673999: Pseudo dice [0.7499, 0.9129, 0.9053, 0.9045] 
2025-06-16 06:09:13.674524: Epoch time: 59.41 s 
2025-06-16 06:09:15.133562:  
2025-06-16 06:09:15.134354: Epoch 408 
2025-06-16 06:09:15.134773: Current learning rate: 0.00624 
2025-06-16 06:10:08.909079: train_loss -0.6162 
2025-06-16 06:10:08.998161: val_loss -0.6301 
2025-06-16 06:10:08.999178: Pseudo dice [0.7653, 0.9187, 0.8919, 0.8992] 
2025-06-16 06:10:09.018218: Epoch time: 53.78 s 
2025-06-16 06:10:11.757666:  
2025-06-16 06:10:11.758271: Epoch 409 
2025-06-16 06:10:11.758695: Current learning rate: 0.00623 
2025-06-16 06:11:18.490381: train_loss -0.6176 
2025-06-16 06:11:18.491293: val_loss -0.6367 
2025-06-16 06:11:18.491886: Pseudo dice [0.798, 0.9212, 0.9113, 0.9158] 
2025-06-16 06:11:18.492341: Epoch time: 66.73 s 
2025-06-16 06:11:21.563218:  
2025-06-16 06:11:21.563885: Epoch 410 
2025-06-16 06:11:21.564473: Current learning rate: 0.00622 
2025-06-16 06:12:15.103225: train_loss -0.6197 
2025-06-16 06:12:15.104208: val_loss -0.6057 
2025-06-16 06:12:15.104846: Pseudo dice [0.8277, 0.9219, 0.8985, 0.8993] 
2025-06-16 06:12:15.105383: Epoch time: 53.54 s 
2025-06-16 06:12:15.105855: Yayy! New best EMA pseudo Dice: 0.8709 
2025-06-16 06:12:18.400688:  
2025-06-16 06:12:18.401336: Epoch 411 
2025-06-16 06:12:18.401964: Current learning rate: 0.00621 
2025-06-16 06:13:14.361887: train_loss -0.6088 
2025-06-16 06:13:14.363462: val_loss -0.6317 
2025-06-16 06:13:14.364347: Pseudo dice [0.769, 0.908, 0.9059, 0.8928] 
2025-06-16 06:13:14.365387: Epoch time: 55.96 s 
2025-06-16 06:13:16.097187:  
2025-06-16 06:13:16.097839: Epoch 412 
2025-06-16 06:13:16.098447: Current learning rate: 0.0062 
2025-06-16 06:14:17.444592: train_loss -0.6166 
2025-06-16 06:14:17.445478: val_loss -0.6178 
2025-06-16 06:14:17.445952: Pseudo dice [0.8269, 0.9187, 0.9096, 0.8844] 
2025-06-16 06:14:17.446368: Epoch time: 61.35 s 
2025-06-16 06:14:17.446855: Yayy! New best EMA pseudo Dice: 0.8721 
2025-06-16 06:14:19.723999:  
2025-06-16 06:14:19.724767: Epoch 413 
2025-06-16 06:14:19.725195: Current learning rate: 0.00619 
2025-06-16 06:15:12.130329: train_loss -0.6217 
2025-06-16 06:15:12.131447: val_loss -0.6084 
2025-06-16 06:15:12.132418: Pseudo dice [0.7963, 0.91, 0.915, 0.9121] 
2025-06-16 06:15:12.133106: Epoch time: 52.41 s 
2025-06-16 06:15:12.133870: Yayy! New best EMA pseudo Dice: 0.8732 
2025-06-16 06:15:14.403576:  
2025-06-16 06:15:14.404269: Epoch 414 
2025-06-16 06:15:14.404825: Current learning rate: 0.00618 
2025-06-16 06:16:17.577433: train_loss -0.6306 
2025-06-16 06:16:17.578126: val_loss -0.6221 
2025-06-16 06:16:17.578507: Pseudo dice [0.819, 0.9112, 0.9107, 0.9118] 
2025-06-16 06:16:17.579128: Epoch time: 63.18 s 
2025-06-16 06:16:17.579460: Yayy! New best EMA pseudo Dice: 0.8747 
2025-06-16 06:16:19.490224:  
2025-06-16 06:16:19.490812: Epoch 415 
2025-06-16 06:16:19.491236: Current learning rate: 0.00617 
2025-06-16 06:17:06.682668: train_loss -0.6317 
2025-06-16 06:17:06.683449: val_loss -0.6128 
2025-06-16 06:17:06.683992: Pseudo dice [0.7575, 0.9133, 0.9041, 0.9079] 
2025-06-16 06:17:06.684423: Epoch time: 47.19 s 
2025-06-16 06:17:10.066453:  
2025-06-16 06:17:10.067073: Epoch 416 
2025-06-16 06:17:10.067483: Current learning rate: 0.00616 
2025-06-16 06:18:03.986013: train_loss -0.6198 
2025-06-16 06:18:03.987274: val_loss -0.6427 
2025-06-16 06:18:03.987985: Pseudo dice [0.7823, 0.9276, 0.8979, 0.8858] 
2025-06-16 06:18:03.988846: Epoch time: 53.92 s 
2025-06-16 06:18:05.890611:  
2025-06-16 06:18:05.891237: Epoch 417 
2025-06-16 06:18:05.891725: Current learning rate: 0.00615 
2025-06-16 06:19:05.981732: train_loss -0.6199 
2025-06-16 06:19:05.986805: val_loss -0.6444 
2025-06-16 06:19:05.987257: Pseudo dice [0.7706, 0.9115, 0.908, 0.9012] 
2025-06-16 06:19:05.988159: Epoch time: 60.09 s 
2025-06-16 06:19:08.430148:  
2025-06-16 06:19:08.430731: Epoch 418 
2025-06-16 06:19:08.431165: Current learning rate: 0.00614 
2025-06-16 06:20:05.689717: train_loss -0.6297 
2025-06-16 06:20:05.690740: val_loss -0.6371 
2025-06-16 06:20:05.691391: Pseudo dice [0.745, 0.9236, 0.9059, 0.8827] 
2025-06-16 06:20:05.692263: Epoch time: 57.26 s 
2025-06-16 06:20:07.524439:  
2025-06-16 06:20:07.525065: Epoch 419 
2025-06-16 06:20:07.525493: Current learning rate: 0.00613 
2025-06-16 06:21:13.881492: train_loss -0.6214 
2025-06-16 06:21:13.882195: val_loss -0.6162 
2025-06-16 06:21:13.882815: Pseudo dice [0.7495, 0.9027, 0.8732, 0.9031] 
2025-06-16 06:21:13.883282: Epoch time: 66.36 s 
2025-06-16 06:21:15.503557:  
2025-06-16 06:21:15.504136: Epoch 420 
2025-06-16 06:21:15.504549: Current learning rate: 0.00612 
2025-06-16 06:22:06.048334: train_loss -0.6275 
2025-06-16 06:22:06.049471: val_loss -0.6342 
2025-06-16 06:22:06.050279: Pseudo dice [0.7707, 0.9096, 0.9045, 0.9362] 
2025-06-16 06:22:06.051050: Epoch time: 50.55 s 
2025-06-16 06:22:07.915304:  
2025-06-16 06:22:07.915835: Epoch 421 
2025-06-16 06:22:07.916240: Current learning rate: 0.00612 
2025-06-16 06:22:58.319330: train_loss -0.6264 
2025-06-16 06:22:58.320097: val_loss -0.6383 
2025-06-16 06:22:58.320823: Pseudo dice [0.728, 0.9184, 0.8974, 0.8665] 
2025-06-16 06:22:58.321721: Epoch time: 50.41 s 
2025-06-16 06:22:59.940442:  
2025-06-16 06:22:59.941111: Epoch 422 
2025-06-16 06:22:59.941670: Current learning rate: 0.00611 
2025-06-16 06:24:00.751972: train_loss -0.6142 
2025-06-16 06:24:00.753003: val_loss -0.6155 
2025-06-16 06:24:00.753698: Pseudo dice [0.8245, 0.9013, 0.9047, 0.8825] 
2025-06-16 06:24:00.754480: Epoch time: 60.81 s 
2025-06-16 06:24:02.713072:  
2025-06-16 06:24:02.713723: Epoch 423 
2025-06-16 06:24:02.714456: Current learning rate: 0.0061 
2025-06-16 06:25:00.186369: train_loss -0.6392 
2025-06-16 06:25:00.190760: val_loss -0.6273 
2025-06-16 06:25:00.191576: Pseudo dice [0.7489, 0.9136, 0.902, 0.912] 
2025-06-16 06:25:00.192795: Epoch time: 57.44 s 
2025-06-16 06:25:04.947390:  
2025-06-16 06:25:04.948053: Epoch 424 
2025-06-16 06:25:04.948630: Current learning rate: 0.00609 
2025-06-16 06:26:04.217002: train_loss -0.6406 
2025-06-16 06:26:04.218075: val_loss -0.6289 
2025-06-16 06:26:04.218970: Pseudo dice [0.8019, 0.9153, 0.9118, 0.8851] 
2025-06-16 06:26:04.219648: Epoch time: 59.27 s 
2025-06-16 06:26:06.179595:  
2025-06-16 06:26:06.180490: Epoch 425 
2025-06-16 06:26:06.181017: Current learning rate: 0.00608 
2025-06-16 06:27:07.256287: train_loss -0.6294 
2025-06-16 06:27:07.257213: val_loss -0.6415 
2025-06-16 06:27:07.257908: Pseudo dice [0.7656, 0.9165, 0.9025, 0.9202] 
2025-06-16 06:27:07.258451: Epoch time: 61.08 s 
2025-06-16 06:27:09.172229:  
2025-06-16 06:27:09.172849: Epoch 426 
2025-06-16 06:27:09.173273: Current learning rate: 0.00607 
2025-06-16 06:28:01.261971: train_loss -0.6314 
2025-06-16 06:28:01.263048: val_loss -0.6433 
2025-06-16 06:28:01.263600: Pseudo dice [0.7944, 0.8999, 0.8903, 0.8934] 
2025-06-16 06:28:01.264249: Epoch time: 52.09 s 
2025-06-16 06:28:02.618828:  
2025-06-16 06:28:02.619392: Epoch 427 
2025-06-16 06:28:02.619746: Current learning rate: 0.00606 
2025-06-16 06:28:57.292726: train_loss -0.6396 
2025-06-16 06:28:57.293695: val_loss -0.6406 
2025-06-16 06:28:57.294403: Pseudo dice [0.7703, 0.9125, 0.9029, 0.9211] 
2025-06-16 06:28:57.295045: Epoch time: 54.68 s 
2025-06-16 06:28:59.170568:  
2025-06-16 06:28:59.171589: Epoch 428 
2025-06-16 06:28:59.172710: Current learning rate: 0.00605 
2025-06-16 06:30:05.963664: train_loss -0.6303 
2025-06-16 06:30:06.070793: val_loss -0.6276 
2025-06-16 06:30:06.071699: Pseudo dice [0.7325, 0.9019, 0.8973, 0.9154] 
2025-06-16 06:30:06.089691: Epoch time: 66.76 s 
2025-06-16 06:30:08.424040:  
2025-06-16 06:30:08.425237: Epoch 429 
2025-06-16 06:30:08.426039: Current learning rate: 0.00604 
2025-06-16 06:31:06.843806: train_loss -0.6228 
2025-06-16 06:31:06.844784: val_loss -0.6418 
2025-06-16 06:31:06.845859: Pseudo dice [0.7725, 0.9217, 0.897, 0.8997] 
2025-06-16 06:31:06.846467: Epoch time: 58.42 s 
2025-06-16 06:31:08.853750:  
2025-06-16 06:31:08.854341: Epoch 430 
2025-06-16 06:31:08.854864: Current learning rate: 0.00603 
2025-06-16 06:32:09.355173: train_loss -0.632 
2025-06-16 06:32:09.356406: val_loss -0.6437 
2025-06-16 06:32:09.357107: Pseudo dice [0.7793, 0.9103, 0.9139, 0.8826] 
2025-06-16 06:32:09.357965: Epoch time: 60.5 s 
2025-06-16 06:32:10.729887:  
2025-06-16 06:32:10.730416: Epoch 431 
2025-06-16 06:32:10.730911: Current learning rate: 0.00602 
2025-06-16 06:33:03.910309: train_loss -0.6353 
2025-06-16 06:33:03.911201: val_loss -0.619 
2025-06-16 06:33:03.911819: Pseudo dice [0.7987, 0.9136, 0.8993, 0.9118] 
2025-06-16 06:33:03.912316: Epoch time: 53.18 s 
2025-06-16 06:33:07.770492:  
2025-06-16 06:33:07.771098: Epoch 432 
2025-06-16 06:33:07.771531: Current learning rate: 0.00601 
2025-06-16 06:33:59.208241: train_loss -0.6336 
2025-06-16 06:33:59.209296: val_loss -0.631 
2025-06-16 06:33:59.210123: Pseudo dice [0.812, 0.9191, 0.9328, 0.9082] 
2025-06-16 06:33:59.210654: Epoch time: 51.44 s 
2025-06-16 06:34:00.868274:  
2025-06-16 06:34:00.868885: Epoch 433 
2025-06-16 06:34:00.869279: Current learning rate: 0.006 
2025-06-16 06:35:06.230367: train_loss -0.5959 
2025-06-16 06:35:06.231294: val_loss -0.6053 
2025-06-16 06:35:06.231982: Pseudo dice [0.7418, 0.9066, 0.883, 0.878] 
2025-06-16 06:35:06.232532: Epoch time: 65.36 s 
2025-06-16 06:35:07.991261:  
2025-06-16 06:35:07.991841: Epoch 434 
2025-06-16 06:35:07.992235: Current learning rate: 0.00599 
2025-06-16 06:36:05.649583: train_loss -0.6138 
2025-06-16 06:36:05.660771: val_loss -0.6494 
2025-06-16 06:36:05.661657: Pseudo dice [0.8096, 0.9162, 0.9205, 0.8657] 
2025-06-16 06:36:05.663474: Epoch time: 57.62 s 
2025-06-16 06:36:08.423328:  
2025-06-16 06:36:08.423949: Epoch 435 
2025-06-16 06:36:08.424343: Current learning rate: 0.00598 
2025-06-16 06:37:19.610640: train_loss -0.6264 
2025-06-16 06:37:19.612207: val_loss -0.6189 
2025-06-16 06:37:19.612986: Pseudo dice [0.7752, 0.9175, 0.9205, 0.8344] 
2025-06-16 06:37:19.613962: Epoch time: 71.19 s 
2025-06-16 06:37:21.557055:  
2025-06-16 06:37:21.557986: Epoch 436 
2025-06-16 06:37:21.558613: Current learning rate: 0.00597 
2025-06-16 06:38:14.221949: train_loss -0.616 
2025-06-16 06:38:14.222740: val_loss -0.6262 
2025-06-16 06:38:14.223145: Pseudo dice [0.7377, 0.915, 0.8839, 0.9012] 
2025-06-16 06:38:14.223626: Epoch time: 52.67 s 
2025-06-16 06:38:15.661475:  
2025-06-16 06:38:15.662006: Epoch 437 
2025-06-16 06:38:15.662363: Current learning rate: 0.00596 
2025-06-16 06:39:04.450012: train_loss -0.6073 
2025-06-16 06:39:04.450864: val_loss -0.6089 
2025-06-16 06:39:04.451291: Pseudo dice [0.8231, 0.9038, 0.8909, 0.8993] 
2025-06-16 06:39:04.451810: Epoch time: 48.79 s 
2025-06-16 06:39:06.087550:  
2025-06-16 06:39:06.088152: Epoch 438 
2025-06-16 06:39:06.088641: Current learning rate: 0.00595 
2025-06-16 06:40:09.380676: train_loss -0.572 
2025-06-16 06:40:09.382065: val_loss -0.6014 
2025-06-16 06:40:09.382955: Pseudo dice [0.7023, 0.9028, 0.8679, 0.8513] 
2025-06-16 06:40:09.383664: Epoch time: 63.29 s 
2025-06-16 06:40:15.038560:  
2025-06-16 06:40:15.039209: Epoch 439 
2025-06-16 06:40:15.039746: Current learning rate: 0.00594 
2025-06-16 06:41:14.206244: train_loss -0.5978 
2025-06-16 06:41:14.207842: val_loss -0.5912 
2025-06-16 06:41:14.208385: Pseudo dice [0.818, 0.9104, 0.9049, 0.8805] 
2025-06-16 06:41:14.208832: Epoch time: 59.17 s 
2025-06-16 06:41:16.516191:  
2025-06-16 06:41:16.516884: Epoch 440 
2025-06-16 06:41:16.517287: Current learning rate: 0.00593 
2025-06-16 06:42:18.064489: train_loss -0.6065 
2025-06-16 06:42:18.065733: val_loss -0.6323 
2025-06-16 06:42:18.066950: Pseudo dice [0.7089, 0.9094, 0.8931, 0.9148] 
2025-06-16 06:42:18.067786: Epoch time: 61.55 s 
2025-06-16 06:42:19.923382:  
2025-06-16 06:42:19.924122: Epoch 441 
2025-06-16 06:42:19.924638: Current learning rate: 0.00592 
2025-06-16 06:43:24.593253: train_loss -0.6216 
2025-06-16 06:43:24.594281: val_loss -0.6289 
2025-06-16 06:43:24.595017: Pseudo dice [0.8123, 0.9334, 0.9199, 0.9082] 
2025-06-16 06:43:24.595610: Epoch time: 64.67 s 
2025-06-16 06:43:26.288716:  
2025-06-16 06:43:26.289278: Epoch 442 
2025-06-16 06:43:26.289812: Current learning rate: 0.00592 
2025-06-16 06:44:18.617469: train_loss -0.6254 
2025-06-16 06:44:18.618387: val_loss -0.606 
2025-06-16 06:44:18.618898: Pseudo dice [0.7613, 0.9124, 0.9027, 0.8964] 
2025-06-16 06:44:18.619335: Epoch time: 52.33 s 
2025-06-16 06:44:20.228739:  
2025-06-16 06:44:20.229335: Epoch 443 
2025-06-16 06:44:20.229756: Current learning rate: 0.00591 
2025-06-16 06:45:15.166880: train_loss -0.6235 
2025-06-16 06:45:15.167951: val_loss -0.6519 
2025-06-16 06:45:15.168430: Pseudo dice [0.8495, 0.9274, 0.926, 0.9021] 
2025-06-16 06:45:15.169305: Epoch time: 54.94 s 
2025-06-16 06:45:17.140891:  
2025-06-16 06:45:17.141573: Epoch 444 
2025-06-16 06:45:17.142179: Current learning rate: 0.0059 
2025-06-16 06:46:25.145964: train_loss -0.6308 
2025-06-16 06:46:25.226747: val_loss -0.6385 
2025-06-16 06:46:25.227761: Pseudo dice [0.7923, 0.8932, 0.9068, 0.9138] 
2025-06-16 06:46:25.241947: Epoch time: 67.98 s 
2025-06-16 06:46:27.826568:  
2025-06-16 06:46:27.827194: Epoch 445 
2025-06-16 06:46:27.827619: Current learning rate: 0.00589 
2025-06-16 06:47:27.022420: train_loss -0.6172 
2025-06-16 06:47:27.023351: val_loss -0.6382 
2025-06-16 06:47:27.024096: Pseudo dice [0.6947, 0.9207, 0.912, 0.9212] 
2025-06-16 06:47:27.024644: Epoch time: 59.2 s 
2025-06-16 06:47:29.458486:  
2025-06-16 06:47:29.459192: Epoch 446 
2025-06-16 06:47:29.459631: Current learning rate: 0.00588 
2025-06-16 06:48:34.509137: train_loss -0.6405 
2025-06-16 06:48:34.509941: val_loss -0.6371 
2025-06-16 06:48:34.510530: Pseudo dice [0.7901, 0.9031, 0.9131, 0.9246] 
2025-06-16 06:48:34.510942: Epoch time: 65.05 s 
2025-06-16 06:48:38.136771:  
2025-06-16 06:48:38.137368: Epoch 447 
2025-06-16 06:48:38.138095: Current learning rate: 0.00587 
2025-06-16 06:49:35.183739: train_loss -0.6262 
2025-06-16 06:49:35.184654: val_loss -0.632 
2025-06-16 06:49:35.185133: Pseudo dice [0.7098, 0.9121, 0.827, 0.8987] 
2025-06-16 06:49:35.185620: Epoch time: 57.05 s 
2025-06-16 06:49:37.369440:  
2025-06-16 06:49:37.370152: Epoch 448 
2025-06-16 06:49:37.370646: Current learning rate: 0.00586 
2025-06-16 06:50:44.431570: train_loss -0.6278 
2025-06-16 06:50:44.432291: val_loss -0.6213 
2025-06-16 06:50:44.432859: Pseudo dice [0.6297, 0.9185, 0.8848, 0.9102] 
2025-06-16 06:50:44.433317: Epoch time: 67.06 s 
2025-06-16 06:50:46.023718:  
2025-06-16 06:50:46.024322: Epoch 449 
2025-06-16 06:50:46.024769: Current learning rate: 0.00585 
2025-06-16 06:51:36.306552: train_loss -0.6204 
2025-06-16 06:51:36.307431: val_loss -0.6567 
2025-06-16 06:51:36.307986: Pseudo dice [0.796, 0.9231, 0.9095, 0.9071] 
2025-06-16 06:51:36.308379: Epoch time: 50.28 s 
2025-06-16 06:51:38.660947:  
2025-06-16 06:51:38.661687: Epoch 450 
2025-06-16 06:51:38.662078: Current learning rate: 0.00584 
2025-06-16 06:52:43.308529: train_loss -0.6263 
2025-06-16 06:52:43.309924: val_loss -0.6196 
2025-06-16 06:52:43.310732: Pseudo dice [0.8435, 0.9219, 0.9013, 0.9031] 
2025-06-16 06:52:43.311621: Epoch time: 64.65 s 
2025-06-16 06:52:45.205443:  
2025-06-16 06:52:45.206346: Epoch 451 
2025-06-16 06:52:45.207195: Current learning rate: 0.00583 
2025-06-16 06:53:40.674058: train_loss -0.6247 
2025-06-16 06:53:40.732449: val_loss -0.6084 
2025-06-16 06:53:40.733464: Pseudo dice [0.7869, 0.91, 0.9113, 0.8822] 
2025-06-16 06:53:40.734816: Epoch time: 55.44 s 
2025-06-16 06:53:42.933904:  
2025-06-16 06:53:42.934458: Epoch 452 
2025-06-16 06:53:42.935037: Current learning rate: 0.00582 
2025-06-16 06:54:35.573028: train_loss -0.5911 
2025-06-16 06:54:35.573900: val_loss -0.6096 
2025-06-16 06:54:35.574468: Pseudo dice [0.7455, 0.9059, 0.8913, 0.9061] 
2025-06-16 06:54:35.575187: Epoch time: 52.64 s 
2025-06-16 06:54:37.520755:  
2025-06-16 06:54:37.521340: Epoch 453 
2025-06-16 06:54:37.522065: Current learning rate: 0.00581 
2025-06-16 06:55:41.815624: train_loss -0.6264 
2025-06-16 06:55:41.816792: val_loss -0.6292 
2025-06-16 06:55:41.817386: Pseudo dice [0.7226, 0.9207, 0.8842, 0.9041] 
2025-06-16 06:55:41.817947: Epoch time: 64.3 s 
2025-06-16 06:55:43.962079:  
2025-06-16 06:55:43.962718: Epoch 454 
2025-06-16 06:55:43.963188: Current learning rate: 0.0058 
2025-06-16 06:56:40.927689: train_loss -0.6236 
2025-06-16 06:56:40.928745: val_loss -0.5911 
2025-06-16 06:56:40.929412: Pseudo dice [0.7342, 0.8817, 0.8907, 0.8786] 
2025-06-16 06:56:40.929990: Epoch time: 56.97 s 
2025-06-16 06:56:42.653733:  
2025-06-16 06:56:42.654422: Epoch 455 
2025-06-16 06:56:42.654875: Current learning rate: 0.00579 
2025-06-16 06:57:48.646383: train_loss -0.6182 
2025-06-16 06:57:48.647345: val_loss -0.6172 
2025-06-16 06:57:48.647844: Pseudo dice [0.8305, 0.9148, 0.9, 0.8784] 
2025-06-16 06:57:48.648337: Epoch time: 65.99 s 
2025-06-16 06:57:50.395109:  
2025-06-16 06:57:50.395762: Epoch 456 
2025-06-16 06:57:50.396200: Current learning rate: 0.00578 
2025-06-16 06:58:40.875663: train_loss -0.624 
2025-06-16 06:58:40.876340: val_loss -0.6181 
2025-06-16 06:58:40.876849: Pseudo dice [0.7716, 0.9129, 0.9188, 0.8683] 
2025-06-16 06:58:40.877239: Epoch time: 50.48 s 
2025-06-16 06:58:42.561256:  
2025-06-16 06:58:42.561880: Epoch 457 
2025-06-16 06:58:42.562282: Current learning rate: 0.00577 
2025-06-16 06:59:39.079929: train_loss -0.6306 
2025-06-16 06:59:39.080671: val_loss -0.6234 
2025-06-16 06:59:39.081106: Pseudo dice [0.786, 0.9065, 0.9027, 0.9062] 
2025-06-16 06:59:39.081482: Epoch time: 56.52 s 
2025-06-16 06:59:40.786212:  
2025-06-16 06:59:40.786866: Epoch 458 
2025-06-16 06:59:40.787453: Current learning rate: 0.00576 
2025-06-16 07:00:45.785823: train_loss -0.6192 
2025-06-16 07:00:45.796191: val_loss -0.6452 
2025-06-16 07:00:45.796868: Pseudo dice [0.7536, 0.9173, 0.8994, 0.9059] 
2025-06-16 07:00:45.798206: Epoch time: 64.97 s 
2025-06-16 07:00:48.184659:  
2025-06-16 07:00:48.185293: Epoch 459 
2025-06-16 07:00:48.185715: Current learning rate: 0.00575 
2025-06-16 07:01:43.014316: train_loss -0.6248 
2025-06-16 07:01:43.015514: val_loss -0.6089 
2025-06-16 07:01:43.016262: Pseudo dice [0.7003, 0.909, 0.9089, 0.8993] 
2025-06-16 07:01:43.016866: Epoch time: 54.83 s 
2025-06-16 07:01:44.894290:  
2025-06-16 07:01:44.895268: Epoch 460 
2025-06-16 07:01:44.895764: Current learning rate: 0.00574 
2025-06-16 07:02:49.396319: train_loss -0.6152 
2025-06-16 07:02:49.397431: val_loss -0.6293 
2025-06-16 07:02:49.398320: Pseudo dice [0.769, 0.9147, 0.9125, 0.9201] 
2025-06-16 07:02:49.399015: Epoch time: 64.5 s 
2025-06-16 07:02:51.070199:  
2025-06-16 07:02:51.070860: Epoch 461 
2025-06-16 07:02:51.071288: Current learning rate: 0.00573 
2025-06-16 07:03:40.806856: train_loss -0.6253 
2025-06-16 07:03:40.882308: val_loss -0.6248 
2025-06-16 07:03:40.883020: Pseudo dice [0.8483, 0.9087, 0.9219, 0.8945] 
2025-06-16 07:03:40.902991: Epoch time: 49.74 s 
2025-06-16 07:03:44.941512:  
2025-06-16 07:03:44.942091: Epoch 462 
2025-06-16 07:03:44.942524: Current learning rate: 0.00572 
2025-06-16 07:04:36.072599: train_loss -0.6281 
2025-06-16 07:04:36.073298: val_loss -0.669 
2025-06-16 07:04:36.073909: Pseudo dice [0.7891, 0.926, 0.9076, 0.8703] 
2025-06-16 07:04:36.074353: Epoch time: 51.13 s 
2025-06-16 07:04:37.353320:  
2025-06-16 07:04:37.353945: Epoch 463 
2025-06-16 07:04:37.354511: Current learning rate: 0.00571 
2025-06-16 07:05:39.401538: train_loss -0.6374 
2025-06-16 07:05:39.402287: val_loss -0.6271 
2025-06-16 07:05:39.402894: Pseudo dice [0.7097, 0.9135, 0.9075, 0.9013] 
2025-06-16 07:05:39.403358: Epoch time: 62.05 s 
2025-06-16 07:05:41.267030:  
2025-06-16 07:05:41.267701: Epoch 464 
2025-06-16 07:05:41.268641: Current learning rate: 0.0057 
2025-06-16 07:06:39.071712: train_loss -0.6204 
2025-06-16 07:06:39.111156: val_loss -0.6256 
2025-06-16 07:06:39.114430: Pseudo dice [0.7812, 0.9082, 0.9092, 0.9178] 
2025-06-16 07:06:39.119813: Epoch time: 57.77 s 
2025-06-16 07:06:41.652189:  
2025-06-16 07:06:41.653107: Epoch 465 
2025-06-16 07:06:41.653681: Current learning rate: 0.0057 
2025-06-16 07:07:44.489268: train_loss -0.633 
2025-06-16 07:07:44.490285: val_loss -0.6319 
2025-06-16 07:07:44.491215: Pseudo dice [0.7887, 0.9154, 0.8988, 0.9225] 
2025-06-16 07:07:44.491920: Epoch time: 62.84 s 
2025-06-16 07:07:46.422435:  
2025-06-16 07:07:46.423386: Epoch 466 
2025-06-16 07:07:46.424057: Current learning rate: 0.00569 
2025-06-16 07:08:41.264751: train_loss -0.6345 
2025-06-16 07:08:41.265492: val_loss -0.6329 
2025-06-16 07:08:41.265905: Pseudo dice [0.6141, 0.9092, 0.9011, 0.9063] 
2025-06-16 07:08:41.266269: Epoch time: 54.84 s 
2025-06-16 07:08:43.060163:  
2025-06-16 07:08:43.060918: Epoch 467 
2025-06-16 07:08:43.061374: Current learning rate: 0.00568 
2025-06-16 07:09:36.010960: train_loss -0.6206 
2025-06-16 07:09:36.011979: val_loss -0.645 
2025-06-16 07:09:36.012585: Pseudo dice [0.7905, 0.9022, 0.9105, 0.9204] 
2025-06-16 07:09:36.013196: Epoch time: 52.95 s 
2025-06-16 07:09:37.797680:  
2025-06-16 07:09:37.798452: Epoch 468 
2025-06-16 07:09:37.798986: Current learning rate: 0.00567 
2025-06-16 07:10:39.427221: train_loss -0.6372 
2025-06-16 07:10:39.428065: val_loss -0.6341 
2025-06-16 07:10:39.428506: Pseudo dice [0.8597, 0.9182, 0.9325, 0.9126] 
2025-06-16 07:10:39.428903: Epoch time: 61.63 s 
2025-06-16 07:10:41.377880:  
2025-06-16 07:10:41.378460: Epoch 469 
2025-06-16 07:10:41.379088: Current learning rate: 0.00566 
2025-06-16 07:11:27.511424: train_loss -0.6323 
2025-06-16 07:11:27.512183: val_loss -0.6664 
2025-06-16 07:11:27.512591: Pseudo dice [0.8962, 0.9316, 0.9365, 0.8914] 
2025-06-16 07:11:27.512970: Epoch time: 46.13 s 
2025-06-16 07:11:27.513330: Yayy! New best EMA pseudo Dice: 0.877 
2025-06-16 07:11:32.108637:  
2025-06-16 07:11:32.109275: Epoch 470 
2025-06-16 07:11:32.109726: Current learning rate: 0.00565 
2025-06-16 07:12:24.938022: train_loss -0.6305 
2025-06-16 07:12:24.939221: val_loss -0.65 
2025-06-16 07:12:24.940139: Pseudo dice [0.8018, 0.9202, 0.9109, 0.9167] 
2025-06-16 07:12:24.940995: Epoch time: 52.83 s 
2025-06-16 07:12:24.941606: Yayy! New best EMA pseudo Dice: 0.878 
2025-06-16 07:12:27.184456:  
2025-06-16 07:12:27.185087: Epoch 471 
2025-06-16 07:12:27.185602: Current learning rate: 0.00564 
2025-06-16 07:13:24.803210: train_loss -0.6431 
2025-06-16 07:13:24.804074: val_loss -0.6534 
2025-06-16 07:13:24.804614: Pseudo dice [0.7906, 0.9202, 0.9092, 0.9047] 
2025-06-16 07:13:24.805248: Epoch time: 57.62 s 
2025-06-16 07:13:24.805680: Yayy! New best EMA pseudo Dice: 0.8783 
2025-06-16 07:13:27.393625:  
2025-06-16 07:13:27.394217: Epoch 472 
2025-06-16 07:13:27.394658: Current learning rate: 0.00563 
2025-06-16 07:14:23.563298: train_loss -0.6408 
2025-06-16 07:14:23.633417: val_loss -0.6448 
2025-06-16 07:14:23.635010: Pseudo dice [0.811, 0.9165, 0.8906, 0.9009] 
2025-06-16 07:14:23.641952: Epoch time: 56.15 s 
2025-06-16 07:14:23.643193: Yayy! New best EMA pseudo Dice: 0.8785 
2025-06-16 07:14:26.852164:  
2025-06-16 07:14:26.852817: Epoch 473 
2025-06-16 07:14:26.853393: Current learning rate: 0.00562 
2025-06-16 07:15:38.388024: train_loss -0.626 
2025-06-16 07:15:38.389309: val_loss -0.6493 
2025-06-16 07:15:38.390178: Pseudo dice [0.7846, 0.9151, 0.9004, 0.8976] 
2025-06-16 07:15:38.391260: Epoch time: 71.54 s 
2025-06-16 07:15:40.225997:  
2025-06-16 07:15:40.226559: Epoch 474 
2025-06-16 07:15:40.226991: Current learning rate: 0.00561 
2025-06-16 07:16:32.763908: train_loss -0.6244 
2025-06-16 07:16:32.764739: val_loss -0.6185 
2025-06-16 07:16:32.765149: Pseudo dice [0.7899, 0.9205, 0.9144, 0.8996] 
2025-06-16 07:16:32.765543: Epoch time: 52.54 s 
2025-06-16 07:16:34.513198:  
2025-06-16 07:16:34.513816: Epoch 475 
2025-06-16 07:16:34.514237: Current learning rate: 0.0056 
2025-06-16 07:17:31.049990: train_loss -0.6306 
2025-06-16 07:17:31.051100: val_loss -0.6633 
2025-06-16 07:17:31.052032: Pseudo dice [0.8063, 0.9275, 0.9211, 0.8921] 
2025-06-16 07:17:31.052791: Epoch time: 56.54 s 
2025-06-16 07:17:31.053421: Yayy! New best EMA pseudo Dice: 0.8792 
2025-06-16 07:17:33.583880:  
2025-06-16 07:17:33.584680: Epoch 476 
2025-06-16 07:17:33.585177: Current learning rate: 0.00559 
2025-06-16 07:18:34.367961: train_loss -0.6335 
2025-06-16 07:18:34.455168: val_loss -0.654 
2025-06-16 07:18:34.455724: Pseudo dice [0.7908, 0.9152, 0.9143, 0.9097] 
2025-06-16 07:18:34.471058: Epoch time: 60.79 s 
2025-06-16 07:18:34.480313: Yayy! New best EMA pseudo Dice: 0.8795 
2025-06-16 07:18:39.072415:  
2025-06-16 07:18:39.073039: Epoch 477 
2025-06-16 07:18:39.073445: Current learning rate: 0.00558 
2025-06-16 07:19:32.205016: train_loss -0.6346 
2025-06-16 07:19:32.205782: val_loss -0.626 
2025-06-16 07:19:32.206340: Pseudo dice [0.8105, 0.9181, 0.9237, 0.897] 
2025-06-16 07:19:32.206806: Epoch time: 53.13 s 
2025-06-16 07:19:32.207188: Yayy! New best EMA pseudo Dice: 0.8803 
2025-06-16 07:19:34.262341:  
2025-06-16 07:19:34.263067: Epoch 478 
2025-06-16 07:19:34.263484: Current learning rate: 0.00557 
2025-06-16 07:20:37.323533: train_loss -0.6297 
2025-06-16 07:20:37.324724: val_loss -0.6135 
2025-06-16 07:20:37.325374: Pseudo dice [0.8318, 0.912, 0.8894, 0.9199] 
2025-06-16 07:20:37.326150: Epoch time: 63.06 s 
2025-06-16 07:20:37.326794: Yayy! New best EMA pseudo Dice: 0.8811 
2025-06-16 07:20:39.970124:  
2025-06-16 07:20:39.970805: Epoch 479 
2025-06-16 07:20:39.971362: Current learning rate: 0.00556 
2025-06-16 07:21:29.664229: train_loss -0.6342 
2025-06-16 07:21:29.665325: val_loss -0.6414 
2025-06-16 07:21:29.666202: Pseudo dice [0.7297, 0.9199, 0.8937, 0.9009] 
2025-06-16 07:21:29.666860: Epoch time: 49.7 s 
2025-06-16 07:21:30.998198:  
2025-06-16 07:21:30.998753: Epoch 480 
2025-06-16 07:21:30.999255: Current learning rate: 0.00555 
2025-06-16 07:22:17.174095: train_loss -0.6312 
2025-06-16 07:22:17.174934: val_loss -0.6358 
2025-06-16 07:22:17.175362: Pseudo dice [0.7681, 0.9217, 0.895, 0.8898] 
2025-06-16 07:22:17.175911: Epoch time: 46.18 s 
2025-06-16 07:22:18.811990:  
2025-06-16 07:22:18.812639: Epoch 481 
2025-06-16 07:22:18.813193: Current learning rate: 0.00554 
2025-06-16 07:23:04.725246: train_loss -0.6202 
2025-06-16 07:23:04.725984: val_loss -0.6482 
2025-06-16 07:23:04.726417: Pseudo dice [0.7352, 0.9213, 0.8813, 0.9087] 
2025-06-16 07:23:04.727063: Epoch time: 45.91 s 
2025-06-16 07:23:06.362755:  
2025-06-16 07:23:06.363441: Epoch 482 
2025-06-16 07:23:06.363875: Current learning rate: 0.00553 
2025-06-16 07:23:52.433819: train_loss -0.6304 
2025-06-16 07:23:52.435259: val_loss -0.6318 
2025-06-16 07:23:52.435987: Pseudo dice [0.8006, 0.9179, 0.9115, 0.9029] 
2025-06-16 07:23:52.436598: Epoch time: 46.07 s 
2025-06-16 07:23:53.758048:  
2025-06-16 07:23:53.758602: Epoch 483 
2025-06-16 07:23:53.758973: Current learning rate: 0.00552 
2025-06-16 07:24:37.046864: train_loss -0.6463 
2025-06-16 07:24:37.047690: val_loss -0.6591 
2025-06-16 07:24:37.048115: Pseudo dice [0.7916, 0.9161, 0.9257, 0.9175] 
2025-06-16 07:24:37.048483: Epoch time: 43.29 s 
2025-06-16 07:24:38.518170:  
2025-06-16 07:24:38.518723: Epoch 484 
2025-06-16 07:24:38.519107: Current learning rate: 0.00551 
2025-06-16 07:25:24.385429: train_loss -0.6327 
2025-06-16 07:25:24.386508: val_loss -0.6347 
2025-06-16 07:25:24.387205: Pseudo dice [0.8612, 0.9244, 0.9282, 0.8869] 
2025-06-16 07:25:24.387775: Epoch time: 45.87 s 
2025-06-16 07:25:25.680080:  
2025-06-16 07:25:25.680637: Epoch 485 
2025-06-16 07:25:25.681277: Current learning rate: 0.0055 
2025-06-16 07:26:08.725649: train_loss -0.6382 
2025-06-16 07:26:08.726435: val_loss -0.6346 
2025-06-16 07:26:08.726840: Pseudo dice [0.7875, 0.9161, 0.9154, 0.8815] 
2025-06-16 07:26:08.727225: Epoch time: 43.05 s 
2025-06-16 07:26:10.367964:  
2025-06-16 07:26:10.368583: Epoch 486 
2025-06-16 07:26:10.369140: Current learning rate: 0.00549 
2025-06-16 07:26:53.814137: train_loss -0.6319 
2025-06-16 07:26:53.814918: val_loss -0.6251 
2025-06-16 07:26:53.815355: Pseudo dice [0.6168, 0.9164, 0.9114, 0.8891] 
2025-06-16 07:26:53.815725: Epoch time: 43.45 s 
2025-06-16 07:26:55.024404:  
2025-06-16 07:26:55.025128: Epoch 487 
2025-06-16 07:26:55.025520: Current learning rate: 0.00548 
2025-06-16 07:27:37.293314: train_loss -0.6358 
2025-06-16 07:27:37.294022: val_loss -0.6292 
2025-06-16 07:27:37.294418: Pseudo dice [0.8006, 0.9168, 0.9206, 0.8898] 
2025-06-16 07:27:37.294982: Epoch time: 42.27 s 
2025-06-16 07:27:38.595124:  
2025-06-16 07:27:38.595763: Epoch 488 
2025-06-16 07:27:38.596172: Current learning rate: 0.00547 
2025-06-16 07:28:24.563746: train_loss -0.6238 
2025-06-16 07:28:24.564416: val_loss -0.6207 
2025-06-16 07:28:24.564790: Pseudo dice [0.845, 0.9169, 0.9045, 0.8778] 
2025-06-16 07:28:24.565121: Epoch time: 45.97 s 
2025-06-16 07:28:25.913784:  
2025-06-16 07:28:25.914491: Epoch 489 
2025-06-16 07:28:25.914892: Current learning rate: 0.00546 
2025-06-16 07:29:15.159811: train_loss -0.6333 
2025-06-16 07:29:15.160647: val_loss -0.6127 
2025-06-16 07:29:15.161112: Pseudo dice [0.6301, 0.9142, 0.9134, 0.8766] 
2025-06-16 07:29:15.161537: Epoch time: 49.25 s 
2025-06-16 07:29:16.700681:  
2025-06-16 07:29:16.701229: Epoch 490 
2025-06-16 07:29:16.701594: Current learning rate: 0.00546 
2025-06-16 07:30:01.160969: train_loss -0.6361 
2025-06-16 07:30:01.161676: val_loss -0.63 
2025-06-16 07:30:01.162070: Pseudo dice [0.7518, 0.9092, 0.8948, 0.8879] 
2025-06-16 07:30:01.162476: Epoch time: 44.46 s 
2025-06-16 07:30:02.380302:  
2025-06-16 07:30:02.380840: Epoch 491 
2025-06-16 07:30:02.381388: Current learning rate: 0.00545 
2025-06-16 07:30:47.373060: train_loss -0.6108 
2025-06-16 07:30:47.373829: val_loss -0.6253 
2025-06-16 07:30:47.374253: Pseudo dice [0.7717, 0.9002, 0.8947, 0.9109] 
2025-06-16 07:30:47.374686: Epoch time: 44.99 s 
2025-06-16 07:30:48.859176:  
2025-06-16 07:30:48.859732: Epoch 492 
2025-06-16 07:30:48.860102: Current learning rate: 0.00544 
2025-06-16 07:31:31.126393: train_loss -0.6387 
2025-06-16 07:31:31.127171: val_loss -0.6473 
2025-06-16 07:31:31.127626: Pseudo dice [0.8598, 0.9143, 0.9034, 0.9133] 
2025-06-16 07:31:31.128133: Epoch time: 42.27 s 
2025-06-16 07:31:32.363433:  
2025-06-16 07:31:32.363958: Epoch 493 
2025-06-16 07:31:32.364336: Current learning rate: 0.00543 
2025-06-16 07:32:16.359580: train_loss -0.6292 
2025-06-16 07:32:16.360472: val_loss -0.6387 
2025-06-16 07:32:16.360922: Pseudo dice [0.7795, 0.922, 0.8999, 0.8917] 
2025-06-16 07:32:16.361328: Epoch time: 44.0 s 
2025-06-16 07:32:17.728366:  
2025-06-16 07:32:17.728889: Epoch 494 
2025-06-16 07:32:17.729310: Current learning rate: 0.00542 
2025-06-16 07:33:00.903781: train_loss -0.6274 
2025-06-16 07:33:00.904553: val_loss -0.6251 
2025-06-16 07:33:00.905106: Pseudo dice [0.6608, 0.9302, 0.9182, 0.9158] 
2025-06-16 07:33:00.905667: Epoch time: 43.18 s 
2025-06-16 07:33:02.237466:  
2025-06-16 07:33:02.238082: Epoch 495 
2025-06-16 07:33:02.238453: Current learning rate: 0.00541 
2025-06-16 07:33:46.517336: train_loss -0.6331 
2025-06-16 07:33:46.518072: val_loss -0.6053 
2025-06-16 07:33:46.518519: Pseudo dice [0.5298, 0.9158, 0.8873, 0.9137] 
2025-06-16 07:33:46.519037: Epoch time: 44.28 s 
2025-06-16 07:33:47.726549:  
2025-06-16 07:33:47.727135: Epoch 496 
2025-06-16 07:33:47.727568: Current learning rate: 0.0054 
2025-06-16 07:34:31.425891: train_loss -0.6304 
2025-06-16 07:34:31.426710: val_loss -0.6322 
2025-06-16 07:34:31.427160: Pseudo dice [0.8043, 0.9182, 0.8993, 0.8968] 
2025-06-16 07:34:31.427577: Epoch time: 43.7 s 
2025-06-16 07:34:32.749794:  
2025-06-16 07:34:32.750384: Epoch 497 
2025-06-16 07:34:32.750785: Current learning rate: 0.00539 
2025-06-16 07:35:17.635947: train_loss -0.6236 
2025-06-16 07:35:17.636687: val_loss -0.6224 
2025-06-16 07:35:17.637076: Pseudo dice [0.8231, 0.9125, 0.8971, 0.8925] 
2025-06-16 07:35:17.637452: Epoch time: 44.89 s 
2025-06-16 07:35:18.865532:  
2025-06-16 07:35:18.866021: Epoch 498 
2025-06-16 07:35:18.866374: Current learning rate: 0.00538 
2025-06-16 07:36:03.037781: train_loss -0.6267 
2025-06-16 07:36:03.038562: val_loss -0.6254 
2025-06-16 07:36:03.039112: Pseudo dice [0.7761, 0.9171, 0.8974, 0.9206] 
2025-06-16 07:36:03.039478: Epoch time: 44.17 s 
2025-06-16 07:36:04.498890:  
2025-06-16 07:36:04.499535: Epoch 499 
2025-06-16 07:36:04.499908: Current learning rate: 0.00537 
2025-06-16 07:36:49.028700: train_loss -0.6259 
2025-06-16 07:36:49.029582: val_loss -0.6509 
2025-06-16 07:36:49.030190: Pseudo dice [0.7827, 0.917, 0.8785, 0.8982] 
2025-06-16 07:36:49.030774: Epoch time: 44.53 s 
2025-06-16 07:36:50.577112:  
2025-06-16 07:36:50.577615: Epoch 500 
2025-06-16 07:36:50.578109: Current learning rate: 0.00536 
2025-06-16 07:37:34.381549: train_loss -0.6348 
2025-06-16 07:37:34.382235: val_loss -0.6255 
2025-06-16 07:37:34.382637: Pseudo dice [0.8393, 0.9131, 0.9067, 0.9024] 
2025-06-16 07:37:34.382989: Epoch time: 43.81 s 
2025-06-16 07:37:35.610115:  
2025-06-16 07:37:35.610726: Epoch 501 
2025-06-16 07:37:35.611098: Current learning rate: 0.00535 
2025-06-16 07:38:19.412525: train_loss -0.6357 
2025-06-16 07:38:19.413294: val_loss -0.6328 
2025-06-16 07:38:19.413892: Pseudo dice [0.8648, 0.9291, 0.9197, 0.8862] 
2025-06-16 07:38:19.414361: Epoch time: 43.8 s 
2025-06-16 07:38:20.636917:  
2025-06-16 07:38:20.637480: Epoch 502 
2025-06-16 07:38:20.637856: Current learning rate: 0.00534 
2025-06-16 07:39:03.931610: train_loss -0.6172 
2025-06-16 07:39:03.932389: val_loss -0.659 
2025-06-16 07:39:03.932784: Pseudo dice [0.8195, 0.9172, 0.9254, 0.8871] 
2025-06-16 07:39:03.933189: Epoch time: 43.3 s 
2025-06-16 07:39:05.411575:  
2025-06-16 07:39:05.412155: Epoch 503 
2025-06-16 07:39:05.412546: Current learning rate: 0.00533 
2025-06-16 07:39:49.292828: train_loss -0.6198 
2025-06-16 07:39:49.293534: val_loss -0.5793 
2025-06-16 07:39:49.293921: Pseudo dice [0.6388, 0.8928, 0.8648, 0.8689] 
2025-06-16 07:39:49.294251: Epoch time: 43.88 s 
2025-06-16 07:39:50.543920:  
2025-06-16 07:39:50.544445: Epoch 504 
2025-06-16 07:39:50.545091: Current learning rate: 0.00532 
2025-06-16 07:40:36.568407: train_loss -0.613 
2025-06-16 07:40:36.569211: val_loss -0.6222 
2025-06-16 07:40:36.569841: Pseudo dice [0.7664, 0.9127, 0.8808, 0.8924] 
2025-06-16 07:40:36.570288: Epoch time: 46.03 s 
2025-06-16 07:40:37.974431:  
2025-06-16 07:40:37.975002: Epoch 505 
2025-06-16 07:40:37.975357: Current learning rate: 0.00531 
2025-06-16 07:41:21.862230: train_loss -0.6139 
2025-06-16 07:41:21.863060: val_loss -0.6276 
2025-06-16 07:41:21.863510: Pseudo dice [0.6693, 0.8983, 0.889, 0.9199] 
2025-06-16 07:41:21.863946: Epoch time: 43.89 s 
2025-06-16 07:41:23.598278:  
2025-06-16 07:41:23.598849: Epoch 506 
2025-06-16 07:41:23.599212: Current learning rate: 0.0053 
2025-06-16 07:42:07.833630: train_loss -0.6354 
2025-06-16 07:42:07.834441: val_loss -0.6287 
2025-06-16 07:42:07.834850: Pseudo dice [0.7249, 0.909, 0.9159, 0.8976] 
2025-06-16 07:42:07.835203: Epoch time: 44.24 s 
2025-06-16 07:42:09.045005:  
2025-06-16 07:42:09.045617: Epoch 507 
2025-06-16 07:42:09.045992: Current learning rate: 0.00529 
2025-06-16 07:42:51.611749: train_loss -0.6188 
2025-06-16 07:42:51.612517: val_loss -0.6133 
2025-06-16 07:42:51.613060: Pseudo dice [0.7993, 0.9061, 0.9065, 0.8752] 
2025-06-16 07:42:51.613494: Epoch time: 42.57 s 
2025-06-16 07:42:52.829140:  
2025-06-16 07:42:52.829659: Epoch 508 
2025-06-16 07:42:52.830041: Current learning rate: 0.00528 
2025-06-16 07:43:36.216903: train_loss -0.6336 
2025-06-16 07:43:36.218072: val_loss -0.6284 
2025-06-16 07:43:36.218575: Pseudo dice [0.7826, 0.8978, 0.9125, 0.919] 
2025-06-16 07:43:36.218983: Epoch time: 43.39 s 
2025-06-16 07:43:37.503003:  
2025-06-16 07:43:37.503566: Epoch 509 
2025-06-16 07:43:37.503944: Current learning rate: 0.00527 
2025-06-16 07:44:19.734419: train_loss -0.6369 
2025-06-16 07:44:19.735152: val_loss -0.6476 
2025-06-16 07:44:19.735620: Pseudo dice [0.83, 0.9253, 0.8929, 0.9189] 
2025-06-16 07:44:19.736069: Epoch time: 42.23 s 
2025-06-16 07:44:20.971681:  
2025-06-16 07:44:20.972304: Epoch 510 
2025-06-16 07:44:20.972680: Current learning rate: 0.00526 
2025-06-16 07:45:05.024472: train_loss -0.6465 
2025-06-16 07:45:05.025293: val_loss -0.6408 
2025-06-16 07:45:05.025925: Pseudo dice [0.8489, 0.9117, 0.9059, 0.9186] 
2025-06-16 07:45:05.026375: Epoch time: 44.05 s 
2025-06-16 07:45:06.527679:  
2025-06-16 07:45:06.528291: Epoch 511 
2025-06-16 07:45:06.528667: Current learning rate: 0.00525 
2025-06-16 07:45:50.437017: train_loss -0.601 
2025-06-16 07:45:50.437780: val_loss -0.5649 
2025-06-16 07:45:50.438191: Pseudo dice [0.5112, 0.9105, 0.8847, 0.8905] 
2025-06-16 07:45:50.438563: Epoch time: 43.91 s 
2025-06-16 07:45:51.655212:  
2025-06-16 07:45:51.655792: Epoch 512 
2025-06-16 07:45:51.656168: Current learning rate: 0.00524 
2025-06-16 07:46:36.035027: train_loss -0.5894 
2025-06-16 07:46:36.035924: val_loss -0.5852 
2025-06-16 07:46:36.036471: Pseudo dice [0.7224, 0.8961, 0.9055, 0.8721] 
2025-06-16 07:46:36.036900: Epoch time: 44.38 s 
2025-06-16 07:46:37.605286:  
2025-06-16 07:46:37.606000: Epoch 513 
2025-06-16 07:46:37.606417: Current learning rate: 0.00523 
2025-06-16 07:47:22.445757: train_loss -0.6163 
2025-06-16 07:47:22.446381: val_loss -0.6526 
2025-06-16 07:47:22.446780: Pseudo dice [0.7915, 0.9146, 0.928, 0.9138] 
2025-06-16 07:47:22.447146: Epoch time: 44.84 s 
2025-06-16 07:47:24.343508:  
2025-06-16 07:47:24.344140: Epoch 514 
2025-06-16 07:47:24.344700: Current learning rate: 0.00522 
2025-06-16 07:48:07.818111: train_loss -0.6084 
2025-06-16 07:48:07.818974: val_loss -0.615 
2025-06-16 07:48:07.819386: Pseudo dice [0.4658, 0.9067, 0.9052, 0.8686] 
2025-06-16 07:48:07.819959: Epoch time: 43.48 s 
2025-06-16 07:48:09.159233:  
2025-06-16 07:48:09.160570: Epoch 515 
2025-06-16 07:48:09.161550: Current learning rate: 0.00521 
2025-06-16 07:48:51.984944: train_loss -0.6104 
2025-06-16 07:48:51.985691: val_loss -0.6204 
2025-06-16 07:48:51.986110: Pseudo dice [0.6943, 0.8972, 0.9057, 0.9093] 
2025-06-16 07:48:51.986437: Epoch time: 42.83 s 
2025-06-16 07:48:53.255565:  
2025-06-16 07:48:53.256112: Epoch 516 
2025-06-16 07:48:53.256513: Current learning rate: 0.0052 
2025-06-16 07:49:36.905951: train_loss -0.6252 
2025-06-16 07:49:36.906666: val_loss -0.6454 
2025-06-16 07:49:36.907125: Pseudo dice [0.7964, 0.8977, 0.892, 0.8943] 
2025-06-16 07:49:36.919660: Epoch time: 43.65 s 
2025-06-16 07:49:38.141063:  
2025-06-16 07:49:38.141609: Epoch 517 
2025-06-16 07:49:38.141962: Current learning rate: 0.00519 
2025-06-16 07:50:22.785432: train_loss -0.6282 
2025-06-16 07:50:22.786263: val_loss -0.6486 
2025-06-16 07:50:22.786872: Pseudo dice [0.7478, 0.9125, 0.9379, 0.9019] 
2025-06-16 07:50:22.787354: Epoch time: 44.65 s 
2025-06-16 07:50:24.040677:  
2025-06-16 07:50:24.041196: Epoch 518 
2025-06-16 07:50:24.041578: Current learning rate: 0.00518 
2025-06-16 07:51:08.226382: train_loss -0.6342 
2025-06-16 07:51:08.227222: val_loss -0.6578 
2025-06-16 07:51:08.227821: Pseudo dice [0.6938, 0.9268, 0.9081, 0.8914] 
2025-06-16 07:51:08.228217: Epoch time: 44.19 s 
2025-06-16 07:51:09.580842:  
2025-06-16 07:51:09.581382: Epoch 519 
2025-06-16 07:51:09.581771: Current learning rate: 0.00518 
2025-06-16 07:51:53.439623: train_loss -0.6306 
2025-06-16 07:51:53.440359: val_loss -0.6704 
2025-06-16 07:51:53.440767: Pseudo dice [0.8062, 0.9293, 0.9022, 0.8738] 
2025-06-16 07:51:53.441143: Epoch time: 43.86 s 
2025-06-16 07:51:54.719962:  
2025-06-16 07:51:54.720496: Epoch 520 
2025-06-16 07:51:54.720904: Current learning rate: 0.00517 
2025-06-16 07:52:42.568157: train_loss -0.6406 
2025-06-16 07:52:42.569002: val_loss -0.611 
2025-06-16 07:52:42.569450: Pseudo dice [0.7955, 0.9096, 0.9019, 0.8898] 
2025-06-16 07:52:42.570042: Epoch time: 47.85 s 
2025-06-16 07:52:43.981081:  
2025-06-16 07:52:43.981684: Epoch 521 
2025-06-16 07:52:43.982111: Current learning rate: 0.00516 
2025-06-16 07:53:55.409419: train_loss -0.6242 
2025-06-16 07:53:55.508779: val_loss -0.6243 
2025-06-16 07:53:55.509912: Pseudo dice [0.5504, 0.9162, 0.9106, 0.8965] 
2025-06-16 07:53:55.535271: Epoch time: 71.41 s 
2025-06-16 07:54:00.551457:  
2025-06-16 07:54:00.552229: Epoch 522 
2025-06-16 07:54:00.552639: Current learning rate: 0.00515 
2025-06-16 07:55:00.518375: train_loss -0.621 
2025-06-16 07:55:00.519554: val_loss -0.6341 
2025-06-16 07:55:00.520211: Pseudo dice [0.834, 0.9143, 0.9217, 0.9163] 
2025-06-16 07:55:00.520976: Epoch time: 59.97 s 
2025-06-16 07:55:02.262771:  
2025-06-16 07:55:02.263476: Epoch 523 
2025-06-16 07:55:02.263895: Current learning rate: 0.00514 
2025-06-16 07:56:04.243400: train_loss -0.6311 
2025-06-16 07:56:04.244528: val_loss -0.6414 
2025-06-16 07:56:04.245787: Pseudo dice [0.8207, 0.9245, 0.9226, 0.924] 
2025-06-16 07:56:04.246621: Epoch time: 61.98 s 
2025-06-16 07:56:06.036568:  
2025-06-16 07:56:06.037259: Epoch 524 
2025-06-16 07:56:06.037775: Current learning rate: 0.00513 
2025-06-16 07:57:08.554107: train_loss -0.6402 
2025-06-16 07:57:08.554927: val_loss -0.6372 
2025-06-16 07:57:08.555443: Pseudo dice [0.7608, 0.9055, 0.8986, 0.8971] 
2025-06-16 07:57:08.556015: Epoch time: 62.52 s 
2025-06-16 07:57:10.495602:  
2025-06-16 07:57:10.496205: Epoch 525 
2025-06-16 07:57:10.496627: Current learning rate: 0.00512 
2025-06-16 07:58:15.945969: train_loss -0.6236 
2025-06-16 07:58:15.946947: val_loss -0.6478 
2025-06-16 07:58:15.947638: Pseudo dice [0.7049, 0.9177, 0.9054, 0.9116] 
2025-06-16 07:58:15.948199: Epoch time: 65.45 s 
2025-06-16 07:58:18.015815:  
2025-06-16 07:58:18.016418: Epoch 526 
2025-06-16 07:58:18.016841: Current learning rate: 0.00511 
2025-06-16 07:59:26.270164: train_loss -0.6155 
2025-06-16 07:59:26.271011: val_loss -0.6385 
2025-06-16 07:59:26.271566: Pseudo dice [0.807, 0.9134, 0.9047, 0.9253] 
2025-06-16 07:59:26.272280: Epoch time: 68.26 s 
2025-06-16 07:59:28.302707:  
2025-06-16 07:59:28.303602: Epoch 527 
2025-06-16 07:59:28.304054: Current learning rate: 0.0051 
2025-06-16 08:00:18.596593: train_loss -0.606 
2025-06-16 08:00:18.597531: val_loss -0.6377 
2025-06-16 08:00:18.597993: Pseudo dice [0.7442, 0.9115, 0.9093, 0.881] 
2025-06-16 08:00:18.598419: Epoch time: 50.3 s 
2025-06-16 08:00:20.437770:  
2025-06-16 08:00:20.438369: Epoch 528 
2025-06-16 08:00:20.438938: Current learning rate: 0.00509 
2025-06-16 08:01:11.112335: train_loss -0.625 
2025-06-16 08:01:11.113098: val_loss -0.6434 
2025-06-16 08:01:11.113569: Pseudo dice [0.8043, 0.9178, 0.9283, 0.897] 
2025-06-16 08:01:11.113974: Epoch time: 50.68 s 
2025-06-16 08:01:12.766846:  
2025-06-16 08:01:12.767889: Epoch 529 
2025-06-16 08:01:12.768773: Current learning rate: 0.00508 
2025-06-16 08:02:13.237994: train_loss -0.6347 
2025-06-16 08:02:13.239376: val_loss -0.5993 
2025-06-16 08:02:13.240362: Pseudo dice [0.7674, 0.8968, 0.9002, 0.8957] 
2025-06-16 08:02:13.241232: Epoch time: 60.47 s 
2025-06-16 08:02:19.907574:  
2025-06-16 08:02:19.908194: Epoch 530 
2025-06-16 08:02:19.908805: Current learning rate: 0.00507 
2025-06-16 08:03:23.288320: train_loss -0.6253 
2025-06-16 08:03:23.315557: val_loss -0.6432 
2025-06-16 08:03:23.316489: Pseudo dice [0.7918, 0.9204, 0.9294, 0.8904] 
2025-06-16 08:03:23.318273: Epoch time: 63.37 s 
2025-06-16 08:03:26.529471:  
2025-06-16 08:03:26.530183: Epoch 531 
2025-06-16 08:03:26.530727: Current learning rate: 0.00506 
2025-06-16 08:04:39.157906: train_loss -0.6253 
2025-06-16 08:04:39.158648: val_loss -0.6317 
2025-06-16 08:04:39.159175: Pseudo dice [0.7342, 0.9133, 0.918, 0.8891] 
2025-06-16 08:04:39.159581: Epoch time: 72.63 s 
2025-06-16 08:04:40.892010:  
2025-06-16 08:04:40.892611: Epoch 532 
2025-06-16 08:04:40.893041: Current learning rate: 0.00505 
2025-06-16 08:05:32.972022: train_loss -0.6274 
2025-06-16 08:05:32.973320: val_loss -0.6009 
2025-06-16 08:05:32.973800: Pseudo dice [0.7736, 0.8736, 0.8727, 0.9057] 
2025-06-16 08:05:32.974207: Epoch time: 52.08 s 
2025-06-16 08:05:34.360852:  
2025-06-16 08:05:34.361367: Epoch 533 
2025-06-16 08:05:34.361797: Current learning rate: 0.00504 
2025-06-16 08:06:26.600762: train_loss -0.6181 
2025-06-16 08:06:26.601671: val_loss -0.6397 
2025-06-16 08:06:26.602256: Pseudo dice [0.7896, 0.9239, 0.9199, 0.8947] 
2025-06-16 08:06:26.602837: Epoch time: 52.24 s 
2025-06-16 08:06:28.425900:  
2025-06-16 08:06:28.426854: Epoch 534 
2025-06-16 08:06:28.427633: Current learning rate: 0.00503 
2025-06-16 08:07:34.723049: train_loss -0.6285 
2025-06-16 08:07:34.724237: val_loss -0.6256 
2025-06-16 08:07:34.724976: Pseudo dice [0.8254, 0.9084, 0.903, 0.8909] 
2025-06-16 08:07:34.725775: Epoch time: 66.3 s 
2025-06-16 08:07:36.642910:  
2025-06-16 08:07:36.643514: Epoch 535 
2025-06-16 08:07:36.644048: Current learning rate: 0.00502 
2025-06-16 08:08:32.382140: train_loss -0.6238 
2025-06-16 08:08:32.412346: val_loss -0.6319 
2025-06-16 08:08:32.412940: Pseudo dice [0.8394, 0.9219, 0.9236, 0.9012] 
2025-06-16 08:08:32.414096: Epoch time: 55.7 s 
2025-06-16 08:08:35.063097:  
2025-06-16 08:08:35.063757: Epoch 536 
2025-06-16 08:08:35.064723: Current learning rate: 0.00501 
2025-06-16 08:09:44.669178: train_loss -0.6242 
2025-06-16 08:09:44.670336: val_loss -0.6471 
2025-06-16 08:09:44.671240: Pseudo dice [0.7388, 0.9112, 0.9241, 0.8899] 
2025-06-16 08:09:44.672072: Epoch time: 69.61 s 
2025-06-16 08:09:54.050065:  
2025-06-16 08:09:54.050871: Epoch 537 
2025-06-16 08:09:54.051522: Current learning rate: 0.005 
2025-06-16 08:10:48.021672: train_loss -0.6315 
2025-06-16 08:10:48.087495: val_loss -0.6591 
2025-06-16 08:10:48.088177: Pseudo dice [0.8025, 0.9269, 0.9207, 0.9114] 
2025-06-16 08:10:48.104001: Epoch time: 53.97 s 
2025-06-16 08:10:49.922437:  
2025-06-16 08:10:49.922995: Epoch 538 
2025-06-16 08:10:49.923403: Current learning rate: 0.00499 
2025-06-16 08:11:50.315915: train_loss -0.6331 
2025-06-16 08:11:50.316684: val_loss -0.6281 
2025-06-16 08:11:50.317291: Pseudo dice [0.737, 0.9191, 0.9097, 0.904] 
2025-06-16 08:11:50.317839: Epoch time: 60.39 s 
2025-06-16 08:11:52.363495:  
2025-06-16 08:11:52.364188: Epoch 539 
2025-06-16 08:11:52.364658: Current learning rate: 0.00498 
2025-06-16 08:12:55.137592: train_loss -0.6342 
2025-06-16 08:12:55.138595: val_loss -0.6606 
2025-06-16 08:12:55.139123: Pseudo dice [0.8058, 0.9291, 0.9067, 0.9046] 
2025-06-16 08:12:55.139796: Epoch time: 62.78 s 
2025-06-16 08:12:57.017743:  
2025-06-16 08:12:57.018370: Epoch 540 
2025-06-16 08:12:57.018784: Current learning rate: 0.00497 
2025-06-16 08:13:53.465096: train_loss -0.6327 
2025-06-16 08:13:53.465963: val_loss -0.6356 
2025-06-16 08:13:53.466871: Pseudo dice [0.8271, 0.9164, 0.8952, 0.8981] 
2025-06-16 08:13:53.467509: Epoch time: 56.45 s 
2025-06-16 08:13:55.443733:  
2025-06-16 08:13:55.444303: Epoch 541 
2025-06-16 08:13:55.444718: Current learning rate: 0.00496 
2025-06-16 08:14:59.856464: train_loss -0.6402 
2025-06-16 08:14:59.857071: val_loss -0.6461 
2025-06-16 08:14:59.857472: Pseudo dice [0.7408, 0.9178, 0.9168, 0.9167] 
2025-06-16 08:14:59.858001: Epoch time: 64.41 s 
2025-06-16 08:15:01.764776:  
2025-06-16 08:15:01.765525: Epoch 542 
2025-06-16 08:15:01.765949: Current learning rate: 0.00495 
2025-06-16 08:15:49.362825: train_loss -0.6329 
2025-06-16 08:15:49.363637: val_loss -0.661 
2025-06-16 08:15:49.364460: Pseudo dice [0.7594, 0.9194, 0.9186, 0.9098] 
2025-06-16 08:15:49.364943: Epoch time: 47.6 s 
2025-06-16 08:15:51.048373:  
2025-06-16 08:15:51.049051: Epoch 543 
2025-06-16 08:15:51.049511: Current learning rate: 0.00494 
2025-06-16 08:16:42.141329: train_loss -0.6347 
2025-06-16 08:16:42.142305: val_loss -0.6324 
2025-06-16 08:16:42.142933: Pseudo dice [0.6965, 0.9173, 0.8891, 0.8982] 
2025-06-16 08:16:42.143393: Epoch time: 51.09 s 
2025-06-16 08:16:44.015341:  
2025-06-16 08:16:44.015985: Epoch 544 
2025-06-16 08:16:44.016592: Current learning rate: 0.00493 
2025-06-16 08:17:49.302740: train_loss -0.6336 
2025-06-16 08:17:49.434479: val_loss -0.6142 
2025-06-16 08:17:49.435122: Pseudo dice [0.675, 0.9174, 0.8811, 0.8969] 
2025-06-16 08:17:49.449837: Epoch time: 65.27 s 
2025-06-16 08:17:54.304064:  
2025-06-16 08:17:54.304701: Epoch 545 
2025-06-16 08:17:54.305115: Current learning rate: 0.00492 
2025-06-16 08:18:48.706414: train_loss -0.643 
2025-06-16 08:18:48.708149: val_loss -0.6623 
2025-06-16 08:18:48.709079: Pseudo dice [0.7828, 0.9215, 0.9118, 0.9345] 
2025-06-16 08:18:48.709893: Epoch time: 54.4 s 
2025-06-16 08:18:50.713251:  
2025-06-16 08:18:50.715276: Epoch 546 
2025-06-16 08:18:50.716377: Current learning rate: 0.00491 
2025-06-16 08:19:42.888698: train_loss -0.6412 
2025-06-16 08:19:42.889383: val_loss -0.6415 
2025-06-16 08:19:42.889822: Pseudo dice [0.6676, 0.9186, 0.9026, 0.8713] 
2025-06-16 08:19:42.890219: Epoch time: 52.18 s 
2025-06-16 08:19:44.166760:  
2025-06-16 08:19:44.167583: Epoch 547 
2025-06-16 08:19:44.168143: Current learning rate: 0.0049 
2025-06-16 08:20:29.909553: train_loss -0.6334 
2025-06-16 08:20:29.910256: val_loss -0.6489 
2025-06-16 08:20:29.910650: Pseudo dice [0.807, 0.9229, 0.9136, 0.9281] 
2025-06-16 08:20:29.911028: Epoch time: 45.74 s 
2025-06-16 08:20:31.498716:  
2025-06-16 08:20:31.499643: Epoch 548 
2025-06-16 08:20:31.500410: Current learning rate: 0.00489 
2025-06-16 08:21:15.949284: train_loss -0.6239 
2025-06-16 08:21:15.950006: val_loss -0.6588 
2025-06-16 08:21:15.950426: Pseudo dice [0.7771, 0.9256, 0.923, 0.9015] 
2025-06-16 08:21:15.950948: Epoch time: 44.45 s 
2025-06-16 08:21:17.182435:  
2025-06-16 08:21:17.183241: Epoch 549 
2025-06-16 08:21:17.183612: Current learning rate: 0.00488 
2025-06-16 08:21:59.341259: train_loss -0.6414 
2025-06-16 08:21:59.342069: val_loss -0.6318 
2025-06-16 08:21:59.342529: Pseudo dice [0.7572, 0.9036, 0.8919, 0.9141] 
2025-06-16 08:21:59.343092: Epoch time: 42.16 s 
2025-06-16 08:22:01.348735:  
2025-06-16 08:22:01.349473: Epoch 550 
2025-06-16 08:22:01.349966: Current learning rate: 0.00487 
2025-06-16 08:22:44.516276: train_loss -0.6252 
2025-06-16 08:22:44.516955: val_loss -0.6384 
2025-06-16 08:22:44.517344: Pseudo dice [0.8605, 0.92, 0.9053, 0.8994] 
2025-06-16 08:22:44.517864: Epoch time: 43.17 s 
2025-06-16 08:22:46.155911:  
2025-06-16 08:22:46.156722: Epoch 551 
2025-06-16 08:22:46.157141: Current learning rate: 0.00486 
2025-06-16 08:23:30.963414: train_loss -0.6399 
2025-06-16 08:23:30.964111: val_loss -0.6329 
2025-06-16 08:23:30.964523: Pseudo dice [0.7787, 0.9201, 0.9012, 0.8863] 
2025-06-16 08:23:30.965203: Epoch time: 44.81 s 
2025-06-16 08:23:32.406632:  
2025-06-16 08:23:32.407222: Epoch 552 
2025-06-16 08:23:32.407638: Current learning rate: 0.00485 
2025-06-16 08:24:15.911688: train_loss -0.6275 
2025-06-16 08:24:15.912626: val_loss -0.6421 
2025-06-16 08:24:15.913160: Pseudo dice [0.7951, 0.9148, 0.9254, 0.899] 
2025-06-16 08:24:15.913708: Epoch time: 43.51 s 
2025-06-16 08:24:17.528019:  
2025-06-16 08:24:17.528918: Epoch 553 
2025-06-16 08:24:17.529625: Current learning rate: 0.00484 
2025-06-16 08:25:02.328285: train_loss -0.6404 
2025-06-16 08:25:02.329078: val_loss -0.6363 
2025-06-16 08:25:02.329483: Pseudo dice [0.8335, 0.9097, 0.9017, 0.9089] 
2025-06-16 08:25:02.330004: Epoch time: 44.8 s 
2025-06-16 08:25:03.550822:  
2025-06-16 08:25:03.551406: Epoch 554 
2025-06-16 08:25:03.551932: Current learning rate: 0.00484 
2025-06-16 08:25:47.037989: train_loss -0.6337 
2025-06-16 08:25:47.038741: val_loss -0.6466 
2025-06-16 08:25:47.039137: Pseudo dice [0.8108, 0.9156, 0.8993, 0.916] 
2025-06-16 08:25:47.039475: Epoch time: 43.49 s 
2025-06-16 08:25:48.265021:  
2025-06-16 08:25:48.265582: Epoch 555 
2025-06-16 08:25:48.266157: Current learning rate: 0.00483 
2025-06-16 08:26:32.363971: train_loss -0.6289 
2025-06-16 08:26:32.364765: val_loss -0.6254 
2025-06-16 08:26:32.365224: Pseudo dice [0.8482, 0.9218, 0.9069, 0.9175] 
2025-06-16 08:26:32.365791: Epoch time: 44.1 s 
2025-06-16 08:26:34.065005:  
2025-06-16 08:26:34.065691: Epoch 556 
2025-06-16 08:26:34.066101: Current learning rate: 0.00482 
2025-06-16 08:27:18.580595: train_loss -0.6349 
2025-06-16 08:27:18.581431: val_loss -0.6325 
2025-06-16 08:27:18.581864: Pseudo dice [0.7163, 0.9145, 0.9134, 0.8924] 
2025-06-16 08:27:18.582262: Epoch time: 44.52 s 
2025-06-16 08:27:19.776782:  
2025-06-16 08:27:19.777425: Epoch 557 
2025-06-16 08:27:19.777814: Current learning rate: 0.00481 
2025-06-16 08:28:06.077643: train_loss -0.6329 
2025-06-16 08:28:06.078467: val_loss -0.6499 
2025-06-16 08:28:06.079083: Pseudo dice [0.8358, 0.9204, 0.916, 0.9184] 
2025-06-16 08:28:06.079805: Epoch time: 46.3 s 
2025-06-16 08:28:07.336883:  
2025-06-16 08:28:07.337433: Epoch 558 
2025-06-16 08:28:07.337796: Current learning rate: 0.0048 
2025-06-16 08:28:50.479710: train_loss -0.6425 
2025-06-16 08:28:50.480396: val_loss -0.656 
2025-06-16 08:28:50.480847: Pseudo dice [0.7727, 0.9209, 0.9293, 0.9264] 
2025-06-16 08:28:50.481194: Epoch time: 43.14 s 
2025-06-16 08:28:52.109968:  
2025-06-16 08:28:52.110777: Epoch 559 
2025-06-16 08:28:52.111837: Current learning rate: 0.00479 
2025-06-16 08:29:36.678268: train_loss -0.6252 
2025-06-16 08:29:36.679068: val_loss -0.6207 
2025-06-16 08:29:36.679507: Pseudo dice [0.7264, 0.8633, 0.9009, 0.8782] 
2025-06-16 08:29:36.680038: Epoch time: 44.57 s 
2025-06-16 08:29:38.468598:  
2025-06-16 08:29:38.469351: Epoch 560 
2025-06-16 08:29:38.469836: Current learning rate: 0.00478 
2025-06-16 08:30:23.152185: train_loss -0.6191 
2025-06-16 08:30:23.153045: val_loss -0.6303 
2025-06-16 08:30:23.153529: Pseudo dice [0.7804, 0.8993, 0.9069, 0.8719] 
2025-06-16 08:30:23.154084: Epoch time: 44.68 s 
2025-06-16 08:30:24.523688:  
2025-06-16 08:30:24.524209: Epoch 561 
2025-06-16 08:30:24.524604: Current learning rate: 0.00477 
2025-06-16 08:31:09.915553: train_loss -0.6166 
2025-06-16 08:31:09.916253: val_loss -0.6034 
2025-06-16 08:31:09.916769: Pseudo dice [0.8061, 0.9001, 0.9114, 0.9164] 
2025-06-16 08:31:09.917211: Epoch time: 45.39 s 
2025-06-16 08:31:11.133240:  
2025-06-16 08:31:11.133961: Epoch 562 
2025-06-16 08:31:11.134358: Current learning rate: 0.00476 
2025-06-16 08:31:55.649774: train_loss -0.6364 
2025-06-16 08:31:55.650691: val_loss -0.6528 
2025-06-16 08:31:55.651254: Pseudo dice [0.7043, 0.9048, 0.9054, 0.8898] 
2025-06-16 08:31:55.651843: Epoch time: 44.52 s 
2025-06-16 08:31:57.361492:  
2025-06-16 08:31:57.362258: Epoch 563 
2025-06-16 08:31:57.363207: Current learning rate: 0.00475 
2025-06-16 08:32:42.653987: train_loss -0.6318 
2025-06-16 08:32:42.654740: val_loss -0.6265 
2025-06-16 08:32:42.655237: Pseudo dice [0.8022, 0.9153, 0.9207, 0.9066] 
2025-06-16 08:32:42.655587: Epoch time: 45.29 s 
2025-06-16 08:32:43.965705:  
2025-06-16 08:32:43.966235: Epoch 564 
2025-06-16 08:32:43.966612: Current learning rate: 0.00474 
2025-06-16 08:33:27.839298: train_loss -0.632 
2025-06-16 08:33:27.840040: val_loss -0.6245 
2025-06-16 08:33:27.840414: Pseudo dice [0.7529, 0.9066, 0.9081, 0.9104] 
2025-06-16 08:33:27.840957: Epoch time: 43.87 s 
2025-06-16 08:33:29.184889:  
2025-06-16 08:33:29.185493: Epoch 565 
2025-06-16 08:33:29.185884: Current learning rate: 0.00473 
2025-06-16 08:34:13.508789: train_loss -0.6279 
2025-06-16 08:34:13.509653: val_loss -0.6565 
2025-06-16 08:34:13.510129: Pseudo dice [0.7501, 0.9202, 0.8895, 0.9263] 
2025-06-16 08:34:13.510537: Epoch time: 44.32 s 
2025-06-16 08:34:14.732078:  
2025-06-16 08:34:14.732755: Epoch 566 
2025-06-16 08:34:14.733159: Current learning rate: 0.00472 
2025-06-16 08:34:58.997842: train_loss -0.6329 
2025-06-16 08:34:58.998587: val_loss -0.6171 
2025-06-16 08:34:58.999103: Pseudo dice [0.7462, 0.9155, 0.8968, 0.8974] 
2025-06-16 08:34:58.999525: Epoch time: 44.27 s 
2025-06-16 08:35:00.527025:  
2025-06-16 08:35:00.527721: Epoch 567 
2025-06-16 08:35:00.528114: Current learning rate: 0.00471 
2025-06-16 08:35:43.778174: train_loss -0.6279 
2025-06-16 08:35:43.779096: val_loss -0.64 
2025-06-16 08:35:43.779490: Pseudo dice [0.7947, 0.9078, 0.9158, 0.8949] 
2025-06-16 08:35:43.780003: Epoch time: 43.25 s 
2025-06-16 08:35:44.983197:  
2025-06-16 08:35:44.983851: Epoch 568 
2025-06-16 08:35:44.984373: Current learning rate: 0.0047 
2025-06-16 08:36:28.966417: train_loss -0.6333 
2025-06-16 08:36:28.967227: val_loss -0.6194 
2025-06-16 08:36:28.967828: Pseudo dice [0.8011, 0.9161, 0.8989, 0.9016] 
2025-06-16 08:36:28.968261: Epoch time: 43.98 s 
2025-06-16 08:36:30.457657:  
2025-06-16 08:36:30.458279: Epoch 569 
2025-06-16 08:36:30.458658: Current learning rate: 0.00469 
2025-06-16 08:37:16.919242: train_loss -0.6396 
2025-06-16 08:37:16.920075: val_loss -0.6209 
2025-06-16 08:37:16.920549: Pseudo dice [0.806, 0.9205, 0.8903, 0.8979] 
2025-06-16 08:37:16.921209: Epoch time: 46.46 s 
2025-06-16 08:37:18.554662:  
2025-06-16 08:37:18.555229: Epoch 570 
2025-06-16 08:37:18.555816: Current learning rate: 0.00468 
2025-06-16 08:38:02.820168: train_loss -0.6265 
2025-06-16 08:38:02.820884: val_loss -0.6484 
2025-06-16 08:38:02.821262: Pseudo dice [0.779, 0.9222, 0.9097, 0.9049] 
2025-06-16 08:38:02.821768: Epoch time: 44.27 s 
2025-06-16 08:38:04.367618:  
2025-06-16 08:38:04.368161: Epoch 571 
2025-06-16 08:38:04.368546: Current learning rate: 0.00467 
2025-06-16 08:38:48.630001: train_loss -0.6324 
2025-06-16 08:38:48.630717: val_loss -0.6343 
2025-06-16 08:38:48.631105: Pseudo dice [0.8419, 0.9089, 0.9054, 0.9168] 
2025-06-16 08:38:48.631448: Epoch time: 44.26 s 
2025-06-16 08:38:49.832109:  
2025-06-16 08:38:49.832675: Epoch 572 
2025-06-16 08:38:49.833059: Current learning rate: 0.00466 
2025-06-16 08:39:34.611721: train_loss -0.6261 
2025-06-16 08:39:34.612634: val_loss -0.6215 
2025-06-16 08:39:34.613133: Pseudo dice [0.7207, 0.9128, 0.9059, 0.8999] 
2025-06-16 08:39:34.613491: Epoch time: 44.78 s 
2025-06-16 08:39:35.831884:  
2025-06-16 08:39:35.832428: Epoch 573 
2025-06-16 08:39:35.832792: Current learning rate: 0.00465 
2025-06-16 08:40:17.739503: train_loss -0.639 
2025-06-16 08:40:17.740333: val_loss -0.6458 
2025-06-16 08:40:17.740789: Pseudo dice [0.8416, 0.9193, 0.9179, 0.9076] 
2025-06-16 08:40:17.741206: Epoch time: 41.91 s 
2025-06-16 08:40:19.206121:  
2025-06-16 08:40:19.206760: Epoch 574 
2025-06-16 08:40:19.207281: Current learning rate: 0.00464 
2025-06-16 08:41:02.653245: train_loss -0.6395 
2025-06-16 08:41:02.654204: val_loss -0.6417 
2025-06-16 08:41:02.658386: Pseudo dice [0.772, 0.9167, 0.9134, 0.9006] 
2025-06-16 08:41:02.658833: Epoch time: 43.45 s 
2025-06-16 08:41:04.393307:  
2025-06-16 08:41:04.393864: Epoch 575 
2025-06-16 08:41:04.394258: Current learning rate: 0.00463 
2025-06-16 08:41:47.700510: train_loss -0.635 
2025-06-16 08:41:47.701239: val_loss -0.6376 
2025-06-16 08:41:47.701647: Pseudo dice [0.7666, 0.9262, 0.907, 0.9047] 
2025-06-16 08:41:47.701998: Epoch time: 43.31 s 
2025-06-16 08:41:48.951764:  
2025-06-16 08:41:48.952298: Epoch 576 
2025-06-16 08:41:48.952663: Current learning rate: 0.00462 
2025-06-16 08:42:32.531326: train_loss -0.6351 
2025-06-16 08:42:32.532015: val_loss -0.6054 
2025-06-16 08:42:32.532457: Pseudo dice [0.7979, 0.9106, 0.8648, 0.8812] 
2025-06-16 08:42:32.532978: Epoch time: 43.58 s 
2025-06-16 08:42:33.900520:  
2025-06-16 08:42:33.901180: Epoch 577 
2025-06-16 08:42:33.901623: Current learning rate: 0.00461 
2025-06-16 08:43:16.265798: train_loss -0.6157 
2025-06-16 08:43:16.266451: val_loss -0.6206 
2025-06-16 08:43:16.266819: Pseudo dice [0.7844, 0.9278, 0.9096, 0.9036] 
2025-06-16 08:43:16.267152: Epoch time: 42.37 s 
2025-06-16 08:43:17.963511:  
2025-06-16 08:43:17.964404: Epoch 578 
2025-06-16 08:43:17.965274: Current learning rate: 0.0046 
2025-06-16 08:44:01.694205: train_loss -0.6355 
2025-06-16 08:44:01.694963: val_loss -0.6577 
2025-06-16 08:44:01.695347: Pseudo dice [0.7083, 0.8988, 0.8998, 0.904] 
2025-06-16 08:44:01.695845: Epoch time: 43.73 s 
2025-06-16 08:44:02.993007:  
2025-06-16 08:44:02.993531: Epoch 579 
2025-06-16 08:44:02.993891: Current learning rate: 0.00459 
2025-06-16 08:44:46.895751: train_loss -0.6353 
2025-06-16 08:44:46.896746: val_loss -0.643 
2025-06-16 08:44:46.897749: Pseudo dice [0.8023, 0.9164, 0.8952, 0.9145] 
2025-06-16 08:44:46.898275: Epoch time: 43.9 s 
2025-06-16 08:44:48.559879:  
2025-06-16 08:44:48.560511: Epoch 580 
2025-06-16 08:44:48.560897: Current learning rate: 0.00458 
2025-06-16 08:45:32.797014: train_loss -0.6368 
2025-06-16 08:45:32.797803: val_loss -0.6469 
2025-06-16 08:45:32.798245: Pseudo dice [0.789, 0.9143, 0.8768, 0.9001] 
2025-06-16 08:45:32.798774: Epoch time: 44.24 s 
2025-06-16 08:45:34.586493:  
2025-06-16 08:45:34.587262: Epoch 581 
2025-06-16 08:45:34.588281: Current learning rate: 0.00457 
2025-06-16 08:46:17.164478: train_loss -0.6236 
2025-06-16 08:46:17.165273: val_loss -0.6576 
2025-06-16 08:46:17.165844: Pseudo dice [0.8302, 0.9211, 0.9202, 0.9056] 
2025-06-16 08:46:17.166245: Epoch time: 42.58 s 
2025-06-16 08:46:18.901768:  
2025-06-16 08:46:18.902323: Epoch 582 
2025-06-16 08:46:18.902880: Current learning rate: 0.00456 
2025-06-16 08:46:59.009691: train_loss -0.6413 
2025-06-16 08:46:59.010531: val_loss -0.6347 
2025-06-16 08:46:59.010998: Pseudo dice [0.8231, 0.9251, 0.8949, 0.8677] 
2025-06-16 08:46:59.011377: Epoch time: 40.11 s 
2025-06-16 08:47:00.342963:  
2025-06-16 08:47:00.343581: Epoch 583 
2025-06-16 08:47:00.343989: Current learning rate: 0.00455 
2025-06-16 08:47:43.163121: train_loss -0.6305 
2025-06-16 08:47:43.163816: val_loss -0.6272 
2025-06-16 08:47:43.164177: Pseudo dice [0.7604, 0.9165, 0.901, 0.9011] 
2025-06-16 08:47:43.164487: Epoch time: 42.82 s 
2025-06-16 08:47:44.768001:  
2025-06-16 08:47:44.768610: Epoch 584 
2025-06-16 08:47:44.769010: Current learning rate: 0.00454 
2025-06-16 08:48:27.023369: train_loss -0.6486 
2025-06-16 08:48:27.024160: val_loss -0.6423 
2025-06-16 08:48:27.024636: Pseudo dice [0.7627, 0.9075, 0.9072, 0.8812] 
2025-06-16 08:48:27.025187: Epoch time: 42.26 s 
2025-06-16 08:48:28.277761:  
2025-06-16 08:48:28.278299: Epoch 585 
2025-06-16 08:48:28.278686: Current learning rate: 0.00453 
2025-06-16 08:49:12.394810: train_loss -0.6445 
2025-06-16 08:49:12.395576: val_loss -0.6712 
2025-06-16 08:49:12.396041: Pseudo dice [0.7991, 0.9223, 0.9159, 0.9133] 
2025-06-16 08:49:12.396444: Epoch time: 44.12 s 
2025-06-16 08:49:13.748599:  
2025-06-16 08:49:13.749241: Epoch 586 
2025-06-16 08:49:13.749620: Current learning rate: 0.00452 
2025-06-16 08:49:57.743444: train_loss -0.6337 
2025-06-16 08:49:57.744262: val_loss -0.6519 
2025-06-16 08:49:57.744726: Pseudo dice [0.6466, 0.9217, 0.8791, 0.917] 
2025-06-16 08:49:57.745070: Epoch time: 44.0 s 
2025-06-16 08:49:59.003996:  
2025-06-16 08:49:59.004554: Epoch 587 
2025-06-16 08:49:59.005121: Current learning rate: 0.00451 
2025-06-16 08:50:42.481824: train_loss -0.6443 
2025-06-16 08:50:42.482544: val_loss -0.6366 
2025-06-16 08:50:42.482930: Pseudo dice [0.7778, 0.9269, 0.917, 0.8961] 
2025-06-16 08:50:42.483283: Epoch time: 43.48 s 
2025-06-16 08:50:43.718863:  
2025-06-16 08:50:43.719395: Epoch 588 
2025-06-16 08:50:43.719804: Current learning rate: 0.0045 
2025-06-16 08:51:27.567961: train_loss -0.6404 
2025-06-16 08:51:27.568773: val_loss -0.6464 
2025-06-16 08:51:27.569230: Pseudo dice [0.7624, 0.9091, 0.9134, 0.9301] 
2025-06-16 08:51:27.569768: Epoch time: 43.85 s 
2025-06-16 08:51:29.066717:  
2025-06-16 08:51:29.067170: Epoch 589 
2025-06-16 08:51:29.067524: Current learning rate: 0.00449 
2025-06-16 08:52:11.154058: train_loss -0.6414 
2025-06-16 08:52:11.154903: val_loss -0.6206 
2025-06-16 08:52:11.155414: Pseudo dice [0.8409, 0.9166, 0.9056, 0.9217] 
2025-06-16 08:52:11.155870: Epoch time: 42.09 s 
2025-06-16 08:52:12.845841:  
2025-06-16 08:52:12.846624: Epoch 590 
2025-06-16 08:52:12.847386: Current learning rate: 0.00448 
2025-06-16 08:52:56.167010: train_loss -0.6468 
2025-06-16 08:52:56.167778: val_loss -0.6639 
2025-06-16 08:52:56.168309: Pseudo dice [0.8082, 0.929, 0.9027, 0.9401] 
2025-06-16 08:52:56.168821: Epoch time: 43.32 s 
2025-06-16 08:52:57.783053:  
2025-06-16 08:52:57.783636: Epoch 591 
2025-06-16 08:52:57.784047: Current learning rate: 0.00447 
2025-06-16 08:53:42.302346: train_loss -0.6383 
2025-06-16 08:53:42.303109: val_loss -0.6523 
2025-06-16 08:53:42.303522: Pseudo dice [0.6487, 0.9143, 0.898, 0.9018] 
2025-06-16 08:53:42.304045: Epoch time: 44.52 s 
2025-06-16 08:53:43.556178:  
2025-06-16 08:53:43.556705: Epoch 592 
2025-06-16 08:53:43.557092: Current learning rate: 0.00446 
2025-06-16 08:54:25.094871: train_loss -0.6517 
2025-06-16 08:54:25.095466: val_loss -0.6255 
2025-06-16 08:54:25.095962: Pseudo dice [0.8051, 0.9161, 0.9042, 0.9169] 
2025-06-16 08:54:25.096327: Epoch time: 41.54 s 
2025-06-16 08:54:26.428550:  
2025-06-16 08:54:26.429125: Epoch 593 
2025-06-16 08:54:26.429558: Current learning rate: 0.00445 
2025-06-16 08:55:10.230984: train_loss -0.6418 
2025-06-16 08:55:10.231825: val_loss -0.6364 
2025-06-16 08:55:10.232274: Pseudo dice [0.8455, 0.9021, 0.9163, 0.9139] 
2025-06-16 08:55:10.232814: Epoch time: 43.8 s 
2025-06-16 08:55:11.832570:  
2025-06-16 08:55:11.833231: Epoch 594 
2025-06-16 08:55:11.833606: Current learning rate: 0.00444 
2025-06-16 08:55:53.553912: train_loss -0.6433 
2025-06-16 08:55:53.554835: val_loss -0.6093 
2025-06-16 08:55:53.555292: Pseudo dice [0.7763, 0.9036, 0.8684, 0.9185] 
2025-06-16 08:55:53.555680: Epoch time: 41.72 s 
2025-06-16 08:55:55.269662:  
2025-06-16 08:55:55.270631: Epoch 595 
2025-06-16 08:55:55.271517: Current learning rate: 0.00443 
2025-06-16 08:56:40.558460: train_loss -0.6179 
2025-06-16 08:56:40.559270: val_loss -0.643 
2025-06-16 08:56:40.559657: Pseudo dice [0.8432, 0.9156, 0.9229, 0.8984] 
2025-06-16 08:56:40.559991: Epoch time: 45.29 s 
2025-06-16 08:56:41.924070:  
2025-06-16 08:56:41.924576: Epoch 596 
2025-06-16 08:56:41.924918: Current learning rate: 0.00442 
2025-06-16 08:57:25.066879: train_loss -0.6381 
2025-06-16 08:57:25.067683: val_loss -0.6547 
2025-06-16 08:57:25.068246: Pseudo dice [0.8132, 0.924, 0.9098, 0.9181] 
2025-06-16 08:57:25.068619: Epoch time: 43.14 s 
2025-06-16 08:57:27.056584:  
2025-06-16 08:57:27.057187: Epoch 597 
2025-06-16 08:57:27.057639: Current learning rate: 0.00441 
2025-06-16 08:58:12.225483: train_loss -0.6105 
2025-06-16 08:58:12.226231: val_loss -0.6232 
2025-06-16 08:58:12.226806: Pseudo dice [0.798, 0.923, 0.9004, 0.8967] 
2025-06-16 08:58:12.227249: Epoch time: 45.17 s 
2025-06-16 08:58:13.874270:  
2025-06-16 08:58:13.875311: Epoch 598 
2025-06-16 08:58:13.876254: Current learning rate: 0.0044 
2025-06-16 08:58:55.316021: train_loss -0.6182 
2025-06-16 08:58:55.316781: val_loss -0.6393 
2025-06-16 08:58:55.317160: Pseudo dice [0.74, 0.9171, 0.9134, 0.9137] 
2025-06-16 08:58:55.317515: Epoch time: 41.44 s 
2025-06-16 08:58:56.528210:  
2025-06-16 08:58:56.528815: Epoch 599 
2025-06-16 08:58:56.529194: Current learning rate: 0.00439 
2025-06-16 08:59:40.439050: train_loss -0.6278 
2025-06-16 08:59:40.439811: val_loss -0.651 
2025-06-16 08:59:40.440195: Pseudo dice [0.73, 0.9149, 0.9065, 0.9257] 
2025-06-16 08:59:40.440616: Epoch time: 43.91 s 
2025-06-16 08:59:41.998606:  
2025-06-16 08:59:41.999211: Epoch 600 
2025-06-16 08:59:41.999619: Current learning rate: 0.00438 
2025-06-16 09:00:26.365288: train_loss -0.6523 
2025-06-16 09:00:26.366056: val_loss -0.6439 
2025-06-16 09:00:26.366440: Pseudo dice [0.8232, 0.9146, 0.9133, 0.9073] 
2025-06-16 09:00:26.367010: Epoch time: 44.37 s 
2025-06-16 09:00:27.647720:  
2025-06-16 09:00:27.648349: Epoch 601 
2025-06-16 09:00:27.648728: Current learning rate: 0.00437 
2025-06-16 09:01:12.459889: train_loss -0.6459 
2025-06-16 09:01:12.460763: val_loss -0.6482 
2025-06-16 09:01:12.461162: Pseudo dice [0.7788, 0.9262, 0.9057, 0.9274] 
2025-06-16 09:01:12.461493: Epoch time: 44.81 s 
2025-06-16 09:01:14.104761:  
2025-06-16 09:01:14.105381: Epoch 602 
2025-06-16 09:01:14.105792: Current learning rate: 0.00436 
2025-06-16 09:01:58.165130: train_loss -0.6397 
2025-06-16 09:01:58.165844: val_loss -0.6303 
2025-06-16 09:01:58.166236: Pseudo dice [0.7236, 0.9044, 0.8755, 0.8925] 
2025-06-16 09:01:58.166775: Epoch time: 44.06 s 
2025-06-16 09:01:59.716041:  
2025-06-16 09:01:59.716834: Epoch 603 
2025-06-16 09:01:59.717263: Current learning rate: 0.00435 
2025-06-16 09:02:43.378349: train_loss -0.6372 
2025-06-16 09:02:43.379043: val_loss -0.6366 
2025-06-16 09:02:43.379435: Pseudo dice [0.6738, 0.9134, 0.921, 0.891] 
2025-06-16 09:02:43.379971: Epoch time: 43.66 s 
2025-06-16 09:02:44.857790:  
2025-06-16 09:02:44.858295: Epoch 604 
2025-06-16 09:02:44.858661: Current learning rate: 0.00434 
2025-06-16 09:03:27.364311: train_loss -0.6224 
2025-06-16 09:03:27.365010: val_loss -0.6291 
2025-06-16 09:03:27.365396: Pseudo dice [0.8231, 0.9208, 0.9074, 0.8897] 
2025-06-16 09:03:27.365958: Epoch time: 42.51 s 
2025-06-16 09:03:28.553492:  
2025-06-16 09:03:28.554116: Epoch 605 
2025-06-16 09:03:28.554513: Current learning rate: 0.00433 
2025-06-16 09:04:12.887977: train_loss -0.6207 
2025-06-16 09:04:12.888714: val_loss -0.6456 
2025-06-16 09:04:12.889103: Pseudo dice [0.7787, 0.9275, 0.9122, 0.8981] 
2025-06-16 09:04:12.889473: Epoch time: 44.34 s 
2025-06-16 09:04:14.375731:  
2025-06-16 09:04:14.376249: Epoch 606 
2025-06-16 09:04:14.376749: Current learning rate: 0.00432 
2025-06-16 09:04:57.914813: train_loss -0.6421 
2025-06-16 09:04:57.915492: val_loss -0.6497 
2025-06-16 09:04:57.915896: Pseudo dice [0.8427, 0.9243, 0.9194, 0.8788] 
2025-06-16 09:04:57.916275: Epoch time: 43.54 s 
2025-06-16 09:04:59.322868:  
2025-06-16 09:04:59.323411: Epoch 607 
2025-06-16 09:04:59.323763: Current learning rate: 0.00431 
2025-06-16 09:05:44.486596: train_loss -0.6469 
2025-06-16 09:05:44.487454: val_loss -0.6428 
2025-06-16 09:05:44.487897: Pseudo dice [0.676, 0.9115, 0.9002, 0.896] 
2025-06-16 09:05:44.488290: Epoch time: 45.16 s 
2025-06-16 09:05:45.811409:  
2025-06-16 09:05:45.811968: Epoch 608 
2025-06-16 09:05:45.812333: Current learning rate: 0.0043 
2025-06-16 09:06:29.131846: train_loss -0.63 
2025-06-16 09:06:29.132631: val_loss -0.6309 
2025-06-16 09:06:29.133090: Pseudo dice [0.7382, 0.9095, 0.8909, 0.9015] 
2025-06-16 09:06:29.133524: Epoch time: 43.32 s 
2025-06-16 09:06:30.628077:  
2025-06-16 09:06:30.628764: Epoch 609 
2025-06-16 09:06:30.629142: Current learning rate: 0.00429 
2025-06-16 09:07:13.922146: train_loss -0.639 
2025-06-16 09:07:13.922900: val_loss -0.6407 
2025-06-16 09:07:13.923300: Pseudo dice [0.8289, 0.9092, 0.9156, 0.9069] 
2025-06-16 09:07:13.923767: Epoch time: 43.3 s 
2025-06-16 09:07:15.155634:  
2025-06-16 09:07:15.156213: Epoch 610 
2025-06-16 09:07:15.156676: Current learning rate: 0.00429 
2025-06-16 09:07:57.808611: train_loss -0.6428 
2025-06-16 09:07:57.809551: val_loss -0.6265 
2025-06-16 09:07:57.809943: Pseudo dice [0.5316, 0.9169, 0.9128, 0.9186] 
2025-06-16 09:07:57.810287: Epoch time: 42.65 s 
2025-06-16 09:07:59.110162:  
2025-06-16 09:07:59.110812: Epoch 611 
2025-06-16 09:07:59.111234: Current learning rate: 0.00428 
2025-06-16 09:08:43.978157: train_loss -0.6386 
2025-06-16 09:08:43.978978: val_loss -0.6518 
2025-06-16 09:08:43.979396: Pseudo dice [0.7182, 0.9217, 0.9017, 0.9037] 
2025-06-16 09:08:43.985046: Epoch time: 44.87 s 
2025-06-16 09:08:45.428290:  
2025-06-16 09:08:45.428928: Epoch 612 
2025-06-16 09:08:45.429291: Current learning rate: 0.00427 
2025-06-16 09:09:28.195964: train_loss -0.642 
2025-06-16 09:09:28.196718: val_loss -0.6475 
2025-06-16 09:09:28.197114: Pseudo dice [0.8351, 0.9142, 0.9153, 0.9147] 
2025-06-16 09:09:28.197490: Epoch time: 42.77 s 
2025-06-16 09:09:29.789512:  
2025-06-16 09:09:29.790379: Epoch 613 
2025-06-16 09:09:29.791256: Current learning rate: 0.00426 
2025-06-16 09:10:13.602968: train_loss -0.6375 
2025-06-16 09:10:13.603611: val_loss -0.6272 
2025-06-16 09:10:13.604020: Pseudo dice [0.7699, 0.9188, 0.8936, 0.8709] 
2025-06-16 09:10:13.604388: Epoch time: 43.81 s 
2025-06-16 09:10:14.812351:  
2025-06-16 09:10:14.813059: Epoch 614 
2025-06-16 09:10:14.813429: Current learning rate: 0.00425 
2025-06-16 09:10:57.218769: train_loss -0.6507 
2025-06-16 09:10:57.219496: val_loss -0.6301 
2025-06-16 09:10:57.219884: Pseudo dice [0.7822, 0.9189, 0.9031, 0.9164] 
2025-06-16 09:10:57.220217: Epoch time: 42.41 s 
2025-06-16 09:10:58.460706:  
2025-06-16 09:10:58.461317: Epoch 615 
2025-06-16 09:10:58.461702: Current learning rate: 0.00424 
2025-06-16 09:11:42.801950: train_loss -0.6577 
2025-06-16 09:11:42.802614: val_loss -0.6593 
2025-06-16 09:11:42.803029: Pseudo dice [0.8252, 0.9219, 0.9318, 0.9324] 
2025-06-16 09:11:42.803381: Epoch time: 44.34 s 
2025-06-16 09:11:44.138451:  
2025-06-16 09:11:44.139070: Epoch 616 
2025-06-16 09:11:44.139461: Current learning rate: 0.00423 
2025-06-16 09:12:28.113921: train_loss -0.6434 
2025-06-16 09:12:28.114671: val_loss -0.6483 
2025-06-16 09:12:28.115195: Pseudo dice [0.8713, 0.9271, 0.9269, 0.9015] 
2025-06-16 09:12:28.115545: Epoch time: 43.98 s 
2025-06-16 09:12:29.354844:  
2025-06-16 09:12:29.355440: Epoch 617 
2025-06-16 09:12:29.355800: Current learning rate: 0.00422 
2025-06-16 09:13:12.140802: train_loss -0.6367 
2025-06-16 09:13:12.141539: val_loss -0.6476 
2025-06-16 09:13:12.141928: Pseudo dice [0.8359, 0.9195, 0.9163, 0.8929] 
2025-06-16 09:13:12.142286: Epoch time: 42.79 s 
2025-06-16 09:13:13.360070:  
2025-06-16 09:13:13.360579: Epoch 618 
2025-06-16 09:13:13.360933: Current learning rate: 0.00421 
2025-06-16 09:13:58.089345: train_loss -0.6373 
2025-06-16 09:13:58.090126: val_loss -0.6301 
2025-06-16 09:13:58.090615: Pseudo dice [0.8651, 0.9109, 0.9164, 0.8822] 
2025-06-16 09:13:58.091314: Epoch time: 44.73 s 
2025-06-16 09:13:59.710597:  
2025-06-16 09:13:59.711496: Epoch 619 
2025-06-16 09:13:59.712273: Current learning rate: 0.0042 
2025-06-16 09:14:44.233713: train_loss -0.637 
2025-06-16 09:14:44.234440: val_loss -0.6481 
2025-06-16 09:14:44.234866: Pseudo dice [0.8184, 0.9226, 0.9166, 0.9277] 
2025-06-16 09:14:44.235251: Epoch time: 44.53 s 
2025-06-16 09:14:44.235750: Yayy! New best EMA pseudo Dice: 0.8819 
2025-06-16 09:14:46.216110:  
2025-06-16 09:14:46.216925: Epoch 620 
2025-06-16 09:14:46.217561: Current learning rate: 0.00419 
2025-06-16 09:15:30.223919: train_loss -0.6356 
2025-06-16 09:15:30.224846: val_loss -0.6389 
2025-06-16 09:15:30.225285: Pseudo dice [0.7495, 0.9047, 0.8808, 0.913] 
2025-06-16 09:15:30.225700: Epoch time: 44.01 s 
2025-06-16 09:15:31.564724:  
2025-06-16 09:15:31.565326: Epoch 621 
2025-06-16 09:15:31.565696: Current learning rate: 0.00418 
2025-06-16 09:16:14.670857: train_loss -0.6469 
2025-06-16 09:16:14.671640: val_loss -0.6523 
2025-06-16 09:16:14.672035: Pseudo dice [0.8111, 0.9134, 0.8896, 0.9209] 
2025-06-16 09:16:14.672447: Epoch time: 43.11 s 
2025-06-16 09:16:16.058377:  
2025-06-16 09:16:16.058995: Epoch 622 
2025-06-16 09:16:16.059371: Current learning rate: 0.00417 
2025-06-16 09:17:02.286866: train_loss -0.6468 
2025-06-16 09:17:02.287677: val_loss -0.6404 
2025-06-16 09:17:02.288114: Pseudo dice [0.8082, 0.9201, 0.913, 0.8963] 
2025-06-16 09:17:02.288557: Epoch time: 46.23 s 
2025-06-16 09:17:03.554674:  
2025-06-16 09:17:03.555214: Epoch 623 
2025-06-16 09:17:03.555587: Current learning rate: 0.00416 
2025-06-16 09:17:46.421838: train_loss -0.6544 
2025-06-16 09:17:46.422612: val_loss -0.6435 
2025-06-16 09:17:46.423136: Pseudo dice [0.7832, 0.9134, 0.9076, 0.9222] 
2025-06-16 09:17:46.423628: Epoch time: 42.87 s 
2025-06-16 09:17:47.633748:  
2025-06-16 09:17:47.634272: Epoch 624 
2025-06-16 09:17:47.634652: Current learning rate: 0.00415 
2025-06-16 09:18:30.763791: train_loss -0.6301 
2025-06-16 09:18:30.764495: val_loss -0.6367 
2025-06-16 09:18:30.764926: Pseudo dice [0.6596, 0.9126, 0.8887, 0.9049] 
2025-06-16 09:18:30.765291: Epoch time: 43.13 s 
2025-06-16 09:18:32.010471:  
2025-06-16 09:18:32.011001: Epoch 625 
2025-06-16 09:18:32.011374: Current learning rate: 0.00414 
2025-06-16 09:19:14.460687: train_loss -0.6349 
2025-06-16 09:19:14.461546: val_loss -0.6562 
2025-06-16 09:19:14.461977: Pseudo dice [0.8111, 0.9225, 0.8987, 0.9125] 
2025-06-16 09:19:14.462366: Epoch time: 42.45 s 
2025-06-16 09:19:15.795023:  
2025-06-16 09:19:15.795565: Epoch 626 
2025-06-16 09:19:15.795927: Current learning rate: 0.00413 
2025-06-16 09:19:59.667717: train_loss -0.6221 
2025-06-16 09:19:59.668489: val_loss -0.6476 
2025-06-16 09:19:59.668914: Pseudo dice [0.8033, 0.9202, 0.9268, 0.8968] 
2025-06-16 09:19:59.669341: Epoch time: 43.87 s 
2025-06-16 09:20:01.550294:  
2025-06-16 09:20:01.551848: Epoch 627 
2025-06-16 09:20:01.552955: Current learning rate: 0.00412 
2025-06-16 09:20:46.247983: train_loss -0.6446 
2025-06-16 09:20:46.248835: val_loss -0.638 
2025-06-16 09:20:46.249248: Pseudo dice [0.8126, 0.9204, 0.8983, 0.9076] 
2025-06-16 09:20:46.249796: Epoch time: 44.7 s 
2025-06-16 09:20:47.979822:  
2025-06-16 09:20:47.980375: Epoch 628 
2025-06-16 09:20:47.980743: Current learning rate: 0.00411 
2025-06-16 09:21:30.999019: train_loss -0.6421 
2025-06-16 09:21:30.999934: val_loss -0.6493 
2025-06-16 09:21:31.000374: Pseudo dice [0.8306, 0.9179, 0.8974, 0.9054] 
2025-06-16 09:21:31.000916: Epoch time: 43.02 s 
2025-06-16 09:21:32.678209:  
2025-06-16 09:21:32.678869: Epoch 629 
2025-06-16 09:21:32.679280: Current learning rate: 0.0041 
2025-06-16 09:22:14.559082: train_loss -0.6384 
2025-06-16 09:22:14.559792: val_loss -0.6361 
2025-06-16 09:22:14.560171: Pseudo dice [0.7807, 0.9184, 0.8962, 0.9116] 
2025-06-16 09:22:14.560554: Epoch time: 41.88 s 
2025-06-16 09:22:15.779447:  
2025-06-16 09:22:15.780001: Epoch 630 
2025-06-16 09:22:15.780359: Current learning rate: 0.00409 
2025-06-16 09:23:01.419952: train_loss -0.6359 
2025-06-16 09:23:01.427132: val_loss -0.6464 
2025-06-16 09:23:01.427584: Pseudo dice [0.8234, 0.9195, 0.9145, 0.8945] 
2025-06-16 09:23:01.428616: Epoch time: 45.63 s 
2025-06-16 09:23:03.032313:  
2025-06-16 09:23:03.032986: Epoch 631 
2025-06-16 09:23:03.033352: Current learning rate: 0.00408 
2025-06-16 09:23:48.132866: train_loss -0.6289 
2025-06-16 09:23:48.133524: val_loss -0.6155 
2025-06-16 09:23:48.133889: Pseudo dice [0.7671, 0.9089, 0.9077, 0.897] 
2025-06-16 09:23:48.134229: Epoch time: 45.1 s 
2025-06-16 09:23:49.708196:  
2025-06-16 09:23:49.709112: Epoch 632 
2025-06-16 09:23:49.709867: Current learning rate: 0.00407 
2025-06-16 09:24:34.242221: train_loss -0.6358 
2025-06-16 09:24:34.243186: val_loss -0.6308 
2025-06-16 09:24:34.243664: Pseudo dice [0.8018, 0.9171, 0.9114, 0.8846] 
2025-06-16 09:24:34.244045: Epoch time: 44.54 s 
2025-06-16 09:24:35.503196:  
2025-06-16 09:24:35.503738: Epoch 633 
2025-06-16 09:24:35.504084: Current learning rate: 0.00406 
2025-06-16 09:25:18.996998: train_loss -0.631 
2025-06-16 09:25:18.997759: val_loss -0.631 
2025-06-16 09:25:18.998142: Pseudo dice [0.81, 0.9241, 0.9211, 0.885] 
2025-06-16 09:25:18.998481: Epoch time: 43.49 s 
2025-06-16 09:25:22.835390:  
2025-06-16 09:25:22.836181: Epoch 634 
2025-06-16 09:25:22.836629: Current learning rate: 0.00405 
2025-06-16 09:26:08.092223: train_loss -0.6307 
2025-06-16 09:26:08.092976: val_loss -0.6374 
2025-06-16 09:26:08.093360: Pseudo dice [0.7993, 0.9203, 0.9092, 0.9253] 
2025-06-16 09:26:08.093850: Epoch time: 45.26 s 
2025-06-16 09:26:09.474001:  
2025-06-16 09:26:09.474912: Epoch 635 
2025-06-16 09:26:09.475585: Current learning rate: 0.00404 
2025-06-16 09:26:54.850381: train_loss -0.6458 
2025-06-16 09:26:54.851174: val_loss -0.6298 
2025-06-16 09:26:54.851887: Pseudo dice [0.8359, 0.923, 0.9194, 0.8839] 
2025-06-16 09:26:54.852360: Epoch time: 45.38 s 
2025-06-16 09:26:56.171720:  
2025-06-16 09:26:56.172381: Epoch 636 
2025-06-16 09:26:56.172750: Current learning rate: 0.00403 
2025-06-16 09:27:39.970400: train_loss -0.6302 
2025-06-16 09:27:39.971184: val_loss -0.6164 
2025-06-16 09:27:39.971880: Pseudo dice [0.8308, 0.9033, 0.9225, 0.8841] 
2025-06-16 09:27:39.972355: Epoch time: 43.8 s 
2025-06-16 09:27:39.972965: Yayy! New best EMA pseudo Dice: 0.8822 
2025-06-16 09:27:42.138898:  
2025-06-16 09:27:42.139424: Epoch 637 
2025-06-16 09:27:42.139938: Current learning rate: 0.00402 
2025-06-16 09:28:24.889149: train_loss -0.6451 
2025-06-16 09:28:24.889970: val_loss -0.6443 
2025-06-16 09:28:24.890409: Pseudo dice [0.8018, 0.9247, 0.9199, 0.9226] 
2025-06-16 09:28:24.891000: Epoch time: 42.75 s 
2025-06-16 09:28:24.891398: Yayy! New best EMA pseudo Dice: 0.8832 
2025-06-16 09:28:26.519091:  
2025-06-16 09:28:26.519834: Epoch 638 
2025-06-16 09:28:26.520251: Current learning rate: 0.00401 
2025-06-16 09:29:10.585794: train_loss -0.6464 
2025-06-16 09:29:10.590671: val_loss -0.6478 
2025-06-16 09:29:10.591352: Pseudo dice [0.7881, 0.9219, 0.9095, 0.9108] 
2025-06-16 09:29:10.591772: Epoch time: 44.07 s 
2025-06-16 09:29:11.877997:  
2025-06-16 09:29:11.878606: Epoch 639 
2025-06-16 09:29:11.878964: Current learning rate: 0.004 
2025-06-16 09:29:55.625231: train_loss -0.6281 
2025-06-16 09:29:55.626035: val_loss -0.6282 
2025-06-16 09:29:55.626418: Pseudo dice [0.7534, 0.8907, 0.8964, 0.8892] 
2025-06-16 09:29:55.626976: Epoch time: 43.75 s 
2025-06-16 09:29:56.897066:  
2025-06-16 09:29:56.897583: Epoch 640 
2025-06-16 09:29:56.897945: Current learning rate: 0.00399 
2025-06-16 09:30:39.503266: train_loss -0.6283 
2025-06-16 09:30:39.503981: val_loss -0.6471 
2025-06-16 09:30:39.504404: Pseudo dice [0.8441, 0.9141, 0.9233, 0.9134] 
2025-06-16 09:30:39.504916: Epoch time: 42.61 s 
2025-06-16 09:30:40.724048:  
2025-06-16 09:30:40.724640: Epoch 641 
2025-06-16 09:30:40.725021: Current learning rate: 0.00398 
2025-06-16 09:31:25.145211: train_loss -0.6324 
2025-06-16 09:31:25.145964: val_loss -0.6568 
2025-06-16 09:31:25.150237: Pseudo dice [0.7616, 0.9085, 0.8915, 0.9154] 
2025-06-16 09:31:25.150666: Epoch time: 44.42 s 
2025-06-16 09:31:26.338481:  
2025-06-16 09:31:26.339076: Epoch 642 
2025-06-16 09:31:26.339437: Current learning rate: 0.00397 
2025-06-16 09:32:11.204183: train_loss -0.6196 
2025-06-16 09:32:11.205098: val_loss -0.6522 
2025-06-16 09:32:11.205542: Pseudo dice [0.7972, 0.9276, 0.9016, 0.9212] 
2025-06-16 09:32:11.206100: Epoch time: 44.87 s 
2025-06-16 09:32:12.855453:  
2025-06-16 09:32:12.856232: Epoch 643 
2025-06-16 09:32:12.856641: Current learning rate: 0.00396 
2025-06-16 09:32:56.875127: train_loss -0.6397 
2025-06-16 09:32:56.875863: val_loss -0.6634 
2025-06-16 09:32:56.876286: Pseudo dice [0.7151, 0.9288, 0.9118, 0.8568] 
2025-06-16 09:32:56.876780: Epoch time: 44.02 s 
2025-06-16 09:32:58.162534:  
2025-06-16 09:32:58.163041: Epoch 644 
2025-06-16 09:32:58.163451: Current learning rate: 0.00395 
2025-06-16 09:33:40.539282: train_loss -0.6416 
2025-06-16 09:33:40.540077: val_loss -0.6615 
2025-06-16 09:33:40.540473: Pseudo dice [0.8414, 0.9107, 0.9268, 0.9053] 
2025-06-16 09:33:40.541079: Epoch time: 42.38 s 
2025-06-16 09:33:41.900926:  
2025-06-16 09:33:41.901447: Epoch 645 
2025-06-16 09:33:41.901980: Current learning rate: 0.00394 
2025-06-16 09:34:23.790972: train_loss -0.648 
2025-06-16 09:34:23.791766: val_loss -0.6254 
2025-06-16 09:34:23.792198: Pseudo dice [0.7455, 0.9232, 0.896, 0.8905] 
2025-06-16 09:34:23.792804: Epoch time: 41.89 s 
2025-06-16 09:34:25.125097:  
2025-06-16 09:34:25.125705: Epoch 646 
2025-06-16 09:34:25.126119: Current learning rate: 0.00393 
2025-06-16 09:35:06.547724: train_loss -0.638 
2025-06-16 09:35:06.548445: val_loss -0.6351 
2025-06-16 09:35:06.548858: Pseudo dice [0.7842, 0.9118, 0.8945, 0.9198] 
2025-06-16 09:35:06.549384: Epoch time: 41.42 s 
2025-06-16 09:35:08.154461:  
2025-06-16 09:35:08.155239: Epoch 647 
2025-06-16 09:35:08.155683: Current learning rate: 0.00392 
2025-06-16 09:35:52.952486: train_loss -0.6323 
2025-06-16 09:35:52.953240: val_loss -0.6594 
2025-06-16 09:35:52.953808: Pseudo dice [0.8218, 0.9195, 0.9214, 0.9101] 
2025-06-16 09:35:52.954246: Epoch time: 44.8 s 
2025-06-16 09:35:54.877772:  
2025-06-16 09:35:54.878776: Epoch 648 
2025-06-16 09:35:54.879634: Current learning rate: 0.00391 
2025-06-16 09:36:35.837978: train_loss -0.6411 
2025-06-16 09:36:35.838798: val_loss -0.6483 
2025-06-16 09:36:35.839283: Pseudo dice [0.8641, 0.9212, 0.9022, 0.9041] 
2025-06-16 09:36:35.839862: Epoch time: 40.96 s 
2025-06-16 09:36:37.173113:  
2025-06-16 09:36:37.173634: Epoch 649 
2025-06-16 09:36:37.173989: Current learning rate: 0.0039 
2025-06-16 09:37:20.345475: train_loss -0.6447 
2025-06-16 09:37:20.346368: val_loss -0.6493 
2025-06-16 09:37:20.346828: Pseudo dice [0.761, 0.9207, 0.9058, 0.9086] 
2025-06-16 09:37:20.347217: Epoch time: 43.17 s 
2025-06-16 09:37:21.947559:  
2025-06-16 09:37:21.948141: Epoch 650 
2025-06-16 09:37:21.948530: Current learning rate: 0.00389 
2025-06-16 09:38:04.018352: train_loss -0.6297 
2025-06-16 09:38:04.019467: val_loss -0.6374 
2025-06-16 09:38:04.020162: Pseudo dice [0.8288, 0.903, 0.9072, 0.8976] 
2025-06-16 09:38:04.020977: Epoch time: 42.07 s 
2025-06-16 09:38:05.791876:  
2025-06-16 09:38:05.792614: Epoch 651 
2025-06-16 09:38:05.793480: Current learning rate: 0.00388 
2025-06-16 09:38:50.586413: train_loss -0.6321 
2025-06-16 09:38:50.587140: val_loss -0.6367 
2025-06-16 09:38:50.587836: Pseudo dice [0.7532, 0.9074, 0.9003, 0.9108] 
2025-06-16 09:38:50.588276: Epoch time: 44.8 s 
2025-06-16 09:38:52.304585:  
2025-06-16 09:38:52.305242: Epoch 652 
2025-06-16 09:38:52.305671: Current learning rate: 0.00387 
2025-06-16 09:39:38.319323: train_loss -0.642 
2025-06-16 09:39:38.320253: val_loss -0.6389 
2025-06-16 09:39:38.320839: Pseudo dice [0.7896, 0.9244, 0.9198, 0.9319] 
2025-06-16 09:39:38.321295: Epoch time: 46.02 s 
2025-06-16 09:39:39.691809:  
2025-06-16 09:39:39.692368: Epoch 653 
2025-06-16 09:39:39.692740: Current learning rate: 0.00386 
2025-06-16 09:40:21.871149: train_loss -0.6458 
2025-06-16 09:40:21.871917: val_loss -0.6249 
2025-06-16 09:40:21.872347: Pseudo dice [0.8286, 0.9119, 0.897, 0.8689] 
2025-06-16 09:40:21.872858: Epoch time: 42.18 s 
2025-06-16 09:40:23.589454:  
2025-06-16 09:40:23.590645: Epoch 654 
2025-06-16 09:40:23.591632: Current learning rate: 0.00385 
2025-06-16 09:41:06.175947: train_loss -0.6477 
2025-06-16 09:41:06.176668: val_loss -0.6362 
2025-06-16 09:41:06.177051: Pseudo dice [0.8015, 0.9217, 0.916, 0.887] 
2025-06-16 09:41:06.177380: Epoch time: 42.59 s 
2025-06-16 09:41:07.630976:  
2025-06-16 09:41:07.631575: Epoch 655 
2025-06-16 09:41:07.631945: Current learning rate: 0.00384 
2025-06-16 09:41:50.391874: train_loss -0.6461 
2025-06-16 09:41:50.392602: val_loss -0.6607 
2025-06-16 09:41:50.393068: Pseudo dice [0.8205, 0.9262, 0.9063, 0.9041] 
2025-06-16 09:41:50.393457: Epoch time: 42.76 s 
2025-06-16 09:41:51.672425:  
2025-06-16 09:41:51.673103: Epoch 656 
2025-06-16 09:41:51.673491: Current learning rate: 0.00383 
2025-06-16 09:42:36.168134: train_loss -0.64 
2025-06-16 09:42:36.168894: val_loss -0.6515 
2025-06-16 09:42:36.169538: Pseudo dice [0.83, 0.9204, 0.9363, 0.8859] 
2025-06-16 09:42:36.170095: Epoch time: 44.5 s 
2025-06-16 09:42:37.560901:  
2025-06-16 09:42:37.561510: Epoch 657 
2025-06-16 09:42:37.561869: Current learning rate: 0.00382 
2025-06-16 09:43:19.533544: train_loss -0.6507 
2025-06-16 09:43:19.534178: val_loss -0.6395 
2025-06-16 09:43:19.534554: Pseudo dice [0.7936, 0.8915, 0.9072, 0.8888] 
2025-06-16 09:43:19.535014: Epoch time: 41.97 s 
2025-06-16 09:43:20.729369:  
2025-06-16 09:43:20.730053: Epoch 658 
2025-06-16 09:43:20.730456: Current learning rate: 0.00381 
