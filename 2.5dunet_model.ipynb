{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85796fb3-dc91-4101-a23d-440d0abfdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from scipy.ndimage import zoom\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df166f99-d3d3-4787-9638-17d6321fbc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now taking 9 adjacent slices: 4 before, 1 center, 4 after → much deeper 2.5D context than trial18 (which used 3)\n",
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, data_dir, patients=None, modalities=(\"t1n\", \"t1c\", \"t2w\", \"t2f\"),\n",
    "                 patch_depth=9, target_size=(128, 128), only_tumor_slices=True): # Explicitly filters out background-only slices, helping reduce class imbalance.\n",
    "        self.modalities = modalities\n",
    "        self.patch_depth = patch_depth\n",
    "        self.half = patch_depth // 2\n",
    "        self.target_size = target_size\n",
    "        self.only_tumor_slices = only_tumor_slices\n",
    "        self.data_dir = data_dir\n",
    "        self.patients = sorted(os.listdir(self.data_dir)) if patients is None else patients\n",
    "\n",
    "        self.index_map = []\n",
    "        for pat in self.patients:\n",
    "            seg_path = os.path.join(self.data_dir, pat, f\"{pat}-seg.nii.gz\")\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "            for z in range(seg.shape[2]):\n",
    "                if self.only_tumor_slices:\n",
    "                    if np.any(seg[:, :, z] > 0):\n",
    "                        self.index_map.append((pat, z))\n",
    "                else:\n",
    "                    self.index_map.append((pat, z))     \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx): # Input Creation\n",
    "        pat, z = self.index_map[idx]\n",
    "        folder = os.path.join(self.data_dir, pat)\n",
    "        H, W = self.target_size\n",
    "\n",
    "        vols = []\n",
    "        for mod in self.modalities:\n",
    "            img = nib.load(os.path.join(folder, f\"{pat}-{mod}.nii.gz\")).get_fdata().astype(np.float32)\n",
    "            mask = img != 0\n",
    "            mu, sigma = (img[mask].mean(), img[mask].std()) if mask.sum() > 0 else (img.mean(), img.std())\n",
    "            img = (img - mu) / (sigma + 1e-8)\n",
    "\n",
    "            resized = np.zeros((H, W, img.shape[2]), dtype=np.float32)\n",
    "            for zi in range(img.shape[2]):\n",
    "                resized[:, :, zi] = cv2.resize(img[:, :, zi], (W, H), interpolation=cv2.INTER_CUBIC)\n",
    "            vols.append(resized)\n",
    "\n",
    "        vol4 = np.stack(vols, axis=0)  # shape: (4, H, W, D)\n",
    "        vol4 = np.pad(vol4, ((0, 0), (0, 0), (0, 0), (self.half, self.half)), mode='edge')\n",
    "        zp = z + self.half\n",
    "        patch = vol4[:, :, :, zp - self.half: zp + self.half + 1]  # (4, H, W, D=5). Patch shape becomes (36, 128, 128): 9 slices × 4 modalities\n",
    "        x = patch.transpose(3, 0, 1, 2).reshape(self.patch_depth * 4, H, W)  # (36, H, W)\n",
    "\n",
    "        '''Segmentation Label Handling:\n",
    "            No change here:\n",
    "            Resizing each slice with nearest neighbor (preserves label integrity),\n",
    "            Padding to align with the same depth,\n",
    "            Returning the center slice label as target.'''\n",
    "        seg = nib.load(os.path.join(folder, f\"{pat}-seg.nii.gz\")).get_fdata().astype(np.int64)\n",
    "        seg_r = np.zeros((H, W, seg.shape[2]), dtype=np.int64)\n",
    "        for zi in range(seg.shape[2]):\n",
    "            seg_r[:, :, zi] = cv2.resize(seg[:, :, zi], (W, H), interpolation=cv2.INTER_NEAREST)\n",
    "        seg_r = np.pad(seg_r, ((0, 0), (0, 0), (self.half, self.half)), mode='edge')\n",
    "        y = seg_r[:, :, zp]  # (H, W)\n",
    "\n",
    "        return torch.from_numpy(x).float(), torch.from_numpy(y).long()\n",
    "\n",
    "# === Data Setup ===\n",
    "data_dir = \"/scratch/scai/mtech/aib232081/brain_tumor_detection/BraTS2024_dataset/BraTS2024-BraTS-GLI-TrainingData/training_data1_v2\"\n",
    "all_patients = sorted(os.listdir(data_dir))  # 1350 patients\n",
    "\n",
    "'''Train: 80% (1200 patients)\n",
    "Val: 10% (150 patients)\n",
    "Test: 10% (150 patients)\n",
    "The use of 0.1111 ensures 150 val out of the 1350 total.'''\n",
    "# Split: 80/10/10\n",
    "train_val_patients, test_patients = train_test_split(all_patients, test_size=0.1, random_state=42)\n",
    "train_patients, val_patients = train_test_split(train_val_patients, test_size=0.1111, random_state=42)\n",
    "\n",
    "# Dataset\n",
    "train_ds = BraTSDataset(data_dir, patients=train_patients, patch_depth=9, only_tumor_slices=True)\n",
    "val_ds   = BraTSDataset(data_dir, patients=val_patients, patch_depth=9, only_tumor_slices=True)\n",
    "test_ds  = BraTSDataset(data_dir, patients=test_patients, patch_depth=9, only_tumor_slices=True)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=10, pin_memory=True, persistent_workers=True, prefetch_factor=4)\n",
    "val_loader   = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "'''we are now using:\n",
    "    num_workers=10: Loads data using 10 CPU threads.\n",
    "    persistent_workers=True: Keeps workers alive across epochs (faster).\n",
    "    prefetch_factor=4: Each worker loads 4 batches in advance.\n",
    "    This can significantly speed up training on GPU systems.'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d72b17",
   "metadata": {},
   "source": [
    "comparison to trial18:\n",
    "| Feature                     | Trial18 (baseline)  | **Trial23**                                       |\n",
    "| --------------------------- | ------------------- | ------------------------------------------------- |\n",
    "| Depth of Input              | 3 slices            | **9 slices** (richer context)                     |\n",
    "| Encoder Blocks              | Simple Conv-BN-ReLU | **Residual Blocks**                               |\n",
    "| Skip Connection Enhancement | None                | **Attention Gates** (AG)                          |\n",
    "| Normalization Type          | BatchNorm           | **GroupNorm** (more stable for small batch sizes) |\n",
    "| Decoder Path                | Normal Conv + Up    | **Attention + Residual Decoder**                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a05789-a2d6-4442-a9dc-5a4e6f3763bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "ResidualConvBlock:\n",
    "    Two 3×3 convolutions + GroupNorm + ReLU.\n",
    "    Adds residual connection via a 1×1 conv on the input.\n",
    "    Output: ReLU(F(x) + x).\n",
    "\n",
    "Why this helps:\n",
    "    Easier gradient flow → improves training stability in deeper networks.\n",
    "    Helps preserve spatial information across layers.'''\n",
    "class ResidualConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(8, out_ch)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.residual = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.residual(x)\n",
    "        out = self.conv(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "'''\n",
    "AttentionGate:\n",
    "    Takes in g (decoder signal) and x (encoder skip connection).\n",
    "    Applies 1×1 convs + GroupNorm to both, then adds, passes through ReLU and sigmoid.\n",
    "    Final attention map modulates the encoder features.\n",
    "\n",
    "Why this helps:\n",
    "    Forces the decoder to focus only on relevant regions (e.g., tumor).\n",
    "    Prevents \"noise\" from early layers diluting the learning.'''\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1),\n",
    "            nn.GroupNorm(8, F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1),\n",
    "            nn.GroupNorm(8, F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class UNet2p5D_AttentionResidual(nn.Module): # Three levels of residual encoder blocks. Each downsampling via MaxPool halves resolution, doubles channels.\n",
    "    def __init__(self, in_ch=36, base_ch=64, n_classes=5):\n",
    "        super().__init__()\n",
    "        self.enc1 = ResidualConvBlock(in_ch, base_ch)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc2 = ResidualConvBlock(base_ch, base_ch * 2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc3 = ResidualConvBlock(base_ch * 2, base_ch * 4)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = ResidualConvBlock(base_ch * 4, base_ch * 8) # Deepest layer. Learns abstract features like tumor boundaries, location consistency, etc.\n",
    "\n",
    "        # Decoder Path with Attention:\n",
    "        self.up3 = nn.ConvTranspose2d(base_ch * 8, base_ch * 4, kernel_size=2, stride=2) # Upsample the bottleneck output\n",
    "        self.att3 = AttentionGate(F_g=base_ch * 4, F_l=base_ch * 4, F_int=base_ch * 2) # Use attention to filter skip features from encoder\n",
    "        self.dec3 = ResidualConvBlock(base_ch * 8, base_ch * 4) # Concatenate and apply a residual conv block\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(base_ch * 4, base_ch * 2, kernel_size=2, stride=2)\n",
    "        self.att2 = AttentionGate(F_g=base_ch * 2, F_l=base_ch * 2, F_int=base_ch)\n",
    "        self.dec2 = ResidualConvBlock(base_ch * 4, base_ch * 2)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(base_ch * 2, base_ch, kernel_size=2, stride=2)\n",
    "        self.att1 = AttentionGate(F_g=base_ch, F_l=base_ch, F_int=base_ch // 2)\n",
    "        self.dec1 = ResidualConvBlock(base_ch * 2, base_ch)\n",
    "\n",
    "        self.out = nn.Conv2d(base_ch, n_classes, kernel_size=1) # Final 1×1 convolution produces logits of shape [B, 5, 128, 128]\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)               # 64\n",
    "        e2 = self.enc2(self.pool1(e1))  # 128\n",
    "        e3 = self.enc3(self.pool2(e2))  # 256\n",
    "        b = self.bottleneck(self.pool3(e3))  # 512\n",
    "\n",
    "        g3 = self.up3(b)\n",
    "        a3 = self.att3(g3, e3)\n",
    "        d3 = self.dec3(torch.cat([g3, a3], dim=1))\n",
    "\n",
    "        g2 = self.up2(d3)\n",
    "        a2 = self.att2(g2, e2)\n",
    "        d2 = self.dec2(torch.cat([g2, a2], dim=1))\n",
    "\n",
    "        g1 = self.up1(d2)\n",
    "        a1 = self.att1(g1, e1)\n",
    "        d1 = self.dec1(torch.cat([g1, a1], dim=1))\n",
    "\n",
    "        return self.out(d1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e5a47-cba1-443d-a456-bbd0149c7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Addressing class imbalance\n",
    "Using a temperature-scaled Generalized Dice Loss\n",
    "Emphasizing Dice over CrossEntropy with alpha = 0.3 and beta = 0.7\n",
    "\n",
    "Applies temperature-scaled softmax, pred = F.softmax(pred / temperature, dim=1):\n",
    "    Lower temperature (<1) makes the distribution sharper.\n",
    "    Helps focus on confident predictions — can improve segmentation boundaries.\n",
    "    \n",
    "    '''\n",
    "def generalized_dice_loss(pred, target, epsilon=1e-6, temperature=0.7):\n",
    "    # Apply temperature-scaled softmax\n",
    "    pred = F.softmax(pred / temperature, dim=1)\n",
    "    one_hot = F.one_hot(target, num_classes=pred.shape[1]).permute(0, 3, 1, 2).float().to(pred.device) # Converts target (shape [B, H, W]) to one-hot (shape [B, C, H, W]) to match predictions.\n",
    "\n",
    "    # Class weights: inverse square of ground truth volume\n",
    "    weights = 1.0 / (one_hot.sum(dim=(2, 3)) ** 2 + epsilon)\n",
    "    '''\n",
    "    Generalized Dice Loss (GDL) uses weights that reduce the impact of large-volume classes:\n",
    "        Background has high volume → gets very small weight.\n",
    "        Tumor regions get higher importance.'''\n",
    "    \n",
    "    # Computes per-class intersection and union over spatial dimensions.\n",
    "    intersect = (pred * one_hot).sum(dim=(2, 3))\n",
    "    union = pred.sum(dim=(2, 3)) + one_hot.sum(dim=(2, 3))\n",
    "    dice = 2 * (weights * intersect).sum(dim=1) / (weights * union).sum(dim=1) # Weighted Dice for each sample in batch\n",
    "\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "\n",
    "def combined_loss(pred, target, alpha=0.3, beta=0.7, temperature=0.7):\n",
    "    # Class weights:  reduces overemphasis on background in CrossEntropy\n",
    "    class_weights = torch.tensor([0.01, 1, 1, 1, 1], device=pred.device)\n",
    "    \n",
    "    ce = F.cross_entropy(pred, target, weight=class_weights, reduction='mean') # Standard cross entropy loss with class weights\n",
    "    gdl = generalized_dice_loss(pred, target, temperature=temperature)\n",
    "\n",
    "    total = alpha * ce + beta * gdl\n",
    "    return total, ce.item(), gdl.item() # also returns individual loss components for logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289dba4-537d-4251-baea-800898b47468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model and loss\n",
    "# from model import UNet2p5D_AttentionResidual\n",
    "# from loss import combined_loss\n",
    "import time\n",
    "\n",
    "def compute_metrics(pred, target, num_classes=5):\n",
    "    pred_soft = F.softmax(pred, dim=1)\n",
    "    pred_labels = pred_soft.argmax(dim=1)\n",
    "\n",
    "    one_hot_pred = F.one_hot(pred_labels, num_classes).permute(0, 3, 1, 2).float()\n",
    "    one_hot_target = F.one_hot(target, num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    one_hot_pred = one_hot_pred.to(pred.device)\n",
    "    one_hot_target = one_hot_target.to(pred.device)\n",
    "\n",
    "    intersect = (one_hot_pred * one_hot_target).sum(dim=(2, 3))\n",
    "    union = one_hot_pred.sum(dim=(2, 3)) + one_hot_target.sum(dim=(2, 3)) - intersect\n",
    "    dice = (2 * intersect) / (one_hot_pred.sum(dim=(2, 3)) + one_hot_target.sum(dim=(2, 3)) + 1e-6)\n",
    "    iou = intersect / (union + 1e-6)\n",
    "\n",
    "    return dice.mean(dim=0).cpu().numpy(), iou.mean(dim=0).cpu().numpy()\n",
    "\n",
    "# Initialize model\n",
    "model = UNet2p5D_AttentionResidual(in_ch=36, base_ch=64, n_classes=5).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "scaler = GradScaler() # For stable mixed-precision training\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "checkpoint_path = \"checkpoint_trial23.pth\"\n",
    "log_path = \"training_logs_trial23.csv\"\n",
    "\n",
    "# Load history if exists\n",
    "if os.path.exists(log_path):\n",
    "    history_df = pd.read_csv(log_path)\n",
    "    history = history_df.to_dict(orient='list')\n",
    "    start_epoch = int(history_df['epoch'].max()) + 1\n",
    "    print(f\"Resuming from epoch {start_epoch}\")\n",
    "else:\n",
    "    history = {\n",
    "        'epoch': [], 'train_loss': [], 'val_loss': [],\n",
    "        'mean_dice_train': [], 'mean_dice_val': [],\n",
    "        'mean_iou_train': [], 'mean_iou_val': [],\n",
    "        'dice_ET_train': [], 'dice_NETC_train': [], 'dice_SNFH_train': [], 'dice_RC_train': [],\n",
    "        'dice_ET_val': [], 'dice_NETC_val': [], 'dice_SNFH_val': [], 'dice_RC_val': [],\n",
    "        'epoch_time_sec': [], 'lr': [], 'train_ce': [], 'train_gdl': [], 'val_ce': [], 'val_gdl': []\n",
    "    }\n",
    "    start_epoch = 0\n",
    "    print(\"Starting new training\")\n",
    "\n",
    "# Load checkpoint if exists\n",
    "best_val_loss = float('inf')\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "    print(f\"Loaded checkpoint with best_val_loss = {best_val_loss:.4f}\")\n",
    "\n",
    "# ==== Training ====\n",
    "num_epochs = 50\n",
    "early_stop_patience = 6 # Stops training if no val improvement for 6 epochs\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "\n",
    "    train_loss_total, ce_loss_total, gdl_loss_total = 0, 0, 0\n",
    "    val_ce_total, val_gdl_total = 0, 0\n",
    "    dice_all, iou_all = [], []\n",
    "\n",
    "    for xb, yb in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
    "        xb, yb = xb.cuda(), yb.cuda()\n",
    "\n",
    "        with autocast():\n",
    "            pred = model(xb)\n",
    "            loss, ce_val, gdl_val = combined_loss(pred, yb, alpha=0.3, beta=0.7, temperature=0.7)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss_total += loss.item()\n",
    "        ce_loss_total += ce_val\n",
    "        gdl_loss_total += gdl_val\n",
    "        d, i = compute_metrics(pred, yb)\n",
    "        dice_all.append(d)\n",
    "        iou_all.append(i)\n",
    "\n",
    "    dice_all = np.array(dice_all)\n",
    "    iou_all = np.array(iou_all)\n",
    "    mean_dice_train = dice_all.mean()\n",
    "    mean_iou_train = iou_all.mean()\n",
    "\n",
    "    # ==== Validation ====\n",
    "    model.eval()\n",
    "    val_loss_total = 0\n",
    "    val_dice_all, val_iou_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.cuda(), yb.cuda()\n",
    "            with autocast():\n",
    "                pred = model(xb)\n",
    "                loss, ce_val, gdl_val = combined_loss(pred, yb, alpha=0.3, beta=0.7, temperature=0.7)\n",
    "\n",
    "            val_loss_total += loss.item()\n",
    "            val_ce_total += ce_val\n",
    "            val_gdl_total += gdl_val\n",
    "            d, i = compute_metrics(pred, yb)\n",
    "            val_dice_all.append(d)\n",
    "            val_iou_all.append(i)\n",
    "\n",
    "    val_dice_all = np.array(val_dice_all)\n",
    "    val_iou_all = np.array(val_iou_all)\n",
    "    mean_dice_val = val_dice_all.mean()\n",
    "    mean_iou_val = val_iou_all.mean()\n",
    "\n",
    "    # Logging and Saving\n",
    "    epoch_time = time.time() - start_time\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1} -- Train Loss: {train_loss_total:.4f}, Val Loss: {val_loss_total:.4f}\")\n",
    "    print(f\"Mean Dice: Train={mean_dice_train:.4f}, Val={mean_dice_val:.4f}\")\n",
    "\n",
    "    scheduler.step(val_loss_total)\n",
    "\n",
    "    if val_loss_total < best_val_loss:\n",
    "        best_val_loss = val_loss_total\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), \"unet2p5d_best_trial23.pth\")\n",
    "        print(\"Saved best model.\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_loss': best_val_loss\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    history['epoch'].append(epoch+1)\n",
    "    history['train_loss'].append(train_loss_total)\n",
    "    history['val_loss'].append(val_loss_total)\n",
    "    history['train_ce'].append(ce_loss_total / len(train_loader))\n",
    "    history['train_gdl'].append(gdl_loss_total / len(train_loader))\n",
    "    history['val_ce'].append(val_ce_total / len(val_loader))\n",
    "    history['val_gdl'].append(val_gdl_total / len(val_loader))\n",
    "    history['mean_dice_train'].append(mean_dice_train)\n",
    "    history['mean_dice_val'].append(mean_dice_val)\n",
    "    history['mean_iou_train'].append(mean_iou_train)\n",
    "    history['mean_iou_val'].append(mean_iou_val)\n",
    "    history['dice_ET_train'].append(dice_all[:,1].mean())\n",
    "    history['dice_NETC_train'].append(dice_all[:,2].mean())\n",
    "    history['dice_SNFH_train'].append(dice_all[:,3].mean())\n",
    "    history['dice_RC_train'].append(dice_all[:,4].mean())\n",
    "    history['dice_ET_val'].append(val_dice_all[:,1].mean())\n",
    "    history['dice_NETC_val'].append(val_dice_all[:,2].mean())\n",
    "    history['dice_SNFH_val'].append(val_dice_all[:,3].mean())\n",
    "    history['dice_RC_val'].append(val_dice_all[:,4].mean())\n",
    "    history['epoch_time_sec'].append(epoch_time)\n",
    "    history['lr'].append(lr)\n",
    "\n",
    "    pd.DataFrame(history).to_csv(log_path, index=False)\n",
    "    print(f\"Epoch {epoch+1} completed and logged.\\n\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8f085-5bce-4c41-9954-364ae9f4703c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lidar_env)",
   "language": "python",
   "name": "lidar_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
